{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")\n",
    "\n",
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier  # Import the Balanced Random Forest\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bal_RF_classifier(X_train, y_train, X_test, cat_cols, target_samples_per_class=3000):\n",
    "    all_cols = X_train.columns.tolist()\n",
    "    cat_indices = [all_cols.index(col) for col in cat_cols]\n",
    "\n",
    "    # Define categorical transformer with one-hot encoding\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot Encode categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine transformations into a single preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('cat', categorical_transformer, cat_indices)]\n",
    "    )\n",
    "\n",
    "    # Create pipeline with the BalancedRandomForestClassifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('brf', BalancedRandomForestClassifier(random_state=42, n_jobs=-1))  # Balanced Random Forest\n",
    "    ])\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "    param_dist = {\n",
    "        'brf__criterion' : ['entropy', 'gini'],\n",
    "        'brf__n_estimators': [100, 200, 300],\n",
    "        'brf__max_depth': [10, 20, None], \n",
    "        'brf__min_samples_split': [2, 5, 10],\n",
    "        'brf__min_samples_leaf': [1, 2, 4],\n",
    "        'brf__max_features' : [None, 2, 3, 5, 'auto', 'log2']\n",
    "    }\n",
    "\n",
    "    # Randomized Search with cross-validation\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=skf,  # Adjust the number of folds for cross-validation if necessary\n",
    "        scoring='balanced_accuracy',\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[INFO] Starting training with {len(X_train)} samples\")\n",
    "    search.fit(X_train, y_train)\n",
    "    print(\"[INFO] Training complete.\")\n",
    "\n",
    "    print(\"Best parameters:\", search.best_params_)\n",
    "    print(\"Best CV balanced accuracy:\", search.best_score_)\n",
    "\n",
    "    # Optionally evaluate again with cross_val_score if needed\n",
    "    try:\n",
    "        cv_scores = cross_val_score(\n",
    "            search.best_estimator_,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=skf,  # Number of cross-validation splits\n",
    "            scoring='balanced_accuracy',\n",
    "            verbose=3\n",
    "        )\n",
    "        print(\"Generalization accuracy (via cross_val_score):\", cv_scores.mean())\n",
    "    except Exception as e:\n",
    "        print(f\"Cross-validation scoring failed: {e}\")\n",
    "\n",
    "    # Final test prediction\n",
    "    test_predictions = search.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "    # tried to figure out feature importance, didnt work\n",
    "    '''\n",
    "      # Get the feature importances\n",
    "    importances = search.best_estimator_.feature_importances_\n",
    "\n",
    "    # Plotting feature importance\n",
    "    indices = importances.argsort()[::-1]  # Sort feature importances in descending order\n",
    "    top_n = 10  # Number of top features to plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Top 10 Feature Importances\")\n",
    "    plt.bar(range(top_n), importances[indices[:top_n]], align=\"center\")\n",
    "    plt.xticks(range(top_n), X_train.columns[indices[:top_n]], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    '''\n",
    "    return search.best_estimator_, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanted to try alternate features to test on\n",
    "df_train = bucket_seasons(df_train)\n",
    "df_test = bucket_seasons(df_test)\n",
    "\n",
    "df_train = bucket_days(df_train)\n",
    "df_test = bucket_days(df_test)\n",
    "\n",
    "df_train['breed'] = df_train['breed'].astype(str)\n",
    "df_test['breed'] = df_test['breed'].astype(str)\n",
    "\n",
    "df_train = df_train.drop(columns=['size', 'intake_hour', 'intake_month'])\n",
    "df_test = df_test.drop(columns=['size', 'intake_hour', 'intake_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed','season', 'is_mix', 'time_of_day', 'primary_color'] # experimenting with droping color\n",
    "num_cols = ['log_age', 'intake_year']    # Replace with your actual numerical columns\n",
    "# freq_cols = ['primary_color'] # for trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2df736",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['outcome_type'])\n",
    "y = df_train['outcome_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30320035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding mapping: ['Adoption' 'Died' 'Euthanasia' 'Return to Owner' 'Transfer']\n",
      "\n",
      "[INFO] Starting training with 88924 samples\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Could not import runpy module\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 19, in <module>\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\n",
      "<function _releaseLock at 0x7f7414cae1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    from pkgutil import read_code, get_importer\n",
      "  File \"/usr/lib/python3.8/pkgutil.py\", line 137, in <module>\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 111, in _get_module_details\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    __import__(pkg_name)\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/sre_compile.py\", line 291, in _optimize_charset\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 111, in _get_module_details\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    __import__(pkg_name)\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    from .memory import Memory\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/memory.py\", line 29, in <module>\n",
      "        from .memory import Memory\n",
      "from .memory import Memory  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/memory.py\", line 28, in <module>\n",
      "\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/memory.py\", line 12, in <module>\n",
      "    from . import hashing\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/hashing.py\", line 11, in <module>\n",
      "    from .memory import Memory\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/memory.py\", line 29, in <module>\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "    from ._store_backends import CacheWarning  # noqa\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/_store_backends.py\", line 17, in <module>\n",
      "    import asyncio\n",
      "  File \"/usr/lib/python3.8/asyncio/__init__.py\", line 8, in <module>\n",
      "    from ._store_backends import CacheWarning  # noqa\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/_store_backends.py\", line 17, in <module>\n",
      "    from .backports import concurrency_safe_rename\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/backports.py\", line 112, in <module>\n",
      "    from .backports import concurrency_safe_rename\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/backports.py\", line 112, in <module>\n",
      "    import numpy as np\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "    from .base_events import *\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 45, in <module>\n",
      "    def iter_importer_modules(importer, prefix=''):\n",
      "  File \"/usr/lib/python3.8/functools.py\", line 808, in singledispatch\n",
      "    charmap[k] = 1\n",
      "IndexError: bytearray index out of range\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    from .memory import Memory\n",
      "  File \"/u/nneoma/.local/lib/python3.8/site-packages/joblib/memory.py\", line 12, in <module>\n",
      "    import asyncio\n",
      "  File \"/usr/lib/python3.8/asyncio/__init__.py\", line 8, in <module>\n",
      "    from .base_events import *\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 18, in <module>\n",
      "    import numpy as np\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "    from . import staggered\n",
      "  File \"/usr/lib/python3.8/asyncio/staggered.py\", line 6, in <module>\n",
      "    import concurrent.futures\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/__init__.py\", line 8, in <module>\n",
      "    import types, weakref\n",
      "  File \"/usr/lib/python3.8/weakref.py\", line 22, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "    import hashlib\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
      "    import typing\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 1951, in <module>\n",
      "    from concurrent.futures._base import (FIRST_COMPLETED,\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 7, in <module>\n",
      "    class TextIO(IO[str]):\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 904, in __init_subclass__\n",
      "    error = Generic in cls.__orig_bases__\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 711, in __eq__\n",
      "    from _weakrefset import WeakSet, _IterationGuard\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "    def __eq__(self, other):\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
      "    import logging\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 417, in <module>\n",
      "    class PercentStyle(object):\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 422, in PercentStyle\n",
      "    validation_pattern = re.compile(r'%\\(\\w+\\)[#0+ -]*(\\*|\\d+)?(\\.(\\*|\\d+))?[diouxefgcrsa%]', re.I)\n",
      "  File \"/usr/lib/python3.8/re.py\", line 252, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.8/re.py\", line 304, in _compile\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.8/sre_compile.py\", line 768, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"/usr/lib/python3.8/sre_compile.py\", line 607, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"/usr/lib/python3.8/sre_compile.py\", line 120, in _compile\n",
      "    charset, hascased = _optimize_charset(av, iscased, tolower, fixes)\n",
      "  File \"/usr/lib/python3.8/sre_compile.py\", line 320, in _optimize_charset\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "    charmap += b'\\0' * 0xff00\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 939, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 939, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1037, in get_data\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 976, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1038, in get_data\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 640, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1539, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 156, in _path_isfile\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGINT(-2), SIGINT(-2), SIGINT(-2), SIGINT(-2), SIGINT(-2), EXIT(1), SIGINT(-2)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(y_test)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncoding mapping:\u001b[39m\u001b[38;5;124m'\u001b[39m, le\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m----> 7\u001b[0m best_model, test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_bal_RF_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cols\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Apply thresholds to the predicted probabilities\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# thresholded_preds = apply_thresholds(y_val_proba, thresholds)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Convert predictions back to original labels.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m classification_report_with_accuracy_score(y_test, test_predictions)\n",
      "Cell \u001b[0;32mIn[38], line 44\u001b[0m, in \u001b[0;36mtrain_bal_RF_classifier\u001b[0;34m(X_train, y_train, X_test, cat_cols, target_samples_per_class)\u001b[0m\n\u001b[1;32m     32\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     33\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     34\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Starting training with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Training complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGINT(-2), SIGINT(-2), SIGINT(-2), SIGINT(-2), SIGINT(-2), EXIT(1), SIGINT(-2)}"
     ]
    }
   ],
   "source": [
    "# Encode the target variable.\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "print('Encoding mapping:', le.classes_)\n",
    "\n",
    "best_model, test_predictions = train_bal_RF_classifier(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    cat_cols=cat_cols\n",
    ")\n",
    "\n",
    "\n",
    "# Apply thresholds to the predicted probabilities\n",
    "# thresholded_preds = apply_thresholds(y_val_proba, thresholds)\n",
    "\n",
    "# Convert predictions back to original labels.\n",
    "classification_report_with_accuracy_score(y_test, test_predictions)\n",
    "#print(importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
