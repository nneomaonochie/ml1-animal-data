{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39dda0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cd719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /u/nneoma/.local/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned color\n",
      "cleaned breed\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_851781/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned color\n",
      "cleaned breed\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7e98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f54764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = time_as_cyclical(df_train)\n",
    "#df_train = bucket_days(df_train)\n",
    "\n",
    "df_test = time_as_cyclical(df_test)\n",
    "#df_test = bucket_days(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8b925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>size</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>sable</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2022</td>\n",
       "      <td>orange</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "0            Stray  Normal / Behavior         Dog   Spayed Female   \n",
       "1            Stray  Normal / Behavior         Dog     Intact Male   \n",
       "2    Public Assist  Normal / Behavior         Cat   Neutered Male   \n",
       "3  Owner Surrender  Normal / Behavior         Dog   Neutered Male   \n",
       "4    Public Assist  Normal / Behavior         Dog   Neutered Male   \n",
       "\n",
       "   age_upon_intake   breed  intake_year primary_color  is_mix  size  \\\n",
       "0             96.0       2         2015         white       0     3   \n",
       "1             11.0       7         2016         sable       1     2   \n",
       "2             24.0  Common         2022        orange       0     2   \n",
       "3             24.0       2         2017     chocolate       1     4   \n",
       "4             72.0       3         2019         black       1     5   \n",
       "\n",
       "      outcome_type      hour_sin      hour_cos  month_sin  month_cos  \n",
       "0  Return to Owner  1.224647e-16 -1.000000e+00  -0.500000  -0.866025  \n",
       "1  Return to Owner -1.000000e+00 -1.836970e-16   0.866025  -0.500000  \n",
       "2         Transfer  0.000000e+00  1.000000e+00   0.500000  -0.866025  \n",
       "3  Return to Owner  1.224647e-16 -1.000000e+00   0.866025   0.500000  \n",
       "4  Return to Owner  7.071068e-01 -7.071068e-01   0.866025  -0.500000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=['size'])\n",
    "df_test = df_test.drop(columns=['size'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'logreg__penalty': 'l2', 'logreg__fit_intercept': False, 'logreg__class_weight': 'balanced', 'logreg__C': 0.01}\n",
    "\n",
    "def train_logreg_classifier(X_train, y_train, X_test, rare_classes):\n",
    "    cat_cols = ['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed','primary_color','is_mix']\n",
    "    num_cols = ['age_upon_intake', 'intake_year']    # Replace with your actual numerical columns\n",
    "\n",
    "\n",
    "    class_labels = np.unique(y_train)  # Get unique class labels in your target variable\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=class_labels,\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weight_dict = dict(zip(class_labels, class_weights))  # Map class labels to weights\n",
    "\n",
    "    # Handle rare categories\n",
    "    rare_threshold = 0.01\n",
    "    for col in cat_cols:\n",
    "        freq = X_train[col].value_counts(normalize=True)\n",
    "        rare_categories = freq[freq < rare_threshold].index\n",
    "        X_train[col] = X_train[col].apply(lambda x: 'Other' if x in rare_categories else x)\n",
    "        X_test[col] = X_test[col].apply(lambda x: 'Other' if x in rare_categories else x)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        X_train[col] = X_train[col].astype(str)\n",
    "        X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "\n",
    "    # Preprocessing for numerical features: Imputation (if needed) + Standardization\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "    #    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values (if any)\n",
    "        ('scaler', StandardScaler())  # Standardize numerical features\n",
    "    ])\n",
    "\n",
    "    # Preprocessing for categorical features: Imputation (if needed) + One-Hot Encoding\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "     #   ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values (if any)\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot Encode categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine both transformations into a single ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)\n",
    "        ])\n",
    "\n",
    "    # Create a pipeline that first transforms the data and then applies Logistic Regression\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('logreg', LogisticRegression(max_iter=1000))  # You can adjust max_iter as needed\n",
    "    ])\n",
    "\n",
    "    param_distributions = {\n",
    "        \"logreg__C\": [0.001, 0.01, 0.1, 1, 10, 100], #uniform(loc=0.01, scale=10),\n",
    "        \"logreg__penalty\": ['l2', 'l1'],\n",
    "        'logreg__solver' : ['lbfgs','liblinear'],\n",
    "        \"logreg__fit_intercept\": [True, False],\n",
    "        'logreg__class_weight': [class_weight_dict, 'balanced'],\n",
    "        'logreg__max_iter' : [1000, 3000, 5000]\n",
    "    }\n",
    "\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=50,\n",
    "        cv=skf,\n",
    "        scoring=balanced_acc_scorer,\n",
    "        verbose=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "\n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "\n",
    "    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=skf, verbose=3, scoring=balanced_acc_scorer)\n",
    "    print('Generalization Balanced accuracy (via cross_val_score):', cv_scores.mean())\n",
    "\n",
    "    test_predictions = randomized_search.predict(X_test)\n",
    "\n",
    "    return randomized_search.best_estimator_, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['outcome_type'])\n",
    "y = df_train['outcome_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e9b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding mapping: ['Adoption' 'Died' 'Euthanasia' 'Return to Owner' 'Transfer']\n",
      "Rare classes:\n",
      "  2: Euthanasia\n",
      "  1: Died\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.437 total time=   0.2s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.432 total time=   0.2s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.437 total time=   0.2s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.447 total time=   0.2s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.442 total time=   0.3s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.446 total time=   0.7s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.439 total time=   0.6s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.440 total time=   0.7s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.447 total time=   0.8s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.442 total time=   0.7s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.468 total time=   3.6s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.462 total time=   5.3s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.459 total time=   4.7s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.471 total time=   3.7s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   3.7s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=3000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.446 total time=   0.6s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.439 total time=   0.7s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.440 total time=   0.7s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.447 total time=   0.7s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=1000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.442 total time=   0.8s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.441 total time=   0.3s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.432 total time=   0.3s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.437 total time=   0.3s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.447 total time=   0.3s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=5000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.447 total time=   0.3s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=5000, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.467 total time=   3.2s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.462 total time=   3.7s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.458 total time=   3.3s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.471 total time=   4.9s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   3.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.443 total time=   0.3s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.439 total time=   0.3s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.440 total time=   0.3s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.448 total time=   0.4s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=3000, logreg__penalty=l2, logreg__solver=liblinear;, score=0.438 total time=   0.3s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight={0: 0.4040806125462931, 1: 21.29916167664671, 2: 6.4625, 3: 1.3310979717087044, 4: 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=1000, logreg__penalty=l1, logreg__solver=liblinear;, score=0.446 total time=  42.6s\n"
     ]
    }
   ],
   "source": [
    "# Encode the target variable.\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "print('Encoding mapping:', le.classes_)\n",
    "\n",
    "# Identify rare classes that need oversampling.\n",
    "rare_classes = [\n",
    "    label for label, count in pd.Series(y_train).value_counts().items()\n",
    "    if count < 0.05 * len(y_train)\n",
    "]\n",
    "print(\"Rare classes:\")\n",
    "for cls in rare_classes:\n",
    "    print(f\"  {cls}: {le.classes_[cls]}\")\n",
    "\n",
    "# Define column groups (this example will one-hot encode all columns, so cat_cols and num_cols are not used in the transformer).\n",
    "cat_cols = {'intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed', 'intake_hour', 'intake_year', 'primary_color', 'season', 'is_mix', 'age_group'}\n",
    "categorical_features = [col for col in X_train.columns if col in cat_cols]\n",
    "\n",
    "\n",
    "'''\n",
    "# cat_cols_freq = ['primary_color']\n",
    "\n",
    "# Frequency encode selected high-cardinality features\n",
    "for col in cat_cols_freq:\n",
    "  freq_map = X_train[col].value_counts()\n",
    "  X_train[col] = X_train[col].map(freq_map)\n",
    "  X_test[col]  = X_test[col].map(freq_map).fillna(0)\n",
    "  '''\n",
    "\n",
    "# Train the classifier with the refactored pipeline.\n",
    "\n",
    "\n",
    "best_model, test_predictions = train_logreg_classifier(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    rare_classes=rare_classes\n",
    ")\n",
    "\n",
    "# Convert predictions back to original labels.\n",
    "classification_report_with_accuracy_score(y_test, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
