{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1cfd6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nbformat in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nbformat\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55270c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad82977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/n0zzld6945vfyf6hj9_n1g4c0000gn/T/ipykernel_61979/850107665.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6582ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_classifier(X_train, y_train, X_test, rare_classes, categorical_features):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost model using SMOTE for class balancing and hyperparameter tuning.\n",
    "    CatBoost handles categorical features natively, but here we're demonstrating hyperparameter tuning with XGBoost.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training features.\n",
    "    y_train (pd.Series or np.array): Training target values.\n",
    "    X_test (pd.DataFrame): Test features.\n",
    "    rare_classes (list): List of integer-encoded classes to be oversampled with SMOTE.\n",
    "    categorical_features (list): List of column names for categorical features.\n",
    "    \n",
    "    Returns:\n",
    "        best_estimator: The best estimator from RandomizedSearchCV.\n",
    "        test_predictions: The predicted labels for X_test from the best estimator.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute rare class sampling target\n",
    "    y_series        = pd.Series(y_train)\n",
    "    max_count       = y_series.value_counts().max()\n",
    "    sampling_target = {cls: max_count for cls in rare_classes}\n",
    "\n",
    "    class_labels = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=class_labels,\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "    # Get indices of categorical features\n",
    "    cat_feature_indices = [X_train.columns.get_loc(col) for col in categorical_features]\n",
    "    \n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True)),\n",
    "        # ('smote', SMOTENC(\n",
    "        #     categorical_features=cat_feature_indices,\n",
    "        #     sampling_strategy=sampling_target,\n",
    "        #     random_state=42\n",
    "        # )),\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', verbosity=1))\n",
    "    ])\n",
    "    \n",
    "    # Expanded parameter grid for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        \"xgb__max_depth\": [2, 3, 5, 7, 9],\n",
    "        \"xgb__learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        \"xgb__n_estimators\": [50, 100, 200, 300, 500],\n",
    "        \"xgb__subsample\": [0.3, 0.5, 0.7, 1.0],\n",
    "        \"xgb__colsample_bytree\": [0.3, 0.5, 0.7, 1.0],\n",
    "        \"xgb__min_child_weight\": [1, 3, 5, 7],\n",
    "        \"xgb__gamma\": [0, 0.1, 0.3, 0.5, 1.0],\n",
    "        \"xgb__reg_alpha\": [0, 0.01, 0.1, 0.5, 1.0],\n",
    "        \"xgb__reg_lambda\": [0.5, 1.0, 1.5, 2.0, 3.0]\n",
    "    }\n",
    "    \n",
    "    stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=20,\n",
    "        cv=stratified_cv,\n",
    "        scoring='balanced_accuracy',\n",
    "        verbose=3,\n",
    "        random_state=42,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[INFO] Starting training with {len(X_train)} samples, {len(y_train)} labels\")\n",
    "    \n",
    "    # Fit the model with hyperparameter search\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    print(f\"[INFO] Training complete. Best model fitted on {len(X_train)} samples.\\n\")\n",
    "    \n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "    \n",
    "    # Assuming classification_report_with_accuracy_score is defined elsewhere\n",
    "    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=5, verbose=3, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print('Generalization accuracy (via cross_val_score):', cv_scores.mean())\n",
    "    \n",
    "    # Predict on test data\n",
    "    test_predictions = randomized_search.predict(X_test)\n",
    "    \n",
    "    return randomized_search.best_estimator_, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b302d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# df_train_downsample = resample(df_train, replace=True, n_samples=10000, random_state=42)\n",
    "# print(df_train_downsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05976deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding mapping: ['Adoption' 'Died' 'Euthanasia' 'Return to Owner' 'Transfer']\n",
      "Rare classes:\n",
      "  2: Euthanasia\n",
      "  1: Died\n",
      "Training model for Dog data:\n",
      "\n",
      "[INFO] Starting training with 111155 samples, 111155 labels\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.369 total time=  10.0s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.374 total time=   9.4s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.370 total time=   9.4s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.364 total time=  10.0s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.371 total time=   9.5s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.355 total time=   2.7s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.350 total time=   2.7s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.352 total time=   2.7s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.348 total time=   2.7s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.353 total time=   2.8s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=0.3;, score=0.375 total time=   9.5s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=0.3;, score=0.377 total time=   9.6s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=0.3;, score=0.378 total time=   9.7s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=0.3;, score=0.370 total time=   9.5s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=2, xgb__min_child_weight=7, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=0.3;, score=0.376 total time=   9.4s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.5, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.385 total time=  11.0s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.5, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.380 total time=  10.9s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.5, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.378 total time=  10.9s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.5, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.375 total time=  11.5s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.5, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.379 total time=  11.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.5, xgb__gamma=0, xgb__learning_rate=0.01, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.357 total time=   8.5s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.5, xgb__gamma=0, xgb__learning_rate=0.01, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.349 total time=   8.5s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.5, xgb__gamma=0, xgb__learning_rate=0.01, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.350 total time=   8.8s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.5, xgb__gamma=0, xgb__learning_rate=0.01, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.355 total time=   8.7s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.5, xgb__gamma=0, xgb__learning_rate=0.01, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.352 total time=   8.9s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=1.0, xgb__subsample=1.0;, score=0.392 total time=   4.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=1.0, xgb__subsample=1.0;, score=0.390 total time=   4.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=1.0, xgb__subsample=1.0;, score=0.387 total time=   4.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=1.0, xgb__subsample=1.0;, score=0.383 total time=   4.2s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=0.5, xgb__reg_lambda=1.0, xgb__subsample=1.0;, score=0.386 total time=   4.2s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=2, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__reg_alpha=0.5, xgb__reg_lambda=1.5, xgb__subsample=0.3;, score=0.349 total time=   4.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=2, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__reg_alpha=0.5, xgb__reg_lambda=1.5, xgb__subsample=0.3;, score=0.347 total time=   4.0s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=2, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__reg_alpha=0.5, xgb__reg_lambda=1.5, xgb__subsample=0.3;, score=0.347 total time=   4.2s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=2, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__reg_alpha=0.5, xgb__reg_lambda=1.5, xgb__subsample=0.3;, score=0.347 total time=   3.9s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.05, xgb__max_depth=2, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__reg_alpha=0.5, xgb__reg_lambda=1.5, xgb__subsample=0.3;, score=0.350 total time=   4.2s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7, xgb__gamma=1.0, xgb__learning_rate=0.2, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=0.5, xgb__subsample=0.3;, score=0.377 total time=   3.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7, xgb__gamma=1.0, xgb__learning_rate=0.2, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=0.5, xgb__subsample=0.3;, score=0.376 total time=   3.5s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7, xgb__gamma=1.0, xgb__learning_rate=0.2, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=0.5, xgb__subsample=0.3;, score=0.374 total time=   3.3s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7, xgb__gamma=1.0, xgb__learning_rate=0.2, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=0.5, xgb__subsample=0.3;, score=0.367 total time=   3.2s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7, xgb__gamma=1.0, xgb__learning_rate=0.2, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=0.5, xgb__subsample=0.3;, score=0.376 total time=   3.3s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.0, xgb__subsample=0.7;, score=0.325 total time=   9.7s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.0, xgb__subsample=0.7;, score=0.324 total time=   9.7s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.0, xgb__subsample=0.7;, score=0.316 total time=  10.5s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.0, xgb__subsample=0.7;, score=0.320 total time=   9.8s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.0, xgb__subsample=0.7;, score=0.313 total time=   9.9s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.5;, score=0.388 total time=  11.0s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.5;, score=0.385 total time=  10.9s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.5;, score=0.388 total time=  10.7s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.5;, score=0.384 total time=  11.2s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.3, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=3.0, xgb__subsample=0.5;, score=0.387 total time=  10.9s\n",
      "[CV 1/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.392 total time=   7.6s\n",
      "[CV 2/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.384 total time=   7.0s\n",
      "[CV 3/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.387 total time=   7.0s\n",
      "[CV 4/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.386 total time=   7.4s\n",
      "[CV 5/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=7, xgb__n_estimators=300, xgb__reg_alpha=1.0, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.389 total time=   7.2s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7, xgb__gamma=0, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.377 total time=  12.7s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7, xgb__gamma=0, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.374 total time=  12.5s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7, xgb__gamma=0, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.371 total time=  12.3s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7, xgb__gamma=0, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.367 total time=  12.4s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7, xgb__gamma=0, xgb__learning_rate=0.1, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=0.01, xgb__reg_lambda=1.5, xgb__subsample=0.7;, score=0.372 total time=  12.6s\n",
      "[CV 1/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.362 total time=   3.6s\n",
      "[CV 2/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.358 total time=   3.5s\n",
      "[CV 3/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.357 total time=   3.4s\n",
      "[CV 4/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.356 total time=   3.4s\n",
      "[CV 5/5] END xgb__colsample_bytree=1.0, xgb__gamma=1.0, xgb__learning_rate=0.01, xgb__max_depth=5, xgb__min_child_weight=3, xgb__n_estimators=100, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.362 total time=   3.5s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.391 total time=  18.5s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.390 total time=  18.5s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.389 total time=  18.6s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.384 total time=  19.5s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.1, xgb__learning_rate=0.2, xgb__max_depth=7, xgb__min_child_weight=5, xgb__n_estimators=500, xgb__reg_alpha=1.0, xgb__reg_lambda=3.0, xgb__subsample=0.7;, score=0.390 total time=  19.3s\n",
      "[CV 1/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=1.0;, score=0.394 total time=   6.5s\n",
      "[CV 2/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=1.0;, score=0.388 total time=   6.4s\n",
      "[CV 3/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=1.0;, score=0.388 total time=   6.5s\n",
      "[CV 4/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=1.0;, score=0.387 total time=   6.5s\n",
      "[CV 5/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.3, xgb__learning_rate=0.3, xgb__max_depth=9, xgb__min_child_weight=5, xgb__n_estimators=100, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=1.0;, score=0.391 total time=   6.6s\n",
      "[CV 1/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.5, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=3, xgb__n_estimators=200, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.3;, score=0.365 total time=   3.5s\n",
      "[CV 2/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.5, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=3, xgb__n_estimators=200, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.3;, score=0.357 total time=   3.5s\n",
      "[CV 3/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.5, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=3, xgb__n_estimators=200, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.3;, score=0.361 total time=   3.4s\n",
      "[CV 4/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.5, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=3, xgb__n_estimators=200, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.3;, score=0.357 total time=   3.5s\n",
      "[CV 5/5] END xgb__colsample_bytree=1.0, xgb__gamma=0.5, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=3, xgb__n_estimators=200, xgb__reg_alpha=0.1, xgb__reg_lambda=3.0, xgb__subsample=0.3;, score=0.359 total time=   3.6s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__reg_alpha=0, xgb__reg_lambda=0.5, xgb__subsample=1.0;, score=0.383 total time=   6.3s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__reg_alpha=0, xgb__reg_lambda=0.5, xgb__subsample=1.0;, score=0.382 total time=   6.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__reg_alpha=0, xgb__reg_lambda=0.5, xgb__subsample=1.0;, score=0.378 total time=   6.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__reg_alpha=0, xgb__reg_lambda=0.5, xgb__subsample=1.0;, score=0.378 total time=   6.2s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__reg_alpha=0, xgb__reg_lambda=0.5, xgb__subsample=1.0;, score=0.380 total time=   6.2s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.3, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.377 total time=   5.4s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.3, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.377 total time=   5.4s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.3, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.373 total time=   5.5s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.3, xgb__gamma=0.5, xgb__learning_rate=0.3, xgb__max_depth=2, xgb__min_child_weight=5, xgb__n_estimators=300, xgb__reg_alpha=0.01, xgb__reg_lambda=2.0, xgb__subsample=1.0;, score=0.366 total time=   5.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X_train\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cat_cols]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model for Dog data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m best_model, test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m  \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m  \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m  \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrare_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrare_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m predictions \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39minverse_transform(test_predictions)\n\u001b[1;32m     37\u001b[0m save_predictions(predictions)\n",
      "Cell \u001b[0;32mIn[23], line 83\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[0;34m(X_train, y_train, X_test, rare_classes, categorical_features)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Starting training with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Fit the model with hyperparameter search\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[43mrandomized_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Training complete. Best model fitted on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, randomized_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/pipeline.py:333\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    332\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1597\u001b[0m )\n\u001b[0;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# df_train = resample(df_train, replace=True, n_samples=25000, random_state=42)\n",
    "\n",
    "## Encode targets with LabelEncoder\n",
    "# Dog encoding\n",
    "le = LabelEncoder()\n",
    "X_train = df_train.drop(columns=['outcome_type'])\n",
    "\n",
    "y_train = df_train['outcome_type']\n",
    "y_train = le.fit_transform(y_train)\n",
    "print('Encoding mapping:', le.classes_)\n",
    "\n",
    "# Define rare classes that need oversampling \n",
    "rare_classes = [\n",
    "  label for label, count in pd.Series(y_train).value_counts().items()\n",
    "  if count < 0.05 * len(y_train)\n",
    "]\n",
    "print(\"Rare classes:\")\n",
    "for cls in rare_classes:\n",
    "  print(f\"  {cls}: {le.classes_[cls]}\")\n",
    "\n",
    "cat_cols = {'intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed', 'primary_color'}\n",
    "categorical_features = [col for col in X_train.columns if col in cat_cols]\n",
    "\n",
    "print(\"Training model for Dog data:\")\n",
    "best_model, test_predictions = train_classifier(\n",
    "  X_train=X_train,\n",
    "  y_train=y_train,\n",
    "  X_test=df_test,\n",
    "  rare_classes=rare_classes,\n",
    "  categorical_features=categorical_features\n",
    ")\n",
    "predictions = le.inverse_transform(test_predictions)\n",
    "\n",
    "save_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined test predictions saved to: ./test_xg_boost_predictions_combined.csv\n"
     ]
    }
   ],
   "source": [
    "predictions = le.inverse_transform(test_predictions)\n",
    "\n",
    "save_predictions(predictions, 'xg_boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa59f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
