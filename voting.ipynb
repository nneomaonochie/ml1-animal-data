{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1300c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5852bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /u/nneoma/.local/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1020305/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860ee9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kog_reg\n",
    "nb = nbformat.read(\"log_reg.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"log_reg_normalized.ipynb\")\n",
    "\n",
    "# Random Frest\n",
    "nb = nbformat.read(\"random_forest.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"random_forest_normalized.ipynb\")\n",
    "\n",
    "# X Random Trees\n",
    "nb = nbformat.read(\"x_random_trees.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"x_random_trees_normalized.ipynb\")\n",
    "\n",
    "# XGBoost\n",
    "nb = nbformat.read(\"xg_boost.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"xg_boost_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67690783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # Important for SMOTE compatibility\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /u/nneoma/.local/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1020428/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n",
      "Done running ml_project.ipynb.\n",
      "Encoding mapping: ['Adoption' 'Died' 'Euthanasia' 'Return to Owner' 'Transfer']\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# rerun when i make changes\n",
    "#%run log_reg.ipynb\n",
    "#%run random_forest.ipynb\n",
    "%#run x_random_trees.ipynb\n",
    "#%run xg_boost.ipynb\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_voting_classifier(X_train, y_train, X_test, models, voting='soft'):\n",
    "    \"\"\"\n",
    "    Trains a VotingClassifier with the given models and evaluates it on the test data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels\n",
    "    - X_test: Test features\n",
    "    - models: List of tuples (model_name, model_instance)\n",
    "    - voting: 'hard' or 'soft' for the type of voting to be used (default is 'soft')\n",
    "    \n",
    "    Returns:\n",
    "    - trained_model: Trained VotingClassifier\n",
    "    - test_predictions: Predictions on the test set\n",
    "    \"\"\"\n",
    "    # Initialize the VotingClassifier with the given models\n",
    "    voting_clf = VotingClassifier(estimators=models, voting=voting, n_jobs=-1)\n",
    "    \n",
    "    # Fit the model\n",
    "    voting_clf.fit(X_train, y_train) #   voting_clf.fit_transform(X_test,)\n",
    "    \n",
    "    # Make predictions\n",
    "    test_predictions = voting_clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = balanced_accuracy_score(y_train, voting_clf.predict(X_train))\n",
    "    print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return voting_clf, test_predictions\n",
    "\n",
    "# needs CV loop after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a1555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "0            Stray  Normal / Behavior         Dog   Spayed Female   \n",
       "1            Stray  Normal / Behavior         Dog     Intact Male   \n",
       "2    Public Assist  Normal / Behavior         Cat   Neutered Male   \n",
       "3  Owner Surrender  Normal / Behavior         Dog   Neutered Male   \n",
       "4    Public Assist  Normal / Behavior         Dog   Neutered Male   \n",
       "\n",
       "   age_upon_intake  breed  intake_year primary_color  is_mix     outcome_type  \\\n",
       "0             96.0      2         2015     non-black       0  Return to Owner   \n",
       "1             11.0      7         2016     non-black       1  Return to Owner   \n",
       "2             24.0      9         2022     non-black       0         Transfer   \n",
       "3             24.0      2         2017     non-black       1  Return to Owner   \n",
       "4             72.0      3         2019         black       1  Return to Owner   \n",
       "\n",
       "   season time_of_day  \n",
       "0  Summer   Afternoon  \n",
       "1  Spring     Evening  \n",
       "2  Spring       Night  \n",
       "3  Winter   Afternoon  \n",
       "4  Spring     Morning  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = bucket_seasons(df_train)\n",
    "df_test = bucket_seasons(df_test)\n",
    "\n",
    "df_train = bucket_days(df_train)\n",
    "df_test = bucket_days(df_test)\n",
    "\n",
    "df_train['breed'] = df_train['breed'].astype(str)\n",
    "df_test['breed'] = df_test['breed'].astype(str)\n",
    "\n",
    "df_train = df_train.drop(columns=['size', 'intake_hour', 'intake_month'])\n",
    "df_test = df_test.drop(columns=['size', 'intake_hour', 'intake_month'])\n",
    "\n",
    "\n",
    "\n",
    "# breed is encoded, but dont fret\n",
    "def encode_breed(val):\n",
    "    if isinstance(val, int):\n",
    "        return val  # Keep numeric as-is\n",
    "    mapping = {'0' : 0, '1' : 1, '2' : 2, '3' : 3, '4' : 4, '5' : 5, '6' : 6, '7' : 7, '8' : 8, 'Common': 9, 'Rare': 10, 'Unknown': 11}\n",
    "    return mapping.get(val, -1)  # Return -1 for unexpected values (or handle as needed)\n",
    "\n",
    "# Apply transformation\n",
    "df_train['breed'] = df_train['breed'].apply(encode_breed)\n",
    "df_test['breed'] = df_test['breed'].apply(encode_breed)\n",
    "\n",
    "\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a661c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breed\n",
       "9     47258\n",
       "4     13754\n",
       "0     13398\n",
       "2      9803\n",
       "5      9663\n",
       "3      6505\n",
       "7      4240\n",
       "10     2569\n",
       "8      2163\n",
       "1      1785\n",
       "6        15\n",
       "11        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['outcome_type'])\n",
    "y = df_train['outcome_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# This is just used to get the model with the best classifiers\\nmodels = [\\n    ('logreg', train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0]), #logistic regression\\n    ('rf', train_RF_classifier(X_train, y_train, X_test, cat_cols)[0]), #random forest\\n    ('xrt', train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0]) #x random trees\\n]\\n\\n# Assuming X_train, y_train, X_test are already defined in your environment\\nvoting_model, test_predictions = train_voting_classifier(X_train, y_train, X_test, models, voting='soft')\\n\\nclassification_report_with_accuracy_score(y_test, test_predictions)\\n\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed','season', 'is_mix', 'time_of_day', 'primary_color'] # experimenting with droping color\n",
    "num_cols = ['age_upon_intake', 'intake_year']    # Replace with your actual numerical columns\n",
    "# freq_cols = ['primary_color'] # for trees\n",
    "\n",
    "'''\n",
    "# This is just used to get the model with the best classifiers\n",
    "models = [\n",
    "    ('logreg', train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0]), #logistic regression\n",
    "    ('rf', train_RF_classifier(X_train, y_train, X_test, cat_cols)[0]), #random forest\n",
    "    ('xrt', train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0]) #x random trees\n",
    "]\n",
    "\n",
    "# Assuming X_train, y_train, X_test are already defined in your environment\n",
    "voting_model, test_predictions = train_voting_classifier(X_train, y_train, X_test, models, voting='soft')\n",
    "\n",
    "classification_report_with_accuracy_score(y_test, test_predictions)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107615</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79497</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88489</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "107615          Stray  Normal / Behavior         Cat   Intact Female   \n",
       "13002           Stray            Injured         Dog     Intact Male   \n",
       "32513   Public Assist  Normal / Behavior         Dog   Intact Female   \n",
       "79497           Stray  Normal / Behavior         Cat   Intact Female   \n",
       "88489           Stray  Normal / Behavior         Dog   Intact Female   \n",
       "\n",
       "        age_upon_intake  breed  intake_year primary_color  is_mix  season  \\\n",
       "107615              1.0      9         2021     non-black       0  Summer   \n",
       "13002              24.0      3         2014     non-black       1  Summer   \n",
       "32513              12.0      4         2019     non-black       1  Summer   \n",
       "79497               1.0      9         2015     non-black       1  Summer   \n",
       "88489               4.0      2         2017         black       0  Spring   \n",
       "\n",
       "       time_of_day  \n",
       "107615     Morning  \n",
       "13002      Morning  \n",
       "32513        Night  \n",
       "79497      Evening  \n",
       "88489      Morning  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb469c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvoting_clf = VotingClassifier(\\n    estimators=[\\n        (\\'xgb\\', xgb_model),      # best XGBoost model\\n        (\\'cat\\', catboost_model), # best CatBoost model\\n        (\\'logreg\\', log_reg_model),\\n        (\\'rf\\', rf_model),\\n        (\\'nb\\', nb_model)\\n    ],\\n    voting=\\'soft\\',\\n  #  weights=[3, 2.5, 2, 1.5, 1],  # optional: weight more accurate models\\n    n_jobs=-1\\n)\\n\\nvoting_clf.fit(X_train, y_train)\\ny_pred = voting_clf.predict(X_test)\\n\\n# Evaluate\\nfrom sklearn.metrics import balanced_accuracy_score\\nprint(\"Ensemble Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming these are pipelines or models you've already trained/tuned\n",
    "'''\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),      # best XGBoost model\n",
    "        ('cat', catboost_model), # best CatBoost model\n",
    "        ('logreg', log_reg_model),\n",
    "        ('rf', rf_model),\n",
    "        ('nb', nb_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "  #  weights=[3, 2.5, 2, 1.5, 1],  # optional: weight more accurate models\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(\"Ensemble Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15630e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for extra valdiation to find the best thresholds to maximize recall per class\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.475 total time=   1.9s\n",
      "[CV 2/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   1.0s\n",
      "[CV 3/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.448 total time= 1.9min\n",
      "[CV 5/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   1.9s\n",
      "[CV 1/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   2.0s\n",
      "[CV 2/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.454 total time=   2.0s\n",
      "[CV 3/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.458 total time=   1.9s\n",
      "[CV 4/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.455 total time=   1.8s\n",
      "[CV 5/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.470 total time=   1.9s\n",
      "[CV 1/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.477 total time=   0.6s\n",
      "[CV 2/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   0.6s\n",
      "[CV 3/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   0.6s\n",
      "[CV 4/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   1.0s\n",
      "[CV 5/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.465 total time=   0.7s\n",
      "[CV 1/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.477 total time=   0.6s\n",
      "[CV 2/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   0.6s\n",
      "[CV 3/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   0.5s\n",
      "[CV 4/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   0.9s\n",
      "[CV 5/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.465 total time=   0.5s\n",
      "[CV 1/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.476 total time=   4.6s\n",
      "[CV 2/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.452 total time=   4.8s\n",
      "[CV 3/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.456 total time=   4.9s\n",
      "[CV 4/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.453 total time=   4.3s\n",
      "[CV 5/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.465 total time=   4.5s\n",
      "[CV 1/5] END logreg__C=0.6216531604882809, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   1.9s\n",
      "[CV 2/5] END logreg__C=0.6216531604882809, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.454 total time=   2.2s\n",
      "[CV 3/5] END logreg__C=0.6216531604882809, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.458 total time=   2.0s\n",
      "[CV 4/5] END logreg__C=0.6216531604882809, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.455 total time=   2.0s\n",
      "[CV 5/5] END logreg__C=0.6216531604882809, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.470 total time=   1.9s\n",
      "[CV 1/5] END logreg__C=0.5347746602583892, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.475 total time=   2.1s\n",
      "[CV 2/5] END logreg__C=0.5347746602583892, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   1.1s\n",
      "[CV 3/5] END logreg__C=0.5347746602583892, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=0.5347746602583892, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.441 total time= 1.9min\n",
      "[CV 5/5] END logreg__C=0.5347746602583892, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   1.2s\n",
      "[CV 1/5] END logreg__C=0.1006064345328208, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.477 total time=   0.7s\n",
      "[CV 2/5] END logreg__C=0.1006064345328208, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   0.6s\n",
      "[CV 3/5] END logreg__C=0.1006064345328208, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   0.6s\n",
      "[CV 4/5] END logreg__C=0.1006064345328208, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.453 total time=   0.9s\n",
      "[CV 5/5] END logreg__C=0.1006064345328208, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.465 total time=   0.7s\n",
      "[CV 1/5] END logreg__C=0.6024145688620425, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   3.9s\n",
      "[CV 2/5] END logreg__C=0.6024145688620425, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.454 total time=   3.7s\n",
      "[CV 3/5] END logreg__C=0.6024145688620425, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.458 total time=   3.6s\n",
      "[CV 4/5] END logreg__C=0.6024145688620425, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.454 total time=   3.9s\n",
      "[CV 5/5] END logreg__C=0.6024145688620425, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.470 total time=   3.4s\n",
      "[CV 1/5] END logreg__C=0.18052412368729154, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.475 total time=   0.6s\n",
      "[CV 2/5] END logreg__C=0.18052412368729154, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.454 total time=   0.7s\n",
      "[CV 3/5] END logreg__C=0.18052412368729154, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   0.6s\n",
      "[CV 4/5] END logreg__C=0.18052412368729154, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.455 total time=   1.2s\n",
      "[CV 5/5] END logreg__C=0.18052412368729154, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   0.8s\n",
      "Best parameters: {'logreg__C': 0.6216531604882809, 'logreg__class_weight': {0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, 'logreg__fit_intercept': False, 'logreg__max_iter': 7000, 'logreg__penalty': 'l2', 'logreg__solver': 'lbfgs'}\n",
      "Best cross-validation accuracy: 0.4623366007339046\n",
      "[CV] END ................................ score: (test=0.462) total time=   2.0s\n",
      "[CV] END ................................ score: (test=0.465) total time=   1.9s\n",
      "[CV] END ................................ score: (test=0.471) total time=   1.9s\n",
      "[CV] END ................................ score: (test=0.460) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.446) total time=   2.0s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.46080181770503986\n",
      "Class weights: {0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}\n",
      "\n",
      "[INFO] Starting training with 71139 samples\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.5s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   4.0s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   2.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   2.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   4.0s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   5.5s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   6.9s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   7.2s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   7.4s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   6.6s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.6s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.9s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[INFO] Training complete.\n",
      "Best parameters: {'rf__n_estimators': 100, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10}\n",
      "Best CV accuracy: 0.44665741590229596\n",
      "[CV] END ................................ score: (test=0.455) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.445) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.444) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.439) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.450) total time=   0.6s\n",
      "Generalization accuracy (via cross_val_score): 0.44665741590229596\n",
      "Class weights: {0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.7s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.4s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.6s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   2.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   3.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.1s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.1s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.1s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   1.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   1.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   3.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   7.5s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   8.8s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   8.9s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   8.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   2.5s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   7.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   0.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   0.7s\n",
      "Best parameters: {'xrt__n_estimators': 100, 'xrt__min_samples_split': 2, 'xrt__min_samples_leaf': 4, 'xrt__max_depth': 10}\n",
      "Best cross-validation accuracy: 0.4479603771348005\n",
      "[CV] END ................................ score: (test=0.457) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.449) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.439) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.443) total time=   0.6s\n",
      "[CV] END ................................ score: (test=0.451) total time=   0.6s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.4479603771348005\n",
      "\n",
      "[INFO] Starting training with 71139 samples and 71139 labels\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=0.520 total time= 4.7min\n",
      "[CV 2/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=0.488 total time= 4.5min\n",
      "[CV 3/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=0.496 total time= 4.4min\n",
      "[CV 4/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=0.504 total time= 4.5min\n",
      "[CV 5/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=0.526 total time= 4.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m rf_CV \u001b[38;5;241m=\u001b[39m train_RF_classifier(X_train_sub, y_train_sub, X_val, cat_cols)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m xrt_CV \u001b[38;5;241m=\u001b[39m train_XRT_classifier(X_train_sub, y_train_sub, X_val, cat_cols)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m xg \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_XG_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get predicted probabilities on validation set\u001b[39;00m\n\u001b[1;32m     10\u001b[0m log_probs_CV \u001b[38;5;241m=\u001b[39m logreg_CV\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m/tmp/ipykernel_1004801/1222623626.py:79\u001b[0m, in \u001b[0;36mtrain_XG_classifier\u001b[0;34m(X_train, y_train, X_test, rare_classes, cat_cols, custom_thresholds)\u001b[0m\n\u001b[1;32m     68\u001b[0m randomized_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     69\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     70\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Starting training with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mrandomized_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb__sample_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Training complete. Best model fitted on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Show sample transformed training features\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:738\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    737\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1597\u001b[0m )\n\u001b[0;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:738\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    737\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:2113\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m     _check_call(\n\u001b[0;32m-> 2113\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2116\u001b[0m     )\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2118\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "# Train on sub-training set\n",
    "logreg_CV = train_logreg_classifier(X_train_sub, y_train_sub, X_val, cat_cols, num_cols)[0]\n",
    "rf_CV = train_RF_classifier(X_train_sub, y_train_sub, X_val, cat_cols)[0]\n",
    "xrt_CV = train_XRT_classifier(X_train_sub, y_train_sub, X_val, cat_cols)[0]\n",
    "xg = train_XG_classifier(X_train_sub, y_train_sub, X_val, [], cat_cols)[0]\n",
    "\n",
    "# Get predicted probabilities on validation set\n",
    "log_probs_CV = logreg_CV.predict_proba(X_test)\n",
    "rf_probs_CV = rf_CV.predict_proba(X_test)\n",
    "xrt_probs_CV = xrt_CV.predict_proba(X_test)\n",
    "xg_probs_CV = xg.predict_proba(X_test)\n",
    "\n",
    "# Average the probabilities\n",
    "avg_probs_val = (log_probs_CV + rf_probs_CV + xrt_probs_CV + xg_probs_CV) / 4\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# Define classes (adjust as needed)\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Threshold options for each class\n",
    "threshold_grid = {\n",
    "    0: [0.5, 0.6, 0.7, 0.8],\n",
    "    1: [0.05, 0.1, 0.2],\n",
    "    2: [0.1, 0.2, 0.3],\n",
    "    3: [0.2, 0.3, 0.4],\n",
    "    4: [0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "# Generate all threshold combinations\n",
    "all_thresholds = list(product(*threshold_grid.values()))\n",
    "\n",
    "# Tune thresholds\n",
    "best_score = -1\n",
    "best_thresholds = None\n",
    "\n",
    "for thresh_combo in all_thresholds:\n",
    "    thresholds = dict(zip(classes, thresh_combo))\n",
    "    preds = []\n",
    "\n",
    "    for probs in avg_probs_val:\n",
    "        passed = [cls for cls, prob in enumerate(probs) if prob >= thresholds.get(cls, 1.0)]\n",
    "        if passed:\n",
    "            chosen = max(passed, key=lambda cls: probs[cls])\n",
    "        else:\n",
    "            chosen = np.argmax(probs)\n",
    "        preds.append(chosen)\n",
    "\n",
    "    score = balanced_accuracy_score(y_val, preds)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_thresholds = thresholds\n",
    "\n",
    "print(\"Best thresholds:\", best_thresholds)\n",
    "print(\"Best balanced accuracy on validation:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43691d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "0            Stray  Normal / Behavior         Dog   Spayed Female   \n",
       "1            Stray  Normal / Behavior         Dog     Intact Male   \n",
       "2    Public Assist  Normal / Behavior         Cat   Neutered Male   \n",
       "3  Owner Surrender  Normal / Behavior         Dog   Neutered Male   \n",
       "4    Public Assist  Normal / Behavior         Dog   Neutered Male   \n",
       "\n",
       "   age_upon_intake  breed  intake_year primary_color  is_mix     outcome_type  \\\n",
       "0             96.0     -1         2015     non-black       0  Return to Owner   \n",
       "1             11.0     -1         2016     non-black       1  Return to Owner   \n",
       "2             24.0      9         2022     non-black       0         Transfer   \n",
       "3             24.0     -1         2017     non-black       1  Return to Owner   \n",
       "4             72.0     -1         2019         black       1  Return to Owner   \n",
       "\n",
       "   season time_of_day  \n",
       "0  Summer   Afternoon  \n",
       "1  Spring     Evening  \n",
       "2  Spring       Night  \n",
       "3  Winter   Afternoon  \n",
       "4  Spring     Morning  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084a9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.474 total time=   8.0s\n",
      "[CV 2/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.451 total time=   8.3s\n",
      "[CV 3/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.462 total time=   8.8s\n",
      "[CV 4/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   8.3s\n",
      "[CV 5/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time= 1.5min\n",
      "[CV 1/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.474 total time=   7.8s\n",
      "[CV 2/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.451 total time=   6.3s\n",
      "[CV 3/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.463 total time=   6.1s\n",
      "[CV 4/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.458 total time=   5.2s\n",
      "[CV 5/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.469 total time=   5.2s\n",
      "[CV 1/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.474 total time=   3.2s\n",
      "[CV 2/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.451 total time=   3.2s\n",
      "[CV 3/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.463 total time=   3.2s\n",
      "[CV 4/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   3.2s\n",
      "[CV 5/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.469 total time=   3.1s\n",
      "[CV 1/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.474 total time=   1.8s\n",
      "[CV 2/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.451 total time=   1.8s\n",
      "[CV 3/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.462 total time=   1.8s\n",
      "[CV 4/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   1.8s\n",
      "[CV 5/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.469 total time=   2.1s\n",
      "[CV 1/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.472 total time=   1.9s\n",
      "[CV 2/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.451 total time=   1.8s\n",
      "[CV 3/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.462 total time=   1.7s\n",
      "[CV 4/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.457 total time=   2.0s\n",
      "[CV 5/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.468 total time=   2.6s\n",
      "Best parameters: {'logreg__C': 0.3845401188473625, 'logreg__class_weight': {'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}, 'logreg__fit_intercept': True, 'logreg__max_iter': 8000, 'logreg__penalty': 'l2', 'logreg__solver': 'saga'}\n",
      "Best cross-validation accuracy: 0.463021665439705\n",
      "[CV] END ................................ score: (test=0.456) total time=   8.4s\n",
      "[CV] END ................................ score: (test=0.471) total time=   8.2s\n",
      "[CV] END ................................ score: (test=0.475) total time=   7.7s\n",
      "[CV] END ................................ score: (test=0.468) total time=   8.0s\n",
      "[CV] END ................................ score: (test=0.453) total time=   8.6s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.46431202805445826\n",
      "Class weights: {'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}\n",
      "\n",
      "[INFO] Starting training with 111155 samples\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   4.1s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   4.3s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   4.2s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   4.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   3.5s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   4.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.6s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.9s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   3.3s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   3.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   3.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   3.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   4.3s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=  10.0s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=  11.3s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=  11.5s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=  11.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   3.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   9.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.4s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.4s\n",
      "[INFO] Training complete.\n",
      "Best parameters: {'rf__n_estimators': 200, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10}\n",
      "Best CV accuracy: 0.4547649853473935\n",
      "[CV] END ................................ score: (test=0.462) total time=   1.7s\n",
      "[CV] END ................................ score: (test=0.455) total time=   1.7s\n",
      "[CV] END ................................ score: (test=0.446) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.454) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.456) total time=   1.7s\n",
      "Generalization accuracy (via cross_val_score): 0.4547649853473935\n",
      "Class weights: {'Adoption': 0.40387689848121505, 'Died': 21.35542747358309, 'Euthanasia': 6.445636416352566, 'Return to Owner': 1.3394589383623547, 'Transfer': 0.6347361809045227}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   6.6s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   6.9s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   6.8s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   6.8s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   3.9s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.7s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.5s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.7s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.6s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.6s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   3.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   3.4s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   3.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   3.6s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  12.7s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  13.3s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  13.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  13.5s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   3.6s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  10.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   2.8s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.6s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.1s\n",
      "Best parameters: {'xrt__n_estimators': 200, 'xrt__min_samples_split': 5, 'xrt__min_samples_leaf': 4, 'xrt__max_depth': 10}\n",
      "Best cross-validation accuracy: 0.4557440850345274\n",
      "[CV] END ................................ score: (test=0.461) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.457) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.446) total time=   1.7s\n",
      "[CV] END ................................ score: (test=0.456) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.458) total time=   1.7s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.4557440850345274\n",
      "\n",
      "[INFO] Starting training with 111155 samples and 111155 labels\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.5621780831931538, xgb__gamma=0.9507143064099162, xgb__learning_rate=0.22227824312530747, xgb__max_depth=6, xgb__min_child_weight=7, xgb__n_estimators=171, xgb__reg_alpha=0.15599452033620265, xgb__reg_lambda=0.6452090304204987, xgb__subsample=0.9063233020424546;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7207805082202461, xgb__gamma=0.7080725777960455, xgb__learning_rate=0.01596950334578271, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=463, xgb__reg_alpha=0.21233911067827616, xgb__reg_lambda=0.9545624180177515, xgb__subsample=0.4283831568974037;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7207805082202461, xgb__gamma=0.7080725777960455, xgb__learning_rate=0.01596950334578271, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=463, xgb__reg_alpha=0.21233911067827616, xgb__reg_lambda=0.9545624180177515, xgb__subsample=0.4283831568974037;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7207805082202461, xgb__gamma=0.7080725777960455, xgb__learning_rate=0.01596950334578271, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=463, xgb__reg_alpha=0.21233911067827616, xgb__reg_lambda=0.9545624180177515, xgb__subsample=0.4283831568974037;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7207805082202461, xgb__gamma=0.7080725777960455, xgb__learning_rate=0.01596950334578271, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=463, xgb__reg_alpha=0.21233911067827616, xgb__reg_lambda=0.9545624180177515, xgb__subsample=0.4283831568974037;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7207805082202461, xgb__gamma=0.7080725777960455, xgb__learning_rate=0.01596950334578271, xgb__max_depth=3, xgb__min_child_weight=4, xgb__n_estimators=463, xgb__reg_alpha=0.21233911067827616, xgb__reg_lambda=0.9545624180177515, xgb__subsample=0.4283831568974037;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.5129695700716763, xgb__gamma=0.5247564316322378, xgb__learning_rate=0.13526405540621358, xgb__max_depth=2, xgb__min_child_weight=3, xgb__n_estimators=108, xgb__reg_alpha=0.3998609717152555, xgb__reg_lambda=0.6166641580340386, xgb__subsample=0.9816288631890213;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.5129695700716763, xgb__gamma=0.5247564316322378, xgb__learning_rate=0.13526405540621358, xgb__max_depth=2, xgb__min_child_weight=3, xgb__n_estimators=108, xgb__reg_alpha=0.3998609717152555, xgb__reg_lambda=0.6166641580340386, xgb__subsample=0.9816288631890213;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.5129695700716763, xgb__gamma=0.5247564316322378, xgb__learning_rate=0.13526405540621358, xgb__max_depth=2, xgb__min_child_weight=3, xgb__n_estimators=108, xgb__reg_alpha=0.3998609717152555, xgb__reg_lambda=0.6166641580340386, xgb__subsample=0.9816288631890213;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.5129695700716763, xgb__gamma=0.5247564316322378, xgb__learning_rate=0.13526405540621358, xgb__max_depth=2, xgb__min_child_weight=3, xgb__n_estimators=108, xgb__reg_alpha=0.3998609717152555, xgb__reg_lambda=0.6166641580340386, xgb__subsample=0.9816288631890213;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.5129695700716763, xgb__gamma=0.5247564316322378, xgb__learning_rate=0.13526405540621358, xgb__max_depth=2, xgb__min_child_weight=3, xgb__n_estimators=108, xgb__reg_alpha=0.3998609717152555, xgb__reg_lambda=0.6166641580340386, xgb__subsample=0.9816288631890213;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.46293993830121294, xgb__gamma=0.0906064345328208, xgb__learning_rate=0.1893319427065953, xgb__max_depth=8, xgb__min_child_weight=4, xgb__n_estimators=369, xgb__reg_alpha=0.4667628932479799, xgb__reg_lambda=2.6498510168408016, xgb__subsample=0.7762152770114458;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.46293993830121294, xgb__gamma=0.0906064345328208, xgb__learning_rate=0.1893319427065953, xgb__max_depth=8, xgb__min_child_weight=4, xgb__n_estimators=369, xgb__reg_alpha=0.4667628932479799, xgb__reg_lambda=2.6498510168408016, xgb__subsample=0.7762152770114458;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.46293993830121294, xgb__gamma=0.0906064345328208, xgb__learning_rate=0.1893319427065953, xgb__max_depth=8, xgb__min_child_weight=4, xgb__n_estimators=369, xgb__reg_alpha=0.4667628932479799, xgb__reg_lambda=2.6498510168408016, xgb__subsample=0.7762152770114458;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.46293993830121294, xgb__gamma=0.0906064345328208, xgb__learning_rate=0.1893319427065953, xgb__max_depth=8, xgb__min_child_weight=4, xgb__n_estimators=369, xgb__reg_alpha=0.4667628932479799, xgb__reg_lambda=2.6498510168408016, xgb__subsample=0.7762152770114458;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.46293993830121294, xgb__gamma=0.0906064345328208, xgb__learning_rate=0.1893319427065953, xgb__max_depth=8, xgb__min_child_weight=4, xgb__n_estimators=369, xgb__reg_alpha=0.4667628932479799, xgb__reg_lambda=2.6498510168408016, xgb__subsample=0.7762152770114458;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.61534947637868, xgb__gamma=0.013264961159866528, xgb__learning_rate=0.28323850914860726, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=314, xgb__reg_alpha=0.015966252220214194, xgb__reg_lambda=1.0772345640553724, xgb__subsample=0.4687178262182082;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.61534947637868, xgb__gamma=0.013264961159866528, xgb__learning_rate=0.28323850914860726, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=314, xgb__reg_alpha=0.015966252220214194, xgb__reg_lambda=1.0772345640553724, xgb__subsample=0.4687178262182082;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.61534947637868, xgb__gamma=0.013264961159866528, xgb__learning_rate=0.28323850914860726, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=314, xgb__reg_alpha=0.015966252220214194, xgb__reg_lambda=1.0772345640553724, xgb__subsample=0.4687178262182082;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.61534947637868, xgb__gamma=0.013264961159866528, xgb__learning_rate=0.28323850914860726, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=314, xgb__reg_alpha=0.015966252220214194, xgb__reg_lambda=1.0772345640553724, xgb__subsample=0.4687178262182082;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.61534947637868, xgb__gamma=0.013264961159866528, xgb__learning_rate=0.28323850914860726, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=314, xgb__reg_alpha=0.015966252220214194, xgb__reg_lambda=1.0772345640553724, xgb__subsample=0.4687178262182082;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7782844631778207, xgb__gamma=0.6099966577826209, xgb__learning_rate=0.25162652440348765, xgb__max_depth=4, xgb__min_child_weight=6, xgb__n_estimators=130, xgb__reg_alpha=0.2587799816000169, xgb__reg_lambda=2.156305710884955, xgb__subsample=0.5181977532625877;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7782844631778207, xgb__gamma=0.6099966577826209, xgb__learning_rate=0.25162652440348765, xgb__max_depth=4, xgb__min_child_weight=6, xgb__n_estimators=130, xgb__reg_alpha=0.2587799816000169, xgb__reg_lambda=2.156305710884955, xgb__subsample=0.5181977532625877;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7782844631778207, xgb__gamma=0.6099966577826209, xgb__learning_rate=0.25162652440348765, xgb__max_depth=4, xgb__min_child_weight=6, xgb__n_estimators=130, xgb__reg_alpha=0.2587799816000169, xgb__reg_lambda=2.156305710884955, xgb__subsample=0.5181977532625877;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7782844631778207, xgb__gamma=0.6099966577826209, xgb__learning_rate=0.25162652440348765, xgb__max_depth=4, xgb__min_child_weight=6, xgb__n_estimators=130, xgb__reg_alpha=0.2587799816000169, xgb__reg_lambda=2.156305710884955, xgb__subsample=0.5181977532625877;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7782844631778207, xgb__gamma=0.6099966577826209, xgb__learning_rate=0.25162652440348765, xgb__max_depth=4, xgb__min_child_weight=6, xgb__n_estimators=130, xgb__reg_alpha=0.2587799816000169, xgb__reg_lambda=2.156305710884955, xgb__subsample=0.5181977532625877;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.6640476148244676, xgb__gamma=0.5467102793432796, xgb__learning_rate=0.06360779210240283, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=93, xgb__reg_alpha=0.9394989415641891, xgb__reg_lambda=2.737068376069122, xgb__subsample=0.7185299851677596;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.6640476148244676, xgb__gamma=0.5467102793432796, xgb__learning_rate=0.06360779210240283, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=93, xgb__reg_alpha=0.9394989415641891, xgb__reg_lambda=2.737068376069122, xgb__subsample=0.7185299851677596;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.6640476148244676, xgb__gamma=0.5467102793432796, xgb__learning_rate=0.06360779210240283, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=93, xgb__reg_alpha=0.9394989415641891, xgb__reg_lambda=2.737068376069122, xgb__subsample=0.7185299851677596;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.6640476148244676, xgb__gamma=0.5467102793432796, xgb__learning_rate=0.06360779210240283, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=93, xgb__reg_alpha=0.9394989415641891, xgb__reg_lambda=2.737068376069122, xgb__subsample=0.7185299851677596;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.6640476148244676, xgb__gamma=0.5467102793432796, xgb__learning_rate=0.06360779210240283, xgb__max_depth=3, xgb__min_child_weight=2, xgb__n_estimators=93, xgb__reg_alpha=0.9394989415641891, xgb__reg_lambda=2.737068376069122, xgb__subsample=0.7185299851677596;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.9453119645161818, xgb__gamma=0.0884925020519195, xgb__learning_rate=0.0668350301015521, xgb__max_depth=10, xgb__min_child_weight=6, xgb__n_estimators=345, xgb__reg_alpha=0.8445338486781514, xgb__reg_lambda=2.368300275343452, xgb__subsample=0.6777844926723557;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.9453119645161818, xgb__gamma=0.0884925020519195, xgb__learning_rate=0.0668350301015521, xgb__max_depth=10, xgb__min_child_weight=6, xgb__n_estimators=345, xgb__reg_alpha=0.8445338486781514, xgb__reg_lambda=2.368300275343452, xgb__subsample=0.6777844926723557;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.9453119645161818, xgb__gamma=0.0884925020519195, xgb__learning_rate=0.0668350301015521, xgb__max_depth=10, xgb__min_child_weight=6, xgb__n_estimators=345, xgb__reg_alpha=0.8445338486781514, xgb__reg_lambda=2.368300275343452, xgb__subsample=0.6777844926723557;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.9453119645161818, xgb__gamma=0.0884925020519195, xgb__learning_rate=0.0668350301015521, xgb__max_depth=10, xgb__min_child_weight=6, xgb__n_estimators=345, xgb__reg_alpha=0.8445338486781514, xgb__reg_lambda=2.368300275343452, xgb__subsample=0.6777844926723557;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.9453119645161818, xgb__gamma=0.0884925020519195, xgb__learning_rate=0.0668350301015521, xgb__max_depth=10, xgb__min_child_weight=6, xgb__n_estimators=345, xgb__reg_alpha=0.8445338486781514, xgb__reg_lambda=2.368300275343452, xgb__subsample=0.6777844926723557;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.7107258159646936, xgb__gamma=0.965255307264138, xgb__learning_rate=0.18603993182913856, xgb__max_depth=10, xgb__min_child_weight=5, xgb__n_estimators=64, xgb__reg_alpha=0.1652669390630025, xgb__reg_lambda=0.5390910168529848, xgb__subsample=0.5963810364944587;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.7107258159646936, xgb__gamma=0.965255307264138, xgb__learning_rate=0.18603993182913856, xgb__max_depth=10, xgb__min_child_weight=5, xgb__n_estimators=64, xgb__reg_alpha=0.1652669390630025, xgb__reg_lambda=0.5390910168529848, xgb__subsample=0.5963810364944587;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.7107258159646936, xgb__gamma=0.965255307264138, xgb__learning_rate=0.18603993182913856, xgb__max_depth=10, xgb__min_child_weight=5, xgb__n_estimators=64, xgb__reg_alpha=0.1652669390630025, xgb__reg_lambda=0.5390910168529848, xgb__subsample=0.5963810364944587;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.7107258159646936, xgb__gamma=0.965255307264138, xgb__learning_rate=0.18603993182913856, xgb__max_depth=10, xgb__min_child_weight=5, xgb__n_estimators=64, xgb__reg_alpha=0.1652669390630025, xgb__reg_lambda=0.5390910168529848, xgb__subsample=0.5963810364944587;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.7107258159646936, xgb__gamma=0.965255307264138, xgb__learning_rate=0.18603993182913856, xgb__max_depth=10, xgb__min_child_weight=5, xgb__n_estimators=64, xgb__reg_alpha=0.1652669390630025, xgb__reg_lambda=0.5390910168529848, xgb__subsample=0.5963810364944587;, score=nan total time=   0.1s\n",
      "[CV 1/5] END xgb__colsample_bytree=0.5764170627228988, xgb__gamma=0.2934881747180381, xgb__learning_rate=0.014083148587374493, xgb__max_depth=4, xgb__min_child_weight=1, xgb__n_estimators=441, xgb__reg_alpha=0.7290071680409873, xgb__reg_lambda=2.4281758667148643, xgb__subsample=0.35183125621386324;, score=nan total time=   0.1s\n",
      "[CV 2/5] END xgb__colsample_bytree=0.5764170627228988, xgb__gamma=0.2934881747180381, xgb__learning_rate=0.014083148587374493, xgb__max_depth=4, xgb__min_child_weight=1, xgb__n_estimators=441, xgb__reg_alpha=0.7290071680409873, xgb__reg_lambda=2.4281758667148643, xgb__subsample=0.35183125621386324;, score=nan total time=   0.1s\n",
      "[CV 3/5] END xgb__colsample_bytree=0.5764170627228988, xgb__gamma=0.2934881747180381, xgb__learning_rate=0.014083148587374493, xgb__max_depth=4, xgb__min_child_weight=1, xgb__n_estimators=441, xgb__reg_alpha=0.7290071680409873, xgb__reg_lambda=2.4281758667148643, xgb__subsample=0.35183125621386324;, score=nan total time=   0.1s\n",
      "[CV 4/5] END xgb__colsample_bytree=0.5764170627228988, xgb__gamma=0.2934881747180381, xgb__learning_rate=0.014083148587374493, xgb__max_depth=4, xgb__min_child_weight=1, xgb__n_estimators=441, xgb__reg_alpha=0.7290071680409873, xgb__reg_lambda=2.4281758667148643, xgb__subsample=0.35183125621386324;, score=nan total time=   0.1s\n",
      "[CV 5/5] END xgb__colsample_bytree=0.5764170627228988, xgb__gamma=0.2934881747180381, xgb__learning_rate=0.014083148587374493, xgb__max_depth=4, xgb__min_child_weight=1, xgb__n_estimators=441, xgb__reg_alpha=0.7290071680409873, xgb__reg_lambda=2.4281758667148643, xgb__subsample=0.35183125621386324;, score=nan total time=   0.1s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n50 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 427, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/xgboost/core.py\", line 738, in inner_f\n    return func(**kwargs)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1559, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['Adoption' 'Died' 'Euthanasia' 'Return to Owner' 'Transfer']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m rf \u001b[38;5;241m=\u001b[39m train_RF_classifier(df_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome_type\u001b[39m\u001b[38;5;124m'\u001b[39m]), df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome_type\u001b[39m\u001b[38;5;124m'\u001b[39m], df_test, cat_cols)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#random forest\u001b[39;00m\n\u001b[1;32m      6\u001b[0m xrt \u001b[38;5;241m=\u001b[39m train_XRT_classifier(df_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome_type\u001b[39m\u001b[38;5;124m'\u001b[39m]), df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome_type\u001b[39m\u001b[38;5;124m'\u001b[39m], df_test, cat_cols)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#x random trees\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m xg \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_XG_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutcome_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutcome_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m logreg\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[1;32m     10\u001b[0m rf_probs \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m/tmp/ipykernel_1004801/1112293194.py:79\u001b[0m, in \u001b[0;36mtrain_XG_classifier\u001b[0;34m(X_train, y_train, X_test, rare_classes, cat_cols, custom_thresholds)\u001b[0m\n\u001b[1;32m     68\u001b[0m randomized_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     69\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     70\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Starting training with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mrandomized_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb__sample_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Training complete. Best model fitted on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Show sample transformed training features\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n50 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 427, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/xgboost/core.py\", line 738, in inner_f\n    return func(**kwargs)\n  File \"/u/nneoma/.local/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1559, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['Adoption' 'Died' 'Euthanasia' 'Return to Owner' 'Transfer']\n"
     ]
    }
   ],
   "source": [
    "# manual voting\n",
    "\n",
    "#def manual_voting(models):\n",
    "logreg = train_logreg_classifier(df_train.drop(columns=['outcome_type']), df_train['outcome_type'], df_test, cat_cols, num_cols)[0] #logistic regression\n",
    "rf = train_RF_classifier(df_train.drop(columns=['outcome_type']), df_train['outcome_type'], df_test, cat_cols)[0] #random forest\n",
    "xrt = train_XRT_classifier(df_train.drop(columns=['outcome_type']), df_train['outcome_type'], df_test, cat_cols)[0] #x random trees\n",
    "xg = train_XG_classifier(df_train.drop(columns=['outcome_type']), df_train['outcome_type'], df_test, [], cat_cols)[0]\n",
    "\n",
    "log_probs = logreg.predict_proba(X_test)\n",
    "rf_probs = rf.predict_proba(X_test)\n",
    "xrt_probs = xrt.predict_proba(X_test)\n",
    "xg_progs = xg.predict_proba(X_test)\n",
    "\n",
    "avg_probs = (log_probs + rf_probs + xrt_probs + xg_progs) / 4\n",
    "\n",
    "'''\n",
    "avg_probs = (\n",
    "    0.1667 * log_probs +\n",
    "    0.1667 * rf_probs +\n",
    "    0.1667 * xrt_probs +\n",
    "    0.5    * xg_progs\n",
    ") \n",
    "\n",
    "'''\n",
    "\n",
    "thresholds = {\n",
    "    0: 0.60,  # Adopted\n",
    "    1: 0.20,  # Died\n",
    "    2: 0.30,  # Euth\n",
    "    3: 0.40,  # RTO\n",
    "    4: 0.30   # Transfer\n",
    "}\n",
    "\n",
    "#le.fit_transform(y_train)\n",
    "\n",
    "custom_preds = []\n",
    "\n",
    "for probs in avg_probs:\n",
    "    # Find which classes exceed their thresholds\n",
    "    passed = [cls for cls, prob in enumerate(probs) if prob >= thresholds.get(cls, 1.0)]\n",
    "    \n",
    "    if passed:\n",
    "        # Among the passed, pick the class with the highest probability\n",
    "        chosen = max(passed, key=lambda cls: probs[cls])\n",
    "    else:\n",
    "        # Default to the class with highest average prob\n",
    "        chosen = np.argmax(probs)\n",
    "        \n",
    "    custom_preds.append(chosen)\n",
    "\n",
    "test_preds = np.array(custom_preds)\n",
    "test_preds_labels = le.inverse_transform(custom_preds)\n",
    "\n",
    "#classification_report_with_accuracy_score(y_test, test_preds_labels)\n",
    "save_predictions(test_preds_labels, 'voting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44722c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Predict from each already-trained model\n",
    "log_preds = logreg.predict(X_test)\n",
    "rf_preds = rf.predict(X_test)\n",
    "xrt_preds = xrt.predict(X_test)\n",
    "\n",
    "# Combine predictions manually, e.g. majority vote\n",
    "from scipy.stats import mode\n",
    "all_preds = np.vstack([log_preds, rf_preds, xrt_preds])\n",
    "final_preds, _ = mode(all_preds, axis=0)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
