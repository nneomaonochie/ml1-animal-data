{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1300c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5852bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /u/nneoma/.local/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned color\n",
      "cleaned breed\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_974738/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned color\n",
      "cleaned breed\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860ee9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kog_reg\n",
    "nb = nbformat.read(\"log_reg.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"log_reg_normalized.ipynb\")\n",
    "\n",
    "# Random Frest\n",
    "nb = nbformat.read(\"random_forest.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"random_forest_normalized.ipynb\")\n",
    "\n",
    "# X Random Trees\n",
    "nb = nbformat.read(\"x_random_trees.ipynb\", as_version=4)\n",
    "nbformat.validator.validate(nb)\n",
    "nbformat.write(nb, \"x_random_trees_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67690783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # Important for SMOTE compatibility\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e235819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>intake_month</th>\n",
       "      <th>intake_hour</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>size</th>\n",
       "      <th>outcome_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>sable</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>orange</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "0            Stray  Normal / Behavior         Dog   Spayed Female   \n",
       "1            Stray  Normal / Behavior         Dog     Intact Male   \n",
       "2    Public Assist  Normal / Behavior         Cat   Neutered Male   \n",
       "3  Owner Surrender  Normal / Behavior         Dog   Neutered Male   \n",
       "4    Public Assist  Normal / Behavior         Dog   Neutered Male   \n",
       "\n",
       "   age_upon_intake   breed  intake_year  intake_month  intake_hour  \\\n",
       "0             96.0       2         2015             7           12   \n",
       "1             11.0       7         2016             4           18   \n",
       "2             24.0  Common         2022             5            0   \n",
       "3             24.0       2         2017             2           12   \n",
       "4             72.0       3         2019             4            9   \n",
       "\n",
       "  primary_color  is_mix  size     outcome_type  \n",
       "0         white       0     3  Return to Owner  \n",
       "1         sable       1     2  Return to Owner  \n",
       "2        orange       0     2         Transfer  \n",
       "3     chocolate       1     4  Return to Owner  \n",
       "4         black       1     5  Return to Owner  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun when i make changes\n",
    "#%run log_reg.ipynb\n",
    "#%run random_forest.ipynb\n",
    "#%run x_random_trees.ipynb\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "996f61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_voting_classifier(X_train, y_train, X_test, models, voting='soft'):\n",
    "    \"\"\"\n",
    "    Trains a VotingClassifier with the given models and evaluates it on the test data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels\n",
    "    - X_test: Test features\n",
    "    - models: List of tuples (model_name, model_instance)\n",
    "    - voting: 'hard' or 'soft' for the type of voting to be used (default is 'soft')\n",
    "    \n",
    "    Returns:\n",
    "    - trained_model: Trained VotingClassifier\n",
    "    - test_predictions: Predictions on the test set\n",
    "    \"\"\"\n",
    "    # Initialize the VotingClassifier with the given models\n",
    "    voting_clf = VotingClassifier(estimators=models, voting=voting, n_jobs=-1)\n",
    "    \n",
    "    # Fit the model\n",
    "    voting_clf.fit(X_train, y_train) #   voting_clf.fit_transform(X_test,)\n",
    "    \n",
    "    # Make predictions\n",
    "    test_predictions = voting_clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = balanced_accuracy_score(y_train, voting_clf.predict(X_train))\n",
    "    print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return voting_clf, test_predictions\n",
    "\n",
    "# needs CV loop after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135a1555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016</td>\n",
       "      <td>sable</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>orange</td>\n",
       "      <td>0</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "0            Stray  Normal / Behavior         Dog   Spayed Female   \n",
       "1            Stray  Normal / Behavior         Dog     Intact Male   \n",
       "2    Public Assist  Normal / Behavior         Cat   Neutered Male   \n",
       "3  Owner Surrender  Normal / Behavior         Dog   Neutered Male   \n",
       "4    Public Assist  Normal / Behavior         Dog   Neutered Male   \n",
       "\n",
       "   age_upon_intake  breed  intake_year primary_color  is_mix     outcome_type  \\\n",
       "0             96.0     -1         2015         white       0  Return to Owner   \n",
       "1             11.0     -1         2016         sable       1  Return to Owner   \n",
       "2             24.0      9         2022        orange       0         Transfer   \n",
       "3             24.0     -1         2017     chocolate       1  Return to Owner   \n",
       "4             72.0     -1         2019         black       1  Return to Owner   \n",
       "\n",
       "   season time_of_day  \n",
       "0  Summer   Afternoon  \n",
       "1  Spring     Evening  \n",
       "2  Spring       Night  \n",
       "3  Winter   Afternoon  \n",
       "4  Spring     Morning  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = bucket_seasons(df_train)\n",
    "df_test = bucket_seasons(df_test)\n",
    "\n",
    "df_train = bucket_days(df_train)\n",
    "df_test = bucket_days(df_test)\n",
    "\n",
    "df_train['breed'] = df_train['breed'].astype(str)\n",
    "df_test['breed'] = df_test['breed'].astype(str)\n",
    "\n",
    "df_train = df_train.drop(columns=['size', 'intake_hour', 'intake_month'])\n",
    "df_test = df_test.drop(columns=['size', 'intake_hour', 'intake_month'])\n",
    "\n",
    "# breed is encoded, but dont fret\n",
    "def encode_breed(val):\n",
    "    if isinstance(val, int):\n",
    "        return val  # Keep numeric as-is\n",
    "    mapping = {'Common': 9, 'Rare': 10, 'Unknown': 11}\n",
    "    return mapping.get(val, -1)  # Return -1 for unexpected values (or handle as needed)\n",
    "\n",
    "# Apply transformation\n",
    "df_train['breed'] = df_train['breed'].apply(encode_breed)\n",
    "df_test['breed'] = df_test['breed'].apply(encode_breed)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f960669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['outcome_type'])\n",
    "y = df_train['outcome_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d718e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# This is just used to get the model with the best classifiers\\nmodels = [\\n    ('logreg', train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0]), #logistic regression\\n    ('rf', train_RF_classifier(X_train, y_train, X_test, cat_cols)[0]), #random forest\\n    ('xrt', train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0]) #x random trees\\n]\\n\\n# Assuming X_train, y_train, X_test are already defined in your environment\\nvoting_model, test_predictions = train_voting_classifier(X_train, y_train, X_test, models, voting='soft')\\n\\nclassification_report_with_accuracy_score(y_test, test_predictions)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed','season', 'is_mix', 'time_of_day', 'primary_color'] # experimenting with droping color\n",
    "num_cols = ['age_upon_intake', 'intake_year']    # Replace with your actual numerical columns\n",
    "# freq_cols = ['primary_color'] # for trees\n",
    "\n",
    "'''\n",
    "# This is just used to get the model with the best classifiers\n",
    "models = [\n",
    "    ('logreg', train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0]), #logistic regression\n",
    "    ('rf', train_RF_classifier(X_train, y_train, X_test, cat_cols)[0]), #random forest\n",
    "    ('xrt', train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0]) #x random trees\n",
    "]\n",
    "\n",
    "# Assuming X_train, y_train, X_test are already defined in your environment\n",
    "voting_model, test_predictions = train_voting_classifier(X_train, y_train, X_test, models, voting='soft')\n",
    "\n",
    "classification_report_with_accuracy_score(y_test, test_predictions)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa32188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107615</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>torbie</td>\n",
       "      <td>0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014</td>\n",
       "      <td>brown brindle</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019</td>\n",
       "      <td>brown</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79497</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>calico</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88489</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "107615          Stray  Normal / Behavior         Cat   Intact Female   \n",
       "13002           Stray            Injured         Dog     Intact Male   \n",
       "32513   Public Assist  Normal / Behavior         Dog   Intact Female   \n",
       "79497           Stray  Normal / Behavior         Cat   Intact Female   \n",
       "88489           Stray  Normal / Behavior         Dog   Intact Female   \n",
       "\n",
       "        age_upon_intake  breed  intake_year  primary_color  is_mix  season  \\\n",
       "107615              1.0      9         2021         torbie       0  Summer   \n",
       "13002              24.0     -1         2014  brown brindle       1  Summer   \n",
       "32513              12.0     -1         2019          brown       1  Summer   \n",
       "79497               1.0      9         2015         calico       1  Summer   \n",
       "88489               4.0     -1         2017          black       0  Spring   \n",
       "\n",
       "       time_of_day  \n",
       "107615     Morning  \n",
       "13002      Morning  \n",
       "32513        Night  \n",
       "79497      Evening  \n",
       "88489      Morning  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8630dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# This is just used to get the model with the best classifiers\\nmodels = [\\n    ('logreg', train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0]), #logistic regression\\n    ('rf', train_RF_classifier(X_train, y_train, X_test, cat_cols)[0]), #random forest\\n    ('xrt', train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0]) #x random trees\\n]\\n\\n# Assuming X_train, y_train, X_test are already defined in your environment\\nvoting_model, test_predictions = train_voting_classifier(X_train, y_train, X_test, models, voting='soft')\\n\\nclassification_report_with_accuracy_score(y_test, test_predictions)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cat_cols = ['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed','season', 'is_mix', 'time_of_day', 'primary_color'] # experimenting with droping color\n",
    "num_cols = ['age_upon_intake', 'intake_year']    # Replace with your actual numerical columns\n",
    "# freq_cols = ['primary_color'] # for trees\n",
    "'''\n",
    "# This is just used to get the model with the best classifiers\n",
    "models = [\n",
    "    ('logreg', train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0]), #logistic regression\n",
    "    ('rf', train_RF_classifier(X_train, y_train, X_test, cat_cols)[0]), #random forest\n",
    "    ('xrt', train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0]) #x random trees\n",
    "]\n",
    "\n",
    "# Assuming X_train, y_train, X_test are already defined in your environment\n",
    "voting_model, test_predictions = train_voting_classifier(X_train, y_train, X_test, models, voting='soft')\n",
    "\n",
    "classification_report_with_accuracy_score(y_test, test_predictions)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb469c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvoting_clf = VotingClassifier(\\n    estimators=[\\n        (\\'xgb\\', xgb_model),      # best XGBoost model\\n        (\\'cat\\', catboost_model), # best CatBoost model\\n        (\\'logreg\\', log_reg_model),\\n        (\\'rf\\', rf_model),\\n        (\\'nb\\', nb_model)\\n    ],\\n    voting=\\'soft\\',\\n  #  weights=[3, 2.5, 2, 1.5, 1],  # optional: weight more accurate models\\n    n_jobs=-1\\n)\\n\\nvoting_clf.fit(X_train, y_train)\\ny_pred = voting_clf.predict(X_test)\\n\\n# Evaluate\\nfrom sklearn.metrics import balanced_accuracy_score\\nprint(\"Ensemble Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming these are pipelines or models you've already trained/tuned\n",
    "'''\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),      # best XGBoost model\n",
    "        ('cat', catboost_model), # best CatBoost model\n",
    "        ('logreg', log_reg_model),\n",
    "        ('rf', rf_model),\n",
    "        ('nb', nb_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "  #  weights=[3, 2.5, 2, 1.5, 1],  # optional: weight more accurate models\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(\"Ensemble Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f25e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   1.6s\n",
      "[CV 2/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.459 total time=   1.1s\n",
      "[CV 3/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.469 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.447 total time= 1.8min\n",
      "[CV 5/5] END logreg__C=0.3845401188473625, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.468 total time=   1.8s\n",
      "[CV 1/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.467 total time=   1.7s\n",
      "[CV 2/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.458 total time=   1.9s\n",
      "[CV 3/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.468 total time=   1.9s\n",
      "[CV 4/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.450 total time=   1.9s\n",
      "[CV 5/5] END logreg__C=0.6086584841970366, logreg__class_weight={0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.468 total time=   1.8s\n",
      "[CV 1/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   0.6s\n",
      "[CV 2/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.457 total time=   0.6s\n",
      "[CV 3/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   0.6s\n",
      "[CV 4/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.449 total time=   2.6s\n",
      "[CV 5/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   1.6s\n",
      "[CV 1/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   0.5s\n",
      "[CV 2/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.457 total time=   0.5s\n",
      "[CV 3/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   0.5s\n",
      "[CV 4/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.449 total time=   0.7s\n",
      "[CV 5/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.470 total time=   0.5s\n",
      "[CV 1/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   4.3s\n",
      "[CV 2/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.459 total time=   4.4s\n",
      "[CV 3/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   4.2s\n",
      "[CV 4/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.450 total time=   4.2s\n",
      "[CV 5/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.472 total time=   4.3s\n",
      "Best parameters: {'logreg__C': 0.010778765841014329, 'logreg__class_weight': 'balanced', 'logreg__fit_intercept': True, 'logreg__max_iter': 7000, 'logreg__penalty': 'l2', 'logreg__solver': 'saga'}\n",
      "Best cross-validation accuracy: 0.46305062985194717\n",
      "[CV] END ................................ score: (test=0.462) total time=   4.1s\n",
      "[CV] END ................................ score: (test=0.462) total time=   4.6s\n",
      "[CV] END ................................ score: (test=0.465) total time=   4.5s\n",
      "[CV] END ................................ score: (test=0.457) total time=   3.9s\n",
      "[CV] END ................................ score: (test=0.447) total time=   4.5s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.45872411842569727\n",
      "Class weights: {0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}\n",
      "\n",
      "[INFO] Starting training with 71139 samples\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   2.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   2.7s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   2.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   2.7s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.8s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.8s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.8s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   1.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   1.5s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   1.9s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   3.5s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   5.4s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   7.1s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   7.2s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   6.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   6.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.9s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.9s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.8s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.9s\n",
      "[INFO] Training complete.\n",
      "Best parameters: {'rf__n_estimators': 100, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10}\n",
      "Best CV accuracy: 0.4494182523860438\n",
      "[CV] END ................................ score: (test=0.452) total time=   0.5s\n",
      "[CV] END ................................ score: (test=0.450) total time=   0.5s\n",
      "[CV] END ................................ score: (test=0.447) total time=   0.5s\n",
      "[CV] END ................................ score: (test=0.453) total time=   0.5s\n",
      "[CV] END ................................ score: (test=0.446) total time=   0.5s\n",
      "Generalization accuracy (via cross_val_score): 0.4494182523860438\n",
      "Class weights: {0: 0.404084067026413, 1: 21.299101796407186, 2: 6.461307901907357, 3: 1.3310693236037048, 4: 0.6360214573088958}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.1s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   3.8s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   4.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   2.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   2.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   0.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   1.6s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   1.8s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   1.5s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   1.7s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.3s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   7.4s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   8.2s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   8.3s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   7.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   2.3s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   6.1s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.6s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   0.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   0.5s\n",
      "Best parameters: {'xrt__n_estimators': 200, 'xrt__min_samples_split': 5, 'xrt__min_samples_leaf': 4, 'xrt__max_depth': 10}\n",
      "Best cross-validation accuracy: 0.44943815776126844\n",
      "[CV] END ................................ score: (test=0.451) total time=   0.9s\n",
      "[CV] END ................................ score: (test=0.454) total time=   0.9s\n",
      "[CV] END ................................ score: (test=0.439) total time=   0.9s\n",
      "[CV] END ................................ score: (test=0.451) total time=   0.9s\n",
      "[CV] END ................................ score: (test=0.452) total time=   0.9s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.44943815776126844\n",
      "Best thresholds: {0: 0.5, 1: 0.2, 2: 0.3, 3: 0.4, 4: 0.3}\n",
      "Best balanced accuracy on validation: 0.4424449775139621\n"
     ]
    }
   ],
   "source": [
    "# used for extra valdiation to find the best thresholds to maximize recall per class\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "# Train on sub-training set\n",
    "logreg_CV = train_logreg_classifier(X_train_sub, y_train_sub, X_val, cat_cols, num_cols)[0]\n",
    "rf_CV = train_RF_classifier(X_train_sub, y_train_sub, X_val, cat_cols)[0]\n",
    "xrt_CV = train_XRT_classifier(X_train_sub, y_train_sub, X_val, cat_cols)[0]\n",
    "\n",
    "# Get predicted probabilities on validation set\n",
    "log_probs_CV = logreg_CV.predict_proba(X_val)\n",
    "rf_probs_CV = rf_CV.predict_proba(X_val)\n",
    "xrt_probs_CV = xrt_CV.predict_proba(X_val)\n",
    "\n",
    "# Average the probabilities\n",
    "avg_probs_val = (log_probs_CV + rf_probs_CV + xrt_probs_CV) / 3\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# Define classes (adjust as needed)\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Threshold options for each class\n",
    "threshold_grid = {\n",
    "    0: [0.5, 0.6, 0.7, 0.8],\n",
    "    1: [0.05, 0.1, 0.2],\n",
    "    2: [0.1, 0.2, 0.3],\n",
    "    3: [0.2, 0.3, 0.4],\n",
    "    4: [0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "# Generate all threshold combinations\n",
    "all_thresholds = list(product(*threshold_grid.values()))\n",
    "\n",
    "# Tune thresholds\n",
    "best_score = -1\n",
    "best_thresholds = None\n",
    "\n",
    "for thresh_combo in all_thresholds:\n",
    "    thresholds = dict(zip(classes, thresh_combo))\n",
    "    preds = []\n",
    "\n",
    "    for probs in avg_probs_val:\n",
    "        passed = [cls for cls, prob in enumerate(probs) if prob >= thresholds.get(cls, 1.0)]\n",
    "        if passed:\n",
    "            chosen = max(passed, key=lambda cls: probs[cls])\n",
    "        else:\n",
    "            chosen = np.argmax(probs)\n",
    "        preds.append(chosen)\n",
    "\n",
    "    score = balanced_accuracy_score(y_val, preds)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_thresholds = thresholds\n",
    "\n",
    "print(\"Best thresholds:\", best_thresholds)\n",
    "print(\"Best balanced accuracy on validation:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e084a9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.453 total time= 2.3min\n",
      "[CV 2/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.456 total time=   1.8s\n",
      "[CV 3/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.453 total time=   1.4s\n",
      "[CV 4/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   3.4s\n",
      "[CV 5/5] END logreg__C=0.3845401188473625, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.468 total time=   1.5s\n",
      "[CV 1/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.457 total time=   2.1s\n",
      "[CV 2/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.456 total time=   2.4s\n",
      "[CV 3/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.453 total time=   2.1s\n",
      "[CV 4/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.467 total time=   2.2s\n",
      "[CV 5/5] END logreg__C=0.6086584841970366, logreg__class_weight={'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, logreg__fit_intercept=False, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.469 total time=   1.8s\n",
      "[CV 1/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.457 total time=   2.9s\n",
      "[CV 2/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.456 total time=   0.9s\n",
      "[CV 3/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.452 total time=   3.4s\n",
      "[CV 4/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.466 total time=   1.0s\n",
      "[CV 5/5] END logreg__C=0.06808361216819946, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=8000, logreg__penalty=l2, logreg__solver=saga;, score=0.468 total time=   0.8s\n",
      "[CV 1/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.457 total time=   0.9s\n",
      "[CV 2/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.456 total time=   0.7s\n",
      "[CV 3/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.452 total time=   0.9s\n",
      "[CV 4/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.467 total time=   0.7s\n",
      "[CV 5/5] END logreg__C=0.06641157902710025, logreg__class_weight=balanced, logreg__fit_intercept=False, logreg__max_iter=7500, logreg__penalty=l2, logreg__solver=saga;, score=0.468 total time=   0.7s\n",
      "[CV 1/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.457 total time=   5.2s\n",
      "[CV 2/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.458 total time=   5.2s\n",
      "[CV 3/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.451 total time=   5.9s\n",
      "[CV 4/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.466 total time=   5.2s\n",
      "[CV 5/5] END logreg__C=0.010778765841014329, logreg__class_weight=balanced, logreg__fit_intercept=True, logreg__max_iter=7000, logreg__penalty=l2, logreg__solver=saga;, score=0.468 total time=   5.1s\n",
      "Best parameters: {'logreg__C': 0.6086584841970366, 'logreg__class_weight': {'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}, 'logreg__fit_intercept': False, 'logreg__max_iter': 8000, 'logreg__penalty': 'l2', 'logreg__solver': 'lbfgs'}\n",
      "Best cross-validation accuracy: 0.46022488306620407\n",
      "[CV] END ................................ score: (test=0.463) total time=   2.5s\n",
      "[CV] END ................................ score: (test=0.467) total time=   2.1s\n",
      "[CV] END ................................ score: (test=0.469) total time=   2.2s\n",
      "[CV] END ................................ score: (test=0.457) total time=   2.6s\n",
      "[CV] END ................................ score: (test=0.455) total time=   2.1s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.46220216895761423\n",
      "Class weights: {'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}\n",
      "\n",
      "[INFO] Starting training with 88924 samples\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/u/nneoma/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.4s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.3s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   3.6s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=100; total time=   2.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=1, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   1.7s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   2.4s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=5, rf__n_estimators=200; total time=   3.1s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   8.4s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   9.1s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   9.2s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   8.9s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   3.2s\n",
      "[CV] END rf__max_depth=20, rf__min_samples_leaf=1, rf__min_samples_split=5, rf__n_estimators=200; total time=   7.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.0s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.2s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   1.1s\n",
      "[CV] END rf__max_depth=10, rf__min_samples_leaf=4, rf__min_samples_split=2, rf__n_estimators=100; total time=   0.8s\n",
      "[INFO] Training complete.\n",
      "Best parameters: {'rf__n_estimators': 200, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10}\n",
      "Best CV accuracy: 0.4457844578454293\n",
      "[CV] END ................................ score: (test=0.441) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.442) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.446) total time=   1.2s\n",
      "[CV] END ................................ score: (test=0.450) total time=   1.2s\n",
      "[CV] END ................................ score: (test=0.449) total time=   1.2s\n",
      "Generalization accuracy (via cross_val_score): 0.4457844578454293\n",
      "Class weights: {'Adoption': 0.4040806125462931, 'Died': 21.29916167664671, 'Euthanasia': 6.4625, 'Return to Owner': 1.3310979717087044, 'Transfer': 0.6360118728319565}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   5.6s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   5.8s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   5.4s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   5.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   2.7s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=100; total time=   3.7s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=1, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   2.3s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   3.8s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   9.3s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  10.7s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  10.8s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=  10.9s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   3.1s\n",
      "[CV] END xrt__max_depth=20, xrt__min_samples_leaf=1, xrt__min_samples_split=5, xrt__n_estimators=200; total time=   9.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.0s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   1.2s\n",
      "[CV] END xrt__max_depth=10, xrt__min_samples_leaf=4, xrt__min_samples_split=2, xrt__n_estimators=100; total time=   0.7s\n",
      "Best parameters: {'xrt__n_estimators': 200, 'xrt__min_samples_split': 5, 'xrt__min_samples_leaf': 4, 'xrt__max_depth': 10}\n",
      "Best cross-validation accuracy: 0.4465834202562721\n",
      "[CV] END ................................ score: (test=0.439) total time=   1.2s\n",
      "[CV] END ................................ score: (test=0.438) total time=   1.2s\n",
      "[CV] END ................................ score: (test=0.445) total time=   1.2s\n",
      "[CV] END ................................ score: (test=0.455) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.456) total time=   1.2s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.4465834202562721\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.65      0.22      0.33     11031\n",
      "           Died       0.01      0.40      0.03       206\n",
      "     Euthanasia       0.17      0.57      0.26       697\n",
      "Return to Owner       0.38      0.70      0.49      3236\n",
      "       Transfer       0.54      0.30      0.39      7061\n",
      "\n",
      "       accuracy                           0.33     22231\n",
      "      macro avg       0.35      0.44      0.30     22231\n",
      "   weighted avg       0.56      0.33      0.37     22231\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.439206016338629"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual voting\n",
    "#def manual_voting(models):\n",
    "logreg = train_logreg_classifier(X_train, y_train, X_test, cat_cols, num_cols)[0] #logistic regression\n",
    "rf = train_RF_classifier(X_train, y_train, X_test, cat_cols)[0] #random forest\n",
    "xrt = train_XRT_classifier(X_train, y_train, X_test, cat_cols)[0] #x random trees\n",
    "\n",
    "log_probs = logreg.predict_proba(X_test)\n",
    "rf_probs = rf.predict_proba(X_test)\n",
    "xrt_probs = xrt.predict_proba(X_test)\n",
    "\n",
    "avg_probs = (log_probs + rf_probs + xrt_probs) / 3\n",
    "\n",
    "\n",
    "thresholds = {\n",
    "    0: 0.60,  # Adopted\n",
    "    1: 0.10,  # Died\n",
    "    2: 0.20,  # Euth\n",
    "    3: 0.30,  # RTO\n",
    "    4: 0.30   # Transfer\n",
    "}\n",
    "\n",
    "le = LabelEncoder()\n",
    "#le.fit_transform(y_train)\n",
    "\n",
    "custom_preds = []\n",
    "\n",
    "for probs in avg_probs:\n",
    "    # Find which classes exceed their thresholds\n",
    "    passed = [cls for cls, prob in enumerate(probs) if prob >= thresholds.get(cls, 1.0)]\n",
    "    \n",
    "    if passed:\n",
    "        # Among the passed, pick the class with the highest probability\n",
    "        chosen = max(passed, key=lambda cls: probs[cls])\n",
    "    else:\n",
    "        # Default to the class with highest average prob\n",
    "        chosen = np.argmax(probs)\n",
    "        \n",
    "    custom_preds.append(chosen)\n",
    "\n",
    "test_preds = np.array(custom_preds)\n",
    "test_preds_labels = le.inverse_transform(custom_preds)\n",
    "\n",
    "classification_report_with_accuracy_score(y_test, test_preds_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44722c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Predict from each already-trained model\n",
    "log_preds = logreg.predict(X_test)\n",
    "rf_preds = rf.predict(X_test)\n",
    "xrt_preds = xrt.predict(X_test)\n",
    "\n",
    "# Combine predictions manually, e.g. majority vote\n",
    "from scipy.stats import mode\n",
    "all_preds = np.vstack([log_preds, rf_preds, xrt_preds])\n",
    "final_preds, _ = mode(all_preds, axis=0)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
