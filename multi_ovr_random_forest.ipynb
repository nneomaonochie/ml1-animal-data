{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b344d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned color\n",
      "cleaned breed\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/knpz54sj16988z9vrp2b98fr0000gn/T/ipykernel_97656/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned color\n",
      "cleaned breed\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")\n",
    "\n",
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74061f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_classifier(X_train, y_train_raw, X_test, thresholds=None, base_model=None):\n",
    "    \"\"\"\n",
    "    Trains separate One-vs-Rest classifiers for each class using Random Forest.\n",
    "    Includes per-fold CV scoring and generalization accuracy.\n",
    "    Defaults to the highest-probability non-Adoption class when needed.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (DataFrame): Training features\n",
    "        y_train_raw (Series): Target labels (strings)\n",
    "        X_test (DataFrame): Test features\n",
    "        thresholds (dict): Optional per-class thresholds\n",
    "        base_model (sklearn estimator): Optional custom classifier\n",
    "\n",
    "    Returns:\n",
    "        final_preds (Series): Final predictions on X_test\n",
    "        ovr_models (dict): Dictionary of trained models\n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = sorted(y_train_raw.unique())\n",
    "    ovr_models = {}\n",
    "    class_probs = []\n",
    "\n",
    "    if base_model is None:\n",
    "        base_model = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "\n",
    "    print(\"\\n=== [ OvR Model Training and Cross-Validation ] ===\")\n",
    "    for target_class in class_labels:\n",
    "        print(f\"\\n[INFO] OvR model for class: '{target_class}'\")\n",
    "        y_binary = (y_train_raw == target_class).astype(int)\n",
    "\n",
    "        weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.array([0, 1]),\n",
    "            y=y_binary\n",
    "        )\n",
    "        class_weight_dict = {0: weights[0], 1: weights[1]}\n",
    "\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            class_weight=class_weight_dict\n",
    "        )\n",
    "\n",
    "        print(\"[INFO] 5-Fold CV (balanced accuracy):\")\n",
    "        scores = cross_val_score(\n",
    "            clf,\n",
    "            X_train,\n",
    "            y_binary,\n",
    "            cv=5,\n",
    "            scoring='balanced_accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        for i, score in enumerate(scores):\n",
    "            print(f\"  Fold {i+1}: {score:.4f}\")\n",
    "        print(f\"  Mean CV score: {scores.mean():.4f}\")\n",
    "\n",
    "        clf.fit(X_train, y_binary)\n",
    "        ovr_models[target_class] = clf\n",
    "\n",
    "        class_probs.append(clf.predict_proba(X_test)[:, 1])  # positive class probability\n",
    "\n",
    "    all_probs = np.vstack(class_probs).T\n",
    "    class_order = class_labels\n",
    "\n",
    "    final_preds = []\n",
    "    fallback_count = 0\n",
    "\n",
    "    for prob_row in all_probs:\n",
    "        scores = dict(zip(class_order, prob_row))\n",
    "        selected_class = None\n",
    "        selected_score = 0\n",
    "\n",
    "        # Apply threshold logic\n",
    "        for cls, score in scores.items():\n",
    "            threshold = thresholds.get(cls, 0.5) if thresholds else 0.5\n",
    "            if score >= threshold and score > selected_score:\n",
    "                selected_class = cls\n",
    "                selected_score = score\n",
    "\n",
    "        # Fallback: pick highest non-Adoption class if no threshold met\n",
    "        if not selected_class:\n",
    "            non_adoption_scores = {cls: sc for cls, sc in scores.items() if cls != 'Adoption'}\n",
    "            selected_class = max(non_adoption_scores.items(), key=lambda x: x[1])[0]\n",
    "            fallback_count += 1\n",
    "\n",
    "        final_preds.append(selected_class)\n",
    "\n",
    "    print(f\"\\n[INFO] Fallback to best non-Adoption class used for {fallback_count} samples\")\n",
    "\n",
    "    # === Generalization accuracy on training set ===\n",
    "    print(\"\\n=== [ Generalization Accuracy on Training Set ] ===\")\n",
    "    train_probs = []\n",
    "    for cls in class_order:\n",
    "        model = ovr_models[cls]\n",
    "        train_probs.append(model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "    train_all_probs = np.vstack(train_probs).T\n",
    "    train_preds = []\n",
    "    fallback_train = 0\n",
    "\n",
    "    for prob_row in train_all_probs:\n",
    "        scores = dict(zip(class_order, prob_row))\n",
    "        selected_class = None\n",
    "        selected_score = 0\n",
    "\n",
    "        for cls, score in scores.items():\n",
    "            threshold = thresholds.get(cls, 0.5) if thresholds else 0.5\n",
    "            if score >= threshold and score > selected_score:\n",
    "                selected_class = cls\n",
    "                selected_score = score\n",
    "\n",
    "        if not selected_class:\n",
    "            non_adoption_scores = {cls: sc for cls, sc in scores.items() if cls != 'Adoption'}\n",
    "            selected_class = max(non_adoption_scores.items(), key=lambda x: x[1])[0]\n",
    "            fallback_train += 1\n",
    "\n",
    "        train_preds.append(selected_class)\n",
    "\n",
    "    acc = accuracy_score(y_train_raw, train_preds)\n",
    "    bal_acc = balanced_accuracy_score(y_train_raw, train_preds)\n",
    "    print(f\"[INFO] Accuracy:           {acc:.4f}\")\n",
    "    print(f\"[INFO] Balanced Accuracy:  {bal_acc:.4f}\")\n",
    "    print(f\"[INFO] Fallbacks (train):  {fallback_train}\")\n",
    "\n",
    "    return pd.Series(final_preds, index=X_test.index), ovr_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding mapping: {'Adoption': 0, 'Died': 1, 'Euthanasia': 2, 'Return to Owner': 3, 'Transfer': 4}\n",
      "Rare classes (by encoded value):\n",
      "  2: Euthanasia\n",
      "  1: Died\n",
      "\n",
      "=== [ OvR Model Training and Cross-Validation ] ===\n",
      "\n",
      "[INFO] OvR model for class: 'Adoption'\n",
      "[INFO] 5-Fold CV (balanced accuracy):\n",
      "  Fold 1: 0.6795\n",
      "  Fold 2: 0.6813\n",
      "  Fold 3: 0.6814\n",
      "  Fold 4: 0.6881\n",
      "  Fold 5: 0.6922\n",
      "  Mean CV score: 0.6845\n",
      "\n",
      "[INFO] OvR model for class: 'Died'\n",
      "[INFO] 5-Fold CV (balanced accuracy):\n",
      "  Fold 1: 0.5216\n",
      "  Fold 2: 0.5261\n",
      "  Fold 3: 0.5347\n",
      "  Fold 4: 0.5359\n",
      "  Fold 5: 0.5229\n",
      "  Mean CV score: 0.5282\n",
      "\n",
      "[INFO] OvR model for class: 'Euthanasia'\n",
      "[INFO] 5-Fold CV (balanced accuracy):\n",
      "  Fold 1: 0.5882\n",
      "  Fold 2: 0.5824\n",
      "  Fold 3: 0.5781\n",
      "  Fold 4: 0.5861\n",
      "  Fold 5: 0.5849\n",
      "  Mean CV score: 0.5839\n",
      "\n",
      "[INFO] OvR model for class: 'Return to Owner'\n",
      "[INFO] 5-Fold CV (balanced accuracy):\n",
      "  Fold 1: 0.6927\n",
      "  Fold 2: 0.6924\n",
      "  Fold 3: 0.6916\n",
      "  Fold 4: 0.6901\n",
      "  Fold 5: 0.6929\n",
      "  Mean CV score: 0.6920\n",
      "\n",
      "[INFO] OvR model for class: 'Transfer'\n",
      "[INFO] 5-Fold CV (balanced accuracy):\n",
      "  Fold 1: 0.6666\n",
      "  Fold 2: 0.6653\n",
      "  Fold 3: 0.6650\n",
      "  Fold 4: 0.6717\n",
      "  Fold 5: 0.6754\n",
      "  Mean CV score: 0.6688\n",
      "\n",
      "[INFO] Fallback to best non-Adoption class used for 11137 samples\n",
      "\n",
      "=== [ Generalization Accuracy on Training Set ] ===\n",
      "[INFO] Accuracy:           0.6648\n",
      "[INFO] Balanced Accuracy:  0.8260\n",
      "[INFO] Fallbacks (train):  26490\n",
      "Combined test predictions saved to: ./test_multi_ovr_with_thresholds_predictions_combined.csv\n",
      "\n",
      "[INFO] Prediction Distribution:\n",
      "Transfer           15353\n",
      "Return to Owner     6837\n",
      "Adoption            3523\n",
      "Euthanasia          1277\n",
      "Died                 801\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# === [1] EXTRA DATA CLEANING ===\n",
    "df_train = bucket_seasons(df_train)\n",
    "df_test  = bucket_seasons(df_test)\n",
    "\n",
    "y_train_raw = df_train['outcome_type']\n",
    "df_train = df_train.drop(columns=['outcome_type', 'is_mix', 'intake_hour', 'intake_month'])\n",
    "\n",
    "X_train = df_train.copy()\n",
    "X_test  = df_test.copy()\n",
    "\n",
    "# === [2] Label encode outcome_type for reporting and consistency ===\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_train_raw)\n",
    "print(\"Encoding mapping:\", dict(zip(le.classes_, range(len(le.classes_)))))\n",
    "\n",
    "# === [3] Identify rare classes (< 5% frequency, for logging/debugging) ===\n",
    "rare_classes = [\n",
    "    label for label, count in pd.Series(y_encoded).value_counts().items()\n",
    "    if count < 0.05 * len(y_encoded)\n",
    "]\n",
    "print(\"Rare classes (by encoded value):\")\n",
    "for cls in rare_classes:\n",
    "    print(f\"  {cls}: {le.classes_[cls]}\")\n",
    "\n",
    "# === [4] Categorical Feature Encoding ===\n",
    "cat_cols_onehot = ['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'season', 'breed']\n",
    "cat_cols_freq   = ['primary_color']\n",
    "\n",
    "# Frequency encode high-cardinality features\n",
    "for col in cat_cols_freq:\n",
    "    freq_map = X_train[col].value_counts()\n",
    "    X_train[col] = X_train[col].map(freq_map)\n",
    "    X_test[col] = X_test[col].map(freq_map).fillna(0)\n",
    "\n",
    "# Save original version for segmented analysis\n",
    "raw_X_train = X_train.copy()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_train = pd.get_dummies(X_train, columns=cat_cols_onehot, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test,  columns=cat_cols_onehot, drop_first=True)\n",
    "\n",
    "# Ensure same columns in both sets\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# === [5] Define Thresholds for Each Class ===\n",
    "thresholds = {\n",
    "    'Adoption': 0.9,\n",
    "    'Died': 0.2,\n",
    "    'Euthanasia': 0.3,\n",
    "    'Return to Owner': 0.5,\n",
    "    'Transfer': 0.5\n",
    "}\n",
    "\n",
    "# === [6] Train OvR Model and Predict ===\n",
    "final_predictions, ovr_models = train_classifier(\n",
    "    X_train=X_train,\n",
    "    y_train_raw=y_train_raw,\n",
    "    X_test=X_test,\n",
    "    thresholds=thresholds\n",
    ")\n",
    "\n",
    "# === [7] Save final decoded predictions ===\n",
    "save_predictions(final_predictions, model_name='multi_ovr_with_thresholds')\n",
    "\n",
    "# === [8] Optional: Per-animal-type reports ===\n",
    "# print(\"\\n[INFO] Prediction Distribution:\")\n",
    "# print(final_predictions.value_counts())\n",
    "\n",
    "# # Masks derived from raw training data\n",
    "# cat_mask = raw_X_train['animal_type'] == 'Cat'\n",
    "# dog_mask = raw_X_train['animal_type'] == 'Dog'\n",
    "\n",
    "# print(\"\\n[INFO] Classification Report (Cats only):\")\n",
    "# print(classification_report(\n",
    "#     y_true=y_train_raw[cat_mask],\n",
    "#     y_pred=train_preds[cat_mask]\n",
    "# ))\n",
    "\n",
    "# print(\"\\n[INFO] Classification Report (Dogs only):\")\n",
    "# print(classification_report(\n",
    "#     y_true=y_train_raw[dog_mask],\n",
    "#     y_pred=train_preds[dog_mask]\n",
    "# ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
