{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /u/nneoma/.local/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from xgboost) (1.17.4)\n",
      "Requirement already satisfied: scipy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nneoma/.local/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.17.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d09f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5655af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to figure out SMOTE\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "#df_train_downsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6921ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_NB_classifier(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains an Naive Bayes Multinominal model using a pipeline that includes a frequency encoding transformation,\n",
    "    OneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series or np.array): Training target values.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "    \n",
    "    Returns:\n",
    "        best_estimator: The best estimator from RandomizedSearchCV.\n",
    "        test_predictions: The predicted labels for X_test from the best estimator.\n",
    "    \"\"\"\n",
    "    # Construct the pipeline:\n",
    "    #   1. Apply frequency encoding (for example, on 'primary_color' & 'breed' if implemented in apply_freq_encode)\n",
    "    #   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\n",
    "    #   3. Fit an XGBClassifier.\n",
    "    smote = SMOTENC(categorical_features=['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed', 'is_mix', 'primary_color'], random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True)),\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # Set up parameter distributions for XGBoost.\n",
    "    param_distributions = {\n",
    "        \"nb__alpha\": [0.1, 0.5, 1, 2, 5, 10],\n",
    "    }\n",
    "    \n",
    "    # Perform hyperparameter search using RandomizedSearchCV.\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline, \n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=1,\n",
    "        cv=5, \n",
    "        scoring='balanced_accuracy', \n",
    "        verbose=3,\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "    \n",
    "    cv_scores = cross_val_score(randomized_search.best_estimator_, X_resampled, y_resampled, cv=5, verbose=3, scoring='balanced_accuracy')\n",
    "    print('Generalization Balanced accuracy (via cross_val_score):', cv_scores.mean())\n",
    "\n",
    "    # Make predictions on the test set using the best estimator.\n",
    "    test_predictions = randomized_search.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "    return randomized_search.best_estimator_, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168a8b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# downsampling\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "df_train_downsample = resample(df_train, replace=False, n_samples=50000, random_state=42)\n",
    "print(df_train_downsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e06300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .......................nb__alpha=5;, score=0.472 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .......................nb__alpha=5;, score=0.511 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .......................nb__alpha=5;, score=0.520 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .......................nb__alpha=5;, score=0.496 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .......................nb__alpha=5;, score=0.500 total time=   0.5s\n",
      "Best parameters: {'nb__alpha': 5}\n",
      "Best estimates: Pipeline(steps=[('freq',\n",
      "                 FunctionTransformer(func=<function apply_freq_encode at 0x7fd5684eab80>)),\n",
      "                ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
      "                ('nb', MultinomialNB(alpha=5))])\n",
      "Best cross-validation accuracy: 0.499903708523097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.473) total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.511) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.521) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.494) total time=   0.4s\n",
      "[CV] END ................................ score: (test=0.501) total time=   0.4s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.500106701366298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNB_conf = confusion_matrix(y_true=labels_test, y_pred=test_pred)\\nprint(\"Confusion Matrix:\\n\", NB_conf)\\n\\n# Generate classification report\\nreport = classification_report(y_true=labels_test, y_pred=test_pred)\\nprint(\"Classification Report:\\n\", report)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation\n",
    "practice_dog = df_train#[df_train_downsample['animal_type'] == 'Dog']\n",
    "practice_dog_labels = practice_dog['outcome_type']\n",
    "practice_dog_data = practice_dog.drop(columns=['outcome_type'])\n",
    "practice_train, practice_test, labels_train, labels_test = train_test_split(practice_dog_data,practice_dog_labels , test_size=0.30, random_state=42)\n",
    "\n",
    "smote = SMOTENC(categorical_features=['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed', 'is_mix', 'primary_color'], random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(practice_train, labels_train)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True)),\n",
    "   # ('smote', SMOTE(random_state=42)),  # <-- insert SMOTE here\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Set up parameter distributions for XGBoost.\n",
    "param_distributions = {\n",
    "    \"nb__alpha\": [0.1,.2, .3, .4, 0.5, 1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "# Perform hyperparameter search using RandomizedSearchCV.\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    estimator=pipeline, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=1,\n",
    "    cv=5, \n",
    "    scoring='balanced_accuracy', \n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "randomized_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "print('Best parameters:', randomized_search.best_params_)\n",
    "print('Best estimates:', randomized_search.best_estimator_)\n",
    "print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "\n",
    "cv_scores = cross_val_score(randomized_search.best_estimator_, X_resampled, y_resampled, cv=5, verbose=3, scoring='balanced_accuracy')\n",
    "print('Generalization Balanced accuracy (via cross_val_score):', cv_scores.mean())\n",
    "\n",
    "test_pred = randomized_search.predict(practice_test)\n",
    "\n",
    "'''\n",
    "NB_conf = confusion_matrix(y_true=labels_test, y_pred=test_pred)\n",
    "print(\"Confusion Matrix:\\n\", NB_conf)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true=labels_test, y_pred=test_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f28d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['intake_time', 'intake_type', 'intake_condition', 'animal_type',\n",
       "       'sex_upon_intake', 'age_upon_intake', 'breed', 'is_mix',\n",
       "       'primary_color', 'outcome_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_dog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163125/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.63      0.79      0.70     16619\n",
      "           Died       0.06      0.12      0.08       306\n",
      "     Euthanasia       0.27      0.34      0.30      1035\n",
      "Return to Owner       0.48      0.58      0.53      4827\n",
      "       Transfer       0.69      0.31      0.43     10560\n",
      "\n",
      "       accuracy                           0.59     33347\n",
      "      macro avg       0.43      0.43      0.41     33347\n",
      "   weighted avg       0.61      0.59      0.57     33347\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return to Owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intake_type_Abandoned</th>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intake_type_Euthanasia Request</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intake_type_Owner Surrender</th>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intake_type_Public Assist</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intake_type_Stray</th>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.010138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_21.151482982566677</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_22.0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_24.0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_mix_0</th>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_mix_1</th>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.008220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99523 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Adoption      Died  Euthanasia  \\\n",
       "intake_type_Abandoned               0.000177  0.000004    0.000014   \n",
       "intake_type_Euthanasia Request      0.000005  0.000004    0.000328   \n",
       "intake_type_Owner Surrender         0.003165  0.001398    0.001888   \n",
       "intake_type_Public Assist           0.000264  0.000015    0.000580   \n",
       "intake_type_Stray                   0.008976  0.011164    0.009775   \n",
       "...                                      ...       ...         ...   \n",
       "age_upon_intake_21.151482982566677  0.000003  0.000003    0.000003   \n",
       "age_upon_intake_22.0                0.000003  0.000003    0.000003   \n",
       "age_upon_intake_24.0                0.000003  0.000003    0.000003   \n",
       "is_mix_0                            0.004947  0.005088    0.003541   \n",
       "is_mix_1                            0.007629  0.007488    0.009035   \n",
       "\n",
       "                                    Return to Owner  Transfer  \n",
       "intake_type_Abandoned                      0.000063  0.000110  \n",
       "intake_type_Euthanasia Request             0.000005  0.000007  \n",
       "intake_type_Owner Surrender                0.000749  0.002060  \n",
       "intake_type_Public Assist                  0.002954  0.000272  \n",
       "intake_type_Stray                          0.008814  0.010138  \n",
       "...                                             ...       ...  \n",
       "age_upon_intake_21.151482982566677         0.000004  0.000003  \n",
       "age_upon_intake_22.0                       0.000004  0.000003  \n",
       "age_upon_intake_24.0                       0.000004  0.000003  \n",
       "is_mix_0                                   0.004463  0.004356  \n",
       "is_mix_1                                   0.008114  0.008220  \n",
       "\n",
       "[99523 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Iteration of NB\n",
    "practice_dog = df_train#[df_train_downsample['animal_type'] == 'Dog']\n",
    "practice_dog_labels = practice_dog['outcome_type']\n",
    "practice_dog_data = practice_dog.drop(columns=['outcome_type'])\n",
    "practice_train, practice_test, labels_train, labels_test = train_test_split(practice_dog_data,practice_dog_labels , test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "smote = SMOTENC(categorical_features=['intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed', 'is_mix', 'primary_color'], random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(practice_train, labels_train)\n",
    "\n",
    "ft =  FunctionTransformer(apply_freq_encode, validate=False)\n",
    "X_freq = ft.fit_transform(X_resampled)\n",
    "\n",
    "oh = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "X_encoded = oh.fit_transform(X_freq)\n",
    "\n",
    "nb = MultinomialNB(alpha=10)\n",
    "nb.fit(X_encoded, y_resampled)\n",
    "\n",
    "X_test_freq = ft.transform(practice_test)\n",
    "X_test_encoded = oh.transform(X_test_freq)\n",
    "\n",
    "# Predict\n",
    "y_pred = nb.predict(X_test_encoded)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "classification_report_with_accuracy_score(labels_test, y_pred)\n",
    "\n",
    "# Convert log probabilities to actual probabilities\n",
    "feature_probs = np.exp(nb.feature_log_prob_)  # shape: (n_classes, n_features)\n",
    "\n",
    "\n",
    "feature_names = oh.get_feature_names_out()  # after one-hot encoding\n",
    "\n",
    "\n",
    "'''\n",
    "pd.set_option('display.max_rows', None)       # Show all rows\n",
    "pd.set_option('display.max_columns', None)    # Show all columns\n",
    "pd.set_option('display.width', None)          # No line wrapping\n",
    "#pd.set_option('display.max_colwidth', None)   # Don't truncate column content\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Build DataFrame: rows = features, columns = classes\n",
    "feature_prob_df = pd.DataFrame(feature_probs.T, index=feature_names, columns=nb.classes_)\n",
    "cleaned_df = feature_prob_df[~feature_prob_df.index.str.contains(\"intake_time\")]\n",
    "no_breed_no_color = cleaned_df[~cleaned_df.index.str.contains(\"primary_color\")]\n",
    "no_breed_no_color = no_breed_no_color[~no_breed_no_color.index.str.contains(\"breed\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85bda2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return to Owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_0.0002300549036006838</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_0.0002373323443590971</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_0.0002378207571990604</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_0.00024073379689816099</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_0.00024083506444665115</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_21.151482982566677</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_22.0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_upon_intake_24.0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_mix_0</th>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_mix_1</th>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.008220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99463 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Adoption      Died  Euthanasia  \\\n",
       "age_upon_intake_0.0002300549036006838   0.000003  0.000004    0.000003   \n",
       "age_upon_intake_0.0002373323443590971   0.000003  0.000004    0.000003   \n",
       "age_upon_intake_0.0002378207571990604   0.000003  0.000004    0.000003   \n",
       "age_upon_intake_0.00024073379689816099  0.000003  0.000004    0.000003   \n",
       "age_upon_intake_0.00024083506444665115  0.000003  0.000004    0.000003   \n",
       "...                                          ...       ...         ...   \n",
       "age_upon_intake_21.151482982566677      0.000003  0.000003    0.000003   \n",
       "age_upon_intake_22.0                    0.000003  0.000003    0.000003   \n",
       "age_upon_intake_24.0                    0.000003  0.000003    0.000003   \n",
       "is_mix_0                                0.004947  0.005088    0.003541   \n",
       "is_mix_1                                0.007629  0.007488    0.009035   \n",
       "\n",
       "                                        Return to Owner  Transfer  \n",
       "age_upon_intake_0.0002300549036006838          0.000003  0.000003  \n",
       "age_upon_intake_0.0002373323443590971          0.000003  0.000003  \n",
       "age_upon_intake_0.0002378207571990604          0.000003  0.000003  \n",
       "age_upon_intake_0.00024073379689816099         0.000003  0.000003  \n",
       "age_upon_intake_0.00024083506444665115         0.000003  0.000003  \n",
       "...                                                 ...       ...  \n",
       "age_upon_intake_21.151482982566677             0.000004  0.000003  \n",
       "age_upon_intake_22.0                           0.000004  0.000003  \n",
       "age_upon_intake_24.0                           0.000004  0.000003  \n",
       "is_mix_0                                       0.004463  0.004356  \n",
       "is_mix_1                                       0.008114  0.008220  \n",
       "\n",
       "[99463 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_breed_no_color.iloc[60:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ddd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m y_train_encoded \u001b[38;5;241m=\u001b[39m le_train\u001b[38;5;241m.\u001b[39mfit_transform(y_train)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m best_estimator, predictions_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_NB_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m predictions \u001b[38;5;241m=\u001b[39m le_train\u001b[38;5;241m.\u001b[39minverse_transform(predictions_encoded)\n\u001b[1;32m     50\u001b[0m save_predictions(predictions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mtrain_NB_classifier\u001b[0;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Construct the pipeline:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#   1. Apply frequency encoding (for example, on 'primary_color' & 'breed' if implemented in apply_freq_encode)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#   3. Fit an XGBClassifier.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTENC(categorical_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintake_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintake_condition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_upon_intake\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_mix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary_color\u001b[39m\u001b[38;5;124m'\u001b[39m], random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     23\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m'\u001b[39m, FunctionTransformer(apply_freq_encode, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[1;32m     24\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, MultinomialNB())\n\u001b[1;32m     26\u001b[0m ])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Set up parameter distributions for XGBoost.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/imblearn/base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:717\u001b[0m, in \u001b[0;36mSMOTENC._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m    716\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mkneighbors(X_class, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 717\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n\u001b[1;32m    721\u001b[0m y_resampled\u001b[38;5;241m.\u001b[39mappend(y_new)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:128\u001b[0m, in \u001b[0;36mBaseSMOTE._make_samples\u001b[0;34m(self, X, y_dtype, y_type, nn_data, nn_num, n_samples, step_size, y)\u001b[0m\n\u001b[1;32m    125\u001b[0m rows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor_divide(samples_indices, nn_num\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    126\u001b[0m cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmod(samples_indices, nn_num\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 128\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m y_new \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(n_samples, fill_value\u001b[38;5;241m=\u001b[39my_type, dtype\u001b[38;5;241m=\u001b[39my_dtype)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_new, y_new\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:803\u001b[0m, in \u001b[0;36mSMOTENC._generate_samples\u001b[0;34m(self, X, nn_data, nn_num, rows, cols, steps, y_type, y)\u001b[0m\n\u001b[1;32m    800\u001b[0m     col_sels \u001b[38;5;241m=\u001b[39m max_idxs[idx_sels, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    802\u001b[0m     ys \u001b[38;5;241m=\u001b[39m start_idx \u001b[38;5;241m+\u001b[39m col_sels\n\u001b[0;32m--> 803\u001b[0m     \u001b[43mX_new\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    804\u001b[0m     X_new[xs, ys] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_new\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_lil.py:331\u001b[0m, in \u001b[0;36mlil_matrix.__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_intXint(key[\u001b[38;5;241m0\u001b[39m], key[\u001b[38;5;241m1\u001b[39m], x)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Everything else takes the normal path.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[43mIndexMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_index.py:146\u001b[0m, in \u001b[0;36mIndexMixin.__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    145\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(i\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_arrayXarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_lil.py:303\u001b[0m, in \u001b[0;36mlil_matrix._set_arrayXarray\u001b[0;34m(self, row, col, x)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_arrayXarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, col, x):\n\u001b[1;32m    302\u001b[0m     i, j, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39matleast_2d, _prepare_index_for_memoryview(row, col, x))\n\u001b[0;32m--> 303\u001b[0m     \u001b[43m_csparsetools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlil_fancy_set\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# For Dog:\n",
    "'''\n",
    "train_dog = df_train_downsample[df_train_downsample['animal_type'] == 'Dog'].copy()\n",
    "X_train_dog = train_dog.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_dog = train_dog['outcome_type']\n",
    "\n",
    "test_dog = df_test[df_test['animal_type'] == 'Dog'].copy()\n",
    "X_test_dog = test_dog.drop(columns=['animal_type'])\n",
    "\n",
    "# For Cat:\n",
    "train_cat = df_train_downsample[df_train_downsample['animal_type'] == 'Cat'].copy()\n",
    "X_train_cat = train_cat.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_cat = train_cat['outcome_type']\n",
    "\n",
    "test_cat = df_test[df_test['animal_type'] == 'Cat'].copy()\n",
    "X_test_cat = test_cat.drop(columns=['animal_type'])\n",
    "\n",
    "## Encode targets with LabelEncoder\n",
    "# Dog encoding\n",
    "le_dog = LabelEncoder()\n",
    "y_train_dog_encoded = le_dog.fit_transform(y_train_dog)\n",
    "\n",
    "# Cat encoding\n",
    "le_cat = LabelEncoder()\n",
    "y_train_cat_encoded = le_cat.fit_transform(y_train_cat)\n",
    "'''\n",
    "\n",
    "'''\n",
    "print(\"Training model for Dog data:\")\n",
    "best_estimator_dog, dog_predictions_encoded = train_NB_classifier(X_train_dog, y_train_dog_encoded, X_test_dog)\n",
    "dog_predictions = le_dog.inverse_transform(dog_predictions_encoded)\n",
    "\n",
    "'''\n",
    "# Don't split cat and dog\n",
    "X_train = df_train.drop(columns=['outcome_type'])\n",
    "y_train = df_train['outcome_type']\n",
    "\n",
    "X_test = df_test\n",
    "\n",
    "le_train = LabelEncoder()\n",
    "y_train_encoded = le_train.fit_transform(y_train)\n",
    "\n",
    "\n",
    "print(\"\\nTraining model\")\n",
    "best_estimator, predictions_encoded = train_NB_classifier(X_train, y_train_encoded, X_test)\n",
    "predictions = le_train.inverse_transform(predictions_encoded)\n",
    "\n",
    "\n",
    "save_predictions(predictions, \"NB\")\n",
    "print(\"DONE!\\n\", best_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fc90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366358a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dc434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09e0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d864b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf1f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71dc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f092d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d1fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
