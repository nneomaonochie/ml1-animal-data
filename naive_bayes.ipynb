{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in /u/nneoma/.local/lib/python3.8/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /u/nneoma/.local/lib/python3.8/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /u/nneoma/.local/lib/python3.8/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /u/nneoma/.local/lib/python3.8/site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /u/nneoma/.local/lib/python3.8/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /u/nneoma/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (0.20.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /u/nneoma/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (6.4.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /u/nneoma/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /u/nneoma/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (1.3.10)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /u/nneoma/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /u/nneoma/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /u/nneoma/.local/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /u/nneoma/.local/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema>=2.6->nbformat) (3.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Read your notebook (assuming version 4 for example purposes)\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/lib/python3/dist-packages (from xgboost) (1.3.3)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from xgboost) (1.17.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d09f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6921ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_NB_classifier(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains an Naive Bayes Multinominal model using a pipeline that includes a frequency encoding transformation,\n",
    "    OneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series or np.array): Training target values.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "    \n",
    "    Returns:\n",
    "        best_estimator: The best estimator from RandomizedSearchCV.\n",
    "        test_predictions: The predicted labels for X_test from the best estimator.\n",
    "    \"\"\"\n",
    "    # Construct the pipeline:\n",
    "    #   1. Apply frequency encoding (for example, on 'primary_color' & 'breed' if implemented in apply_freq_encode)\n",
    "    #   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\n",
    "    #   3. Fit an XGBClassifier.\n",
    "    pipeline = Pipeline([\n",
    "        ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # Set up parameter distributions for XGBoost.\n",
    "    param_distributions = {\n",
    "        \"nb__alpha\": [0.1, 0.5, 1, 2, 5, 10],\n",
    "    }\n",
    "    \n",
    "    # Perform hyperparameter search using RandomizedSearchCV.\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline, \n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=1,\n",
    "        cv=5, \n",
    "        scoring='balanced_accuracy', \n",
    "        verbose=3,\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "    \n",
    "    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=5, verbose=3, scoring='balanced_accuracy')\n",
    "    print('Generalization Balanced accuracy (via cross_val_score):', cv_scores.mean())\n",
    "\n",
    "    # Make predictions on the test set using the best estimator.\n",
    "    test_predictions = randomized_search.predict(X_test)\n",
    "    \n",
    "    return randomized_search.best_estimator_, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "168a8b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# downsampling\n",
    "from sklearn.utils import resample\n",
    "df_train_downsample = resample(df_train, replace=False, n_samples=50000, random_state=42)\n",
    "print(df_train_downsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to figure out SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] nb__alpha=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... nb__alpha=0.4, score=0.335, total=   1.9s\n",
      "[CV] nb__alpha=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... nb__alpha=0.4, score=0.347, total=   1.9s\n",
      "[CV] nb__alpha=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... nb__alpha=0.4, score=0.339, total=   1.8s\n",
      "[CV] nb__alpha=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... nb__alpha=0.4, score=0.336, total=   1.9s\n",
      "[CV] nb__alpha=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... nb__alpha=0.4, score=0.347, total=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.3s finished\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'nb__alpha': 0.4}\n",
      "Best cross-validation accuracy: 0.3406683555569499\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.335, total=   1.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.345, total=   1.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.336, total=   1.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.335, total=   1.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.346, total=   1.8s\n",
      "Generalization Balanced accuracy (via cross_val_score): 0.339563857464952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.3s finished\n",
      "/tmp/ipykernel_4120395/2931022905.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(freq_series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4339    0    1  227  364]\n",
      " [  54    0    0    5   43]\n",
      " [ 152    0    7   42   96]\n",
      " [ 742    0    0  672   49]\n",
      " [1760    0    1  159 1287]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.62      0.88      0.72      4931\n",
      "           Died       0.00      0.00      0.00       102\n",
      "     Euthanasia       0.78      0.02      0.05       297\n",
      "Return to Owner       0.61      0.46      0.52      1463\n",
      "       Transfer       0.70      0.40      0.51      3207\n",
      "\n",
      "       accuracy                           0.63     10000\n",
      "      macro avg       0.54      0.35      0.36     10000\n",
      "   weighted avg       0.64      0.63      0.60     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "practice_dog = df_train_downsample#[df_train_downsample['animal_type'] == 'Dog']\n",
    "practice_dog_labels = practice_dog['outcome_type']\n",
    "practice_dog_data = practice_dog.drop(columns=['outcome_type'])\n",
    "practice_train, practice_test, labels_train, labels_test = train_test_split(practice_dog_data,practice_dog_labels , test_size=0.20, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Set up parameter distributions for XGBoost.\n",
    "param_distributions = {\n",
    "    \"nb__alpha\": [0.1,.2, .3, .4, 0.5, 1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "# Perform hyperparameter search using RandomizedSearchCV.\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    estimator=pipeline, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=1,\n",
    "    cv=5, \n",
    "    scoring='balanced_accuracy', \n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "randomized_search.fit(practice_train, labels_train)\n",
    "\n",
    "print('Best parameters:', randomized_search.best_params_)\n",
    "print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "\n",
    "cv_scores = cross_val_score(randomized_search.best_estimator_, practice_train, labels_train, cv=5, verbose=3, scoring='balanced_accuracy')\n",
    "print('Generalization Balanced accuracy (via cross_val_score):', cv_scores.mean())\n",
    "\n",
    "test_pred = randomized_search.predict(practice_test)\n",
    "\n",
    "\n",
    "NB_conf = confusion_matrix(y_true=labels_test, y_pred=test_pred)\n",
    "print(\"Confusion Matrix:\\n\", NB_conf)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true=labels_test, y_pred=test_pred)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ddd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Dog data:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sparse_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m y_train_cat_encoded \u001b[38;5;241m=\u001b[39m le_cat\u001b[38;5;241m.\u001b[39mfit_transform(y_train_cat)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model for Dog data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m best_estimator_dog, dog_predictions_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_NB_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_dog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_dog_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_dog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m dog_predictions \u001b[38;5;241m=\u001b[39m le_dog\u001b[38;5;241m.\u001b[39minverse_transform(dog_predictions_encoded)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining model for Cat data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mtrain_NB_classifier\u001b[0;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTrains an Naive Bayes Multinominal model using a pipeline that includes a frequency encoding transformation,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mOneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    test_predictions: The predicted labels for X_test from the best estimator.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Construct the pipeline:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#   1. Apply frequency encoding (for example, on 'primary_color' & 'breed' if implemented in apply_freq_encode)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#   3. Fit an XGBClassifier.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     20\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m'\u001b[39m, FunctionTransformer(apply_freq_encode, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[0;32m---> 21\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m),\n\u001b[1;32m     22\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, MultinomialNB())\n\u001b[1;32m     23\u001b[0m ])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Set up parameter distributions for XGBoost.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m param_distributions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnb__alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m     28\u001b[0m }\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'sparse_output'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# For Dog:\n",
    "train_dog = df_train[df_train['animal_type'] == 'Dog'].copy()\n",
    "X_train_dog = train_dog.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_dog = train_dog['outcome_type']\n",
    "\n",
    "test_dog = df_test[df_test['animal_type'] == 'Dog'].copy()\n",
    "X_test_dog = test_dog.drop(columns=['animal_type'])\n",
    "\n",
    "# For Cat:\n",
    "train_cat = df_train[df_train['animal_type'] == 'Cat'].copy()\n",
    "X_train_cat = train_cat.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_cat = train_cat['outcome_type']\n",
    "\n",
    "test_cat = df_test[df_test['animal_type'] == 'Cat'].copy()\n",
    "X_test_cat = test_cat.drop(columns=['animal_type'])\n",
    "\n",
    "## Encode targets with LabelEncoder\n",
    "# Dog encoding\n",
    "le_dog = LabelEncoder()\n",
    "y_train_dog_encoded = le_dog.fit_transform(y_train_dog)\n",
    "\n",
    "# Cat encoding\n",
    "le_cat = LabelEncoder()\n",
    "y_train_cat_encoded = le_cat.fit_transform(y_train_cat)\n",
    "\n",
    "print(\"Training model for Dog data:\")\n",
    "best_estimator_dog, dog_predictions_encoded = train_NB_classifier(X_train_dog, y_train_dog_encoded, X_test_dog)\n",
    "dog_predictions = le_dog.inverse_transform(dog_predictions_encoded)\n",
    "\n",
    "print(\"\\nTraining model for Cat data:\")\n",
    "best_estimator_cat, cat_predictions_encoded = train_NB_classifier(X_train_cat, y_train_cat_encoded, X_test_cat)\n",
    "cat_predictions = le_cat.inverse_transform(cat_predictions_encoded)\n",
    "\n",
    "combine_predictions(dog_predictions, cat_predictions, X_test_dog, X_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
