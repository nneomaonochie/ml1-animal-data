{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6786200",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5f819ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /u/nneoma/.local/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /u/nneoma/.local/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae12383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d346067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR DATA CLEANING - all the stuff should be here\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train = df_train[df_train['intake_type'] != 'Wildlife']\n",
    "df_train = df_train.dropna(subset=['age_upon_intake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42369420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    cols_to_drop = ['id', 'name', 'date_of_birth', 'outcome_time', 'found_location']\n",
    "    existing_cols = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11b21d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for when you want to use hour and month as NUMERICAL -- this is because the models need to know that these months / hours wrap around\n",
    "def time_as_cyclical(df):\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['intake_hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['intake_hour'] / 24)\n",
    "\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['intake_month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['intake_month'] / 12)\n",
    "\n",
    "    df = df.drop(columns=['intake_hour', 'intake_month'])\n",
    "    return df\n",
    "\n",
    "def bucket_seasons(df):\n",
    "    def month_to_season(month):\n",
    "        if month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        elif month in [9, 10, 11]:\n",
    "            return 'Fall'\n",
    "        elif month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "\n",
    "    df['season'] = df['intake_month'].apply(month_to_season)\n",
    "    return df\n",
    "\n",
    "def bucket_days(df):\n",
    "    def hour_to_time_of_day(hour):\n",
    "        if hour in [5, 6, 7, 8, 9, 10, 11]:\n",
    "            return 'Morning'\n",
    "        elif hour in [12, 13, 14, 15, 16, 17]:\n",
    "            return 'Afternoon'\n",
    "        elif hour in [18, 19]:\n",
    "            return 'Evening'\n",
    "        elif hour in [20, 21, 22, 23, 0, 1, 2, 3, 4]:\n",
    "            return 'Night'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "\n",
    "    df['time_of_day'] = df['intake_hour'].apply(hour_to_time_of_day)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "812c087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this converts intake_time into different columns for years, months, hours, and if it is a weekend\n",
    "def engineer_time(df):\n",
    "    df['intake_datetime'] = pd.to_datetime(df['intake_time'], unit='s')\n",
    "    df['intake_year'] = df['intake_datetime'].dt.year\n",
    "    df['intake_month'] = df['intake_datetime'].dt.month\n",
    "    # df['intake_dayofweek'] = df['intake_datetime'].dt.dayofweek\n",
    "    df['intake_hour'] = df['intake_datetime'].dt.hour\n",
    "    # df['is_weekend'] = df['intake_dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "\n",
    "    df = df.drop(columns=['intake_time', 'intake_datetime' ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc333ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_in_months(age_str):\n",
    "    \"\"\"\n",
    "    Convert age strings to months.\n",
    "    Expected format: \"<number> <unit>\" e.g., \"2 years\", \"8 months\", \"3 weeks\", \"15 days\"\n",
    "    \"\"\"\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num = float(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    unit = parts[1].lower()\n",
    "    if \"year\" in unit:\n",
    "        return num * 12\n",
    "    elif \"month\" in unit:\n",
    "        return num\n",
    "    elif \"week\" in unit:\n",
    "        return num / 4  # approx. weeks in a month\n",
    "    elif \"day\" in unit:\n",
    "        return num / 30.0  # approx. days in a month\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64692110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_time(df):\n",
    "    # Intake Time\n",
    "    # Convert string timestamps to UNIX timestamp\n",
    "    dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n",
    "    df['intake_time'] = dt_series.astype('int64') // (10 ** 9)\n",
    "    return engineer_time(df)\n",
    "\n",
    "# Age Upon Intake\n",
    "def convert_age(age_str):\n",
    "    \"\"\"\n",
    "    Convert age strings to years.\n",
    "    Expected format: \"<number> <unit>\" e.g., \"2 years\", \"8 months\", \"3 weeks\", \"15 days\"\n",
    "    \"\"\"\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num = float(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    unit = parts[1].lower()\n",
    "    if \"year\" in unit:\n",
    "        return num\n",
    "    elif \"month\" in unit:\n",
    "        return num / 12\n",
    "    elif \"week\" in unit:\n",
    "        return num / 52\n",
    "    elif \"day\" in unit:\n",
    "        return num / 365\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_age_and_sex_upon_intake(df):\n",
    "    df.loc[df['sex_upon_intake'].isna(), 'sex_upon_intake'] = 'Unknown'\n",
    "    df['age_upon_intake'] = df['age_upon_intake'].apply(age_in_months)#(convert_age)\n",
    "    df.loc[df['age_upon_intake'] < 0, 'age_upon_intake'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57201a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cat_rarity(df):\n",
    "    is_domestic = df[\"breed\"].str.lower().str.contains(\"domestic\", na=False)\n",
    "    df.loc[~is_domestic, \"breed\"] = \"Rare\"\n",
    "    df.loc[is_domestic, \"breed\"] = \"Common\"\n",
    "    df['size'] = 2\n",
    "    df[\"size\"] = df[\"size\"].astype(int)  # enforce int type\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b43298a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_breed(df):\n",
    "    # Create is_mix column\n",
    "    df['is_mix'] = (df['breed'].str.contains('mix', case=False, na=False).astype(int)) | (df['breed'].str.contains('/', case=False, na=False).astype(int))\n",
    "    # remove mix from all breeds\n",
    "    df['breed'] = df['breed'].str.replace(' mix', '', case=False)\n",
    "\n",
    "    df_dog = map_dog_cluster(df[df['animal_type'] == 'Dog'].copy())\n",
    "    df_cat = map_cat_rarity(df[df['animal_type'] == 'Cat'].copy())\n",
    "\n",
    "    # Add cleaned dog and cat records back\n",
    "    df_cleaned = pd.concat([df_dog, df_cat])\n",
    "\n",
    "    # Sort back to the original order using the index\n",
    "    df_cleaned = df_cleaned.sort_index()\n",
    "\n",
    "    df_cleaned.head()\n",
    "    df_cleaned['size'] = df_cleaned['size'].fillna(3).astype(int)\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a834ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual corrections BEFORE splitting / \n",
    "manual_fixes = {\n",
    "  'Black/Tan Hound': 'English Coonhound', \n",
    "  'Black/Tan Hound/Black Mouth Cur': 'English Coonhound',\n",
    "  'Black/Tan Hound/Catahoula': 'English Coonhound', \n",
    "  'Black/Tan Hound/Doberman Pinsch': 'English Coonhound',\n",
    "  'Black/Tan Hound/Great Dane': 'English Coonhound',\n",
    "  'Black/Tan Hound/Labrador Retriever': 'English Coonhound',\n",
    "  'Black/Tan Hound/Siberian Husky': 'English Coonhound',\n",
    "  'Catahoula/Black/Tan Hound': 'Catahoula',\n",
    "  'Dachshund Stan': 'Dachshund',\n",
    "  'Dachshund/Black/Tan Hound': 'Dachshund',\n",
    "  'Doberman Pinsch/Black/Tan Hound': 'Doberman Pinsch',\n",
    "  'German Shepherd/Black/Tan Hound': 'German Shepherd',\n",
    "  'Labrador Retriever/Black/Tan Hound': 'Labrador Retriever',\n",
    "  'Plott Hound/Black/Tan Hound': 'Plott Hound',\n",
    "  'Dachshund Stan Mix': 'Dachshund',\n",
    "\n",
    "  # nneomas mappings (may have created new breeds in dog_info)\n",
    "  \"Boxer/Miniature Poodle\" : \"Boxerdoodle\",\n",
    "  \"Minature Poodle/Boxer\" : \"Boxerdoodle\",\n",
    "  \"Miniature Poodle/Cocker Spaniel\": \"Cockapoo\",\n",
    "  \"Cocker Spaniel/Miniature Poodle\": \"Cockapoo\",\n",
    "  \"Miniature Poodle/English Cocker Spaniel\": \"Cockapoo\",\n",
    "  \"English Cocker Spaniel/Miniature Poodle\": \"Cockapoo\",\n",
    "  \"Toy Poodle/Cocker Spaniel\": \"Cockapoo\",\n",
    "  \"Cocker Spaniel/Toy Poodle\": \"Cockapoo\",\n",
    "  \"Toy Poodle/English Cocker Spaniel\": \"Cockapoo\",\n",
    "  \"English Cocker Spaniel/Toy Poodle\": \"Cockapoo\",\n",
    "  \"Standard Poodle/Cocker Spaniel\": \"Cockapoo\",\n",
    "  \"Cocker Spaniel/Standard Poodle\": \"Cockapoo\",\n",
    "  \"Standard Poodle/English Cocker Spaniel\": \"Cockapoo\",\n",
    "  \"English Cocker Spaniel/Standard Poodle\": \"Cockapoo\",\n",
    "  \"Miniature Poodle/Lhasa Apso\": \"Lhasapoo\",\n",
    "  \"Lhasa Apso/Miniature Poodle\": \"Lhasapoo\",\n",
    "  \"Lhasa Apso/Toy Poodle\": \"Lhasapoo\",\n",
    "  \"Toy Poodle/Lhasa Apso\": \"Lhasapoo\",\n",
    "  \"Standard Poodle/Lhasa Apso\": \"Lhasapoo\",\n",
    "  \"Lhasa Apso/Standard Poodle\": \"Lhasapoo\",\n",
    "  \"Standard Poodle/Labrador Retriever\": \"Labradoodle\",\n",
    "  \"Labrador Retriever/Standard Poodle\": \"Labradoodle\",\n",
    "  \"Labrador Retriever/Miniature Poodle\": \"Labradoodle Miniature\",\n",
    "  \"Miniature Poodle/Labrador Retriever\": \"Labradoodle Miniature\",\n",
    "  \"Labrador Retriever/Toy Poodle\": \"Labradoodle Miniature\",\n",
    "  \"Toy Poodle/Labrador Retriever\": \"Labradoodle Miniature\",\n",
    "  \"Yorkshire Terrier/Miniature Poodle\" : \"Yorkipoo\",\n",
    "  \"Miniature Poodle/Yorkshire Terrier\" : \"Yorkipoo\",\n",
    "  \"Yorkshire Terrier/Toy Poodle\" : \"Yorkipoo\",\n",
    "  \"Toy Poodle/Yorkshire Terrier\" : \"Yorkipoo\",\n",
    "  \"Yorkshire Terrier/Standard Poodle \" : \"Yorkipoo\",\n",
    "  \"Standard Poodlee/Yorkshire Terrier\" : \"Yorkipoo\",\n",
    "  # Mini Schnoodle (Mini Schnauzer x Mini or Toy Poodle)\n",
    "  \"Miniature Schnauzer/Miniature Poodle\": \"Mini Schnoodle\",\n",
    "  \"Miniature Poodle/Miniature Schnauzer\": \"Mini Schnoodle\",\n",
    "  \"Miniature Schnauzer/Toy Poodle\": \"Mini Schnoodle\",\n",
    "  \"Toy Poodle/Miniature Schnauzer\": \"Mini Schnoodle\",\n",
    "  # Standard Schnoodle (Miniature or Standard Schnauzer x Mini or Standard Poodle)\n",
    "  \"Standard Schnauzer/Miniature Poodle\": \"Standard Schnoodle\",\n",
    "  \"Miniature Poodle/Standard Schnauzer\": \"Standard Schnoodle\",\n",
    "  \"Miniature Schnauzer/Standard Poodle\": \"Standard Schnoodle\",\n",
    "  \"Standard Poodle/Miniature Schnauzer\": \"Standard Schnoodle\",\n",
    "  \"Standard Schnauzer/Toy Poodle\": \"Standard Schnoodle\",\n",
    "  \"Toy Poodle/Standard Schnauzer\": \"Standard Schnoodle\",\n",
    "  # Giant Schnoodle (Giant Schnauzer x Standard Poodle)\n",
    "  \"Standard Schnauzer/Standard Poodle\": \"Giant Schnoodle\",\n",
    "  \"Standard Poodle/Standard Schnauzer\": \"Giant Schnoodle\",\n",
    "  \"Schnauzer Giant/Standard Poodle\": \"Giant Schnoodle\",\n",
    "  \"Standard Poodle/Schnauzer Giant\": \"Giant Schnoodle\",\n",
    "  \"German Shepherd/Pit Bull\" : \"German Shepherd Pit Bull\",\n",
    "  \"Pit Bull/German Shepherd\" : \"German Shepherd Pit Bull\",\n",
    "  \"Labrador Retriever/Pit Bull\":\"Labrabull\",\n",
    "  \"Pit Bull/Labrador Retriever\":\"Labrabull\",\n",
    "  \"Labrador Retriever/American Pit Bull Terrier\": \"Labrabull\",\n",
    "  \"American Pit Bull Terrier/Labrador Retriever\": \"Labrabull\",\n",
    "  \"German Shepherd/Labrador Retriever\": \"German Sheprador\",\n",
    "  \"Labrador Retriever/German Shepherd\": \"German Sheprador\",\n",
    "  \"Australian Shepherd/Labrador Retriever\": \"Australian Shepherd Lab\", \n",
    "  \"Labrador Retriever/Australian Shepherd\": \"Australian Shepherd Lab\",\n",
    "  \"Chihuahua Shorthair/Dachshund\": \"Chiweenie\",\n",
    "  \"Dachshund/Chihuahua Shorthair\": \"Chiweenie\",\n",
    "  \"Dachshund Longhair/Chihuahua Longhair\": \"Chiweenie\",\n",
    "  \"Chihuahua Shorthair/Dachshund Wirehair\": \"Chiweenie\",\n",
    "  \"Dachshund Wirehair/Chihuahua Shorthair\": \"Chiweenie\",\n",
    "  \"Chihuahua Longhair/Dachshund\": \"Chiweenie\",\n",
    "  \"Dachshund/Chihuahua Longhair\": \"Chiweenie\",\n",
    "  \"Dachshund Longhair/Chihuahua Shorthair\": \"Chiweenie\",\n",
    "  \"Chihuahua Longhair/Dachshund Longhair\": \"Chiweenie\",\n",
    "  \"Dachshund Wirehair/Chihuahua Longhair\": \"Chiweenie\",\n",
    "  \"Chihuahua Longhair/Dachshund Wirehair\": \"Chiweenie\",\n",
    "  \"Chihuahua Shorthair/Dachshund Longhair\": \"Chiweenie\",\n",
    "  \"Labrador Retriever/Border Collie\": \"Borador\",\n",
    "  \"Border Collie/Labrador Retriever\": \"Borador\",\n",
    "  \"Maltese/Miniature Poodle\": \"Maltipoo\",\n",
    "  \"Miniature Poodle/Maltese\": \"Maltipoo\",\n",
    "  \"Maltese/Toy Poodle\": \"Maltipoo\",\n",
    "  \"Toy Poodle/Maltese\": \"Maltipoo\",\n",
    "  \"Maltese/Standard Poodle\": \"Maltipoo\",\n",
    "  \"Standard Poodle/Maltese\": \"Maltipoo\",\n",
    "  \"Pit Bull/Boxer\": \"Bullboxer Pit\",\n",
    "  \"Boxer/Pit Bull\" : \"Bullboxer Pit\",\n",
    "  \"Boxer/American Pit Bull Terrier\" : \"Bullboxer Pit\",\n",
    "  \"American Pit Bull Terrier/Boxer\" : \"Bullboxer Pit\",\n",
    "  \"Siberian Husky/German Shepherd\" : \"Shepsky\",\n",
    "  \"German Shepherd/Siberian Husky\" : \"Shepsky\",\n",
    "  \"Australian Shepherd/Siberian Husky\" : \"Australian Shepherd Husky\",\n",
    "  \"Siberian Husky/Australian Shepherd\" : \"Australian Shepherd Husky\",\n",
    "  \"Australian Shepherd/Pit Bull\" : \"Australian Shepherd Pit Bull\",\n",
    "  \"Pit Bull/Australian Shepherd\" : \"Australian Shepherd Pit Bull\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f84ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging to file\n",
    "logging.basicConfig(\n",
    "    filename='breed_mapping.log',         # Log file name\n",
    "    level=logging.INFO,                   # Log level (use DEBUG for more detail)\n",
    "    format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceed9b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (916673925.py, line 105)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[63], line 105\u001b[0;36m\u001b[0m\n\u001b[0;31m    breed_cluster_df = pd.read_csv('dog_breed_to_cluster_map.csv')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def map_dog_cluster(df):\n",
    "    # Load data\n",
    "    dog_info = pd.read_csv('dog_info.csv')\n",
    "    known_breeds = set(dog_info['Breed Name'].dropna().unique())\n",
    "\n",
    "    # Clean dog records\n",
    "    df_dog = df[df[\"animal_type\"] == \"Dog\"].copy()\n",
    "\n",
    "    # Merge to find unmatched\n",
    "    breeds = pd.merge(df_dog, dog_info, left_on='breed', right_on='Breed Name', how='left')\n",
    "    unmapped = breeds[breeds['Breed Name'].isna()]\n",
    "    unmapped_breed_list = sorted([str(b).strip() for b in unmapped['breed'].dropna().unique()])\n",
    "   # print(breeds.head())\n",
    "    # Create final rename mapping and unmatched list\n",
    "    breed_rename_map = {}\n",
    "    unmatched_breeds = []\n",
    "    \n",
    "    logging.info(\"\\n[LOG] Starting breed resolution process...\\n\")\n",
    "\n",
    "    for original_breed in unmapped_breed_list:\n",
    "        # Apply manual correction if available\n",
    "        if original_breed in manual_fixes:\n",
    "            fixed = manual_fixes[original_breed]\n",
    "            logging.info(f\"[MANUAL] '{original_breed}' → '{fixed}'\")\n",
    "            breed_rename_map[original_breed] = fixed\n",
    "            continue\n",
    "\n",
    "        # Split the breed string\n",
    "        parts = [p.strip() for p in original_breed.split('/')]\n",
    "\n",
    "        # Check for \"Mix\" at the end\n",
    "        if original_breed.strip().endswith(\"Mix\"):\n",
    "            candidate = original_breed.replace(\"Mix\", \"\").strip()\n",
    "            if candidate in known_breeds:\n",
    "                logging.info(f\"[MIX] '{original_breed}' ends in 'Mix', resolved to known breed '{candidate}'\")\n",
    "                breed_rename_map[original_breed] = candidate\n",
    "            else:\n",
    "                logging.warning(f\"[MIX-FAIL] '{original_breed}' ends in 'Mix' but '{candidate}' not found in dog_info\")\n",
    "                unmatched_breeds.append(original_breed)\n",
    "            continue\n",
    "\n",
    "        # Try resolving multi-part breed\n",
    "        matched = None\n",
    "        for part in parts:\n",
    "            if part in known_breeds:\n",
    "                matched = part\n",
    "                logging.info(f\"[MATCH] '{original_breed}' → first matched breed '{matched}'\")\n",
    "                breed_rename_map[original_breed] = matched\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            logging.warning(f\"[UNMATCHED] No parts of '{original_breed}' matched known breeds\")\n",
    "            unmatched_breeds.append(original_breed)\n",
    "\n",
    "    # Apply initial mapping\n",
    "    df_dog['breed'] = df_dog['breed'].apply(\n",
    "        lambda b: manual_fixes.get(b, breed_rename_map.get(b, b))\n",
    "    )\n",
    "\n",
    "    '''\n",
    "    # editing something\n",
    "    traits = [\n",
    "        'Good For Novice Owners',\n",
    "        'Tolerates Being Alone',\n",
    "        'Kid-Friendly',\n",
    "        'Easy To Groom',\n",
    "        'General Health',\n",
    "        'Energy Level',\n",
    "        'Exercise Needs',\n",
    "        'Potential For Playfulness'\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Loop through each trait and map from breed name\n",
    "    for trait in traits:\n",
    "        trait_col_name = trait.lower().replace(' ', '_')  # Create clean column names\n",
    "        # Replace 'No' with 0 in the source table (we won't change the original dog_info)\n",
    "        temp_series = dog_info[trait].replace({'No' : '1', 'Moderate' : '3'})\n",
    "        #temp_series = temp_series.replace()\n",
    "        # Create the mapping\n",
    "        mapping_dict = dict(zip(dog_info['Breed Name'], temp_series))\n",
    "        # Apply to df_dog\n",
    "        df_dog[trait_col_name] = df_dog['breed'].map(mapping_dict) # Keeps NA-safe int\n",
    "'''\n",
    "\n",
    "\n",
    "    # Create a lookup dictionary from dog_info\n",
    "    breed_to_ft = dict(zip(dog_info['Breed Name'], dog_info['Size']))\n",
    "\n",
    "    # Apply the mapping\n",
    "    df_dog['size'] = df_dog['breed'].map(breed_to_ft)\n",
    "\n",
    "    # Set Unknown breeds to 3\n",
    "    df_dog.loc[df_dog['breed'] == 'Unknown', 'size'] = 3\n",
    "\n",
    "    # If you want it to be integer type\n",
    "    df_dog['size'] = df_dog['size'].astype('Int64')  # Allows NA-safe ints\n",
    "\n",
    "    # Combine all rename logic\n",
    "    #combined_rename_map = {**breed_rename_map, **manual_fixes}\n",
    "\n",
    "    #df_dog['breed'] = df_dog['breed'].apply(lambda b: combined_rename_map.get(b, b))\n",
    "    \n",
    "    # Load breed-to-cluster mapping\n",
    "    breed_cluster_df = pd.read_csv('dog_breed_to_cluster_map.csv')\n",
    "    breed_to_cluster = dict(zip(breed_cluster_df['Breed Name'], breed_cluster_df['Cluster']))\n",
    "\n",
    "    # Map breed to cluster\n",
    "    df_dog['breed'] = df_dog['breed'].apply(\n",
    "        lambda b: breed_to_cluster.get(b, \"Rare\") if b != \"Unknown\" else \"Unknown\"\n",
    "    )\n",
    "    \n",
    "    # Optional: Log all final unmapped as rare\n",
    "    logging.info(\"\\n[SUMMARY] Breeds marked as 'Rare' due to no valid match:\")\n",
    "    for breed in unmatched_breeds:\n",
    "        logging.info(f\" - {breed}\")\n",
    "\n",
    "\n",
    "    return df_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "948eeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairings that don't have a common string \n",
    "color_group_map = {\n",
    "  'silver':           'gray',\n",
    "  'blue':             'gray',\n",
    "  'red':              'orange',\n",
    "  'yellow':           'orange',\n",
    "  'tan':              'orange',\n",
    "  'cream':            'white',\n",
    "  'buff':             'orange',\n",
    "  'tricolor':         'multicolor',\n",
    "  'tortie':           'multicolor',\n",
    "  'agouti':           'white',\n",
    "  'apricot':          'white',\n",
    "  'chocolate':        'brown',\n",
    "  'fawn':             'orange',\n",
    "  'flame point':      'orange',\n",
    "  'gold':             'orange',\n",
    "  'lilac point':      'white',\n",
    "  'liver':            'brown',\n",
    "  'lynx':             'white',\n",
    "  'pink':             'orange',\n",
    "  'ruddy':            'brown',\n",
    "  'sable':            'brown',\n",
    "  'seal point':       'brown',\n",
    "  'torbie':           'multicolor',\n",
    "  'calico':           'multicolor'\n",
    "}\n",
    "\n",
    "# main_colors = {'gray', 'brown', 'orange', 'black', 'white', 'multicolor'}\n",
    "\n",
    "def clean_color(df):\n",
    "  # lowercase\n",
    "  df['color'] = df['color'].str.lower().str.strip()\n",
    "\n",
    "  # feature engineering -> primary color \n",
    "  df['primary_color'] = df['color'].astype(str).apply(\n",
    "      lambda x: x.split('/')[0].strip() if '/' in x else x.strip()\n",
    "  )\n",
    "\n",
    "  # # uncomment this block to go back to main_colors mapping!\n",
    "  # # df['primary_color'] = df['primary_color'].map(color_group_map).fillna(df['primary_color'])\n",
    "  # df['primary_color'] = df['primary_color'].apply(\n",
    "  #   lambda x: next((v for k, v in color_group_map.items() if pd.notna(x) and k in x), x)\n",
    "  # )\n",
    "  # # simplify to one of 6 colors\n",
    "  # df['primary_color'] = df['primary_color'].apply(\n",
    "  #   lambda x: next((color for color in main_colors if pd.notna(x) and color in x), x)\n",
    "  # )\n",
    "\n",
    "  # Collapse colors to 'black' or 'non-black'\n",
    "  df['primary_color'] = df['primary_color'].apply(\n",
    "      lambda x: 'black' if 'black' in x else 'non-black'\n",
    "  )\n",
    "\n",
    "  pd.set_option('display.max_rows', None)  # Ensures full list is shown\n",
    "  unique_colors = df['primary_color'].dropna().unique().tolist()\n",
    "  print(\"Unique primary colors:\")\n",
    "  for i, color in enumerate(sorted(unique_colors), 1):\n",
    "    print(f\"{i:2}. {color}\")\n",
    "\n",
    "  df = df.drop(columns=['color'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36e9403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>intake_time</th>\n",
       "      <th>found_location</th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>outcome_time</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>primary_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A706918</td>\n",
       "      <td>Belle</td>\n",
       "      <td>07/05/2015 12:59:00 PM</td>\n",
       "      <td>9409 Bluegrass Dr in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>8 years</td>\n",
       "      <td>English Springer Spaniel</td>\n",
       "      <td>07/05/2015 03:13:00 PM</td>\n",
       "      <td>07/05/2007</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>non-black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A724273</td>\n",
       "      <td>Runster</td>\n",
       "      <td>04/14/2016 06:43:00 PM</td>\n",
       "      <td>2818 Palomino Trail in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11 months</td>\n",
       "      <td>Basenji Mix</td>\n",
       "      <td>04/21/2016 05:17:00 PM</td>\n",
       "      <td>04/17/2015</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>non-black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A857105</td>\n",
       "      <td>Johnny Ringo</td>\n",
       "      <td>05/12/2022 12:23:00 AM</td>\n",
       "      <td>4404 Sarasota Drive in Austin (TX)</td>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Domestic Shorthair</td>\n",
       "      <td>05/12/2022 02:35:00 PM</td>\n",
       "      <td>05/12/2020</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>non-black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A743852</td>\n",
       "      <td>Odin</td>\n",
       "      <td>02/18/2017 12:46:00 PM</td>\n",
       "      <td>Austin (TX)</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>02/21/2017 05:44:00 PM</td>\n",
       "      <td>02/18/2015</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>non-black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A635072</td>\n",
       "      <td>Beowulf</td>\n",
       "      <td>04/16/2019 09:53:00 AM</td>\n",
       "      <td>415 East Mary Street in Austin (TX)</td>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>6 years</td>\n",
       "      <td>Great Dane Mix</td>\n",
       "      <td>04/18/2019 01:45:00 PM</td>\n",
       "      <td>06/03/2012</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          name             intake_time  \\\n",
       "0  A706918         Belle  07/05/2015 12:59:00 PM   \n",
       "1  A724273       Runster  04/14/2016 06:43:00 PM   \n",
       "2  A857105  Johnny Ringo  05/12/2022 12:23:00 AM   \n",
       "3  A743852          Odin  02/18/2017 12:46:00 PM   \n",
       "4  A635072       Beowulf  04/16/2019 09:53:00 AM   \n",
       "\n",
       "                        found_location      intake_type intake_condition  \\\n",
       "0     9409 Bluegrass Dr in Austin (TX)            Stray           Normal   \n",
       "1   2818 Palomino Trail in Austin (TX)            Stray           Normal   \n",
       "2   4404 Sarasota Drive in Austin (TX)    Public Assist           Normal   \n",
       "3                          Austin (TX)  Owner Surrender           Normal   \n",
       "4  415 East Mary Street in Austin (TX)    Public Assist           Normal   \n",
       "\n",
       "  animal_type sex_upon_intake age_upon_intake                     breed  \\\n",
       "0         Dog   Spayed Female         8 years  English Springer Spaniel   \n",
       "1         Dog     Intact Male       11 months               Basenji Mix   \n",
       "2         Cat   Neutered Male         2 years        Domestic Shorthair   \n",
       "3         Dog   Neutered Male         2 years    Labrador Retriever Mix   \n",
       "4         Dog   Neutered Male         6 years            Great Dane Mix   \n",
       "\n",
       "             outcome_time date_of_birth     outcome_type primary_color  \n",
       "0  07/05/2015 03:13:00 PM    07/05/2007  Return to Owner     non-black  \n",
       "1  04/21/2016 05:17:00 PM    04/17/2015  Return to Owner     non-black  \n",
       "2  05/12/2022 02:35:00 PM    05/12/2020         Transfer     non-black  \n",
       "3  02/21/2017 05:44:00 PM    02/18/2015  Return to Owner     non-black  \n",
       "4  04/18/2019 01:45:00 PM    06/03/2012  Return to Owner         black  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_df = df_train.copy(deep=True)\n",
    "color_df = clean_color(color_df)\n",
    "\n",
    "color_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3966062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_encode(df, col):\n",
    "  # count frequencies\n",
    "  freq_series = df[col].value_counts()\n",
    "\n",
    "  # map frequencies back to the original column, replacing values\n",
    "  df[col] = df[col].map(freq_series)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fe3c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_cond(df):\n",
    "    # Known mappings\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Unknown': 'Unknown Condition / Other', 'Other': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Space': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Behavior': 'Normal / Behavior', 'Normal': 'Normal / Behavior'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neonatal': 'Nursing / Neonatal', 'Nursing': 'Nursing / Neonatal'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neurologic': 'Med Urgent', 'Agonal': 'Med Urgent', 'Parvo': 'Med Urgent'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Agonal': 'Med Urgent / Neurological'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Congenital': 'Sick'})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "552f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = drop_cols(df)\n",
    "    print('dropped columns')\n",
    "    df = clean_intake_time(df)\n",
    "    print('cleaned intake time')\n",
    "    df = clean_intake_cond(df)\n",
    "    print('cleaned intake condition')\n",
    "    df = clean_age_and_sex_upon_intake(df)\n",
    "    print('cleaned age and sex')\n",
    "    df = clean_color(df)\n",
    "    print('cleaned color')\n",
    "    df = clean_breed(df)\n",
    "    print('cleaned breed')\n",
    "    # df = clean_animal_type(df)\n",
    "    # print('cleaned animal type')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edee2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def encode_columns(df):\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    encoder.fit(df[['category_column']])\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_type'])\n",
    "    df = df.drop('intake_type', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_condition'])\n",
    "    df = df.drop('intake_condition', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['sex_upon_intake'])\n",
    "    df = df.drop('sex_upon_intake', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4662dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df_train = encode_columns(df_train)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m label_column \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome_type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[60], line 12\u001b[0m, in \u001b[0;36mclean_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m clean_color(df)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned color\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_breed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned breed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# df = clean_animal_type(df)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print('cleaned animal type')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m, in \u001b[0;36mclean_breed\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# remove mix from all breeds\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m df_dog \u001b[38;5;241m=\u001b[39m \u001b[43mmap_dog_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manimal_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df_cat \u001b[38;5;241m=\u001b[39m map_cat_rarity(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Add cleaned dog and cat records back\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 79\u001b[0m, in \u001b[0;36mmap_dog_cluster\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Replace 'No' with 0 in the source table (we won't change the original dog_info)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m temp_series \u001b[38;5;241m=\u001b[39m dog_info[trait]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m temp_series \u001b[38;5;241m=\u001b[39m \u001b[43mtemp_series\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrait\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModerate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Create the mapping\u001b[39;00m\n\u001b[1;32m     81\u001b[0m mapping_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(dog_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreed Name\u001b[39m\u001b[38;5;124m'\u001b[39m], temp_series))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Size'"
     ]
    }
   ],
   "source": [
    "df_train = clean_data(df_train)\n",
    "# df_train = encode_columns(df_train)\n",
    "label_column = df_train.pop('outcome_type')\n",
    "df_train.insert(df_train.shape[1], 'outcome_type', label_column)   \n",
    "# df_train[df_train['size'].isna()]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce3bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/knpz54sj16988z9vrp2b98fr0000gn/T/ipykernel_5628/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>intake_month</th>\n",
       "      <th>intake_hour</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Sick</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intake_type   intake_condition animal_type sex_upon_intake  age_upon_intake  \\\n",
       "0       Stray  Normal / Behavior         Dog   Neutered Male             24.0   \n",
       "1       Stray               Sick         Cat   Intact Female              1.0   \n",
       "2       Stray  Normal / Behavior         Dog   Neutered Male             48.0   \n",
       "3       Stray  Normal / Behavior         Dog   Intact Female              5.0   \n",
       "4       Stray            Injured         Cat   Intact Female             24.0   \n",
       "\n",
       "    breed  intake_year  intake_month  intake_hour primary_color  is_mix  size  \n",
       "0       7         2019             1           16     non-black       1     2  \n",
       "1  Common         2013            10            7     non-black       1     2  \n",
       "2       3         2014             6           10     non-black       1     4  \n",
       "3       4         2015             7           18     non-black       0     3  \n",
       "4  Common         2017             2           10         black       1     2  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = clean_data(df_test)\n",
    "df_train[df_train['size'].isna()]\n",
    "df_test.head()\n",
    "df_test['breed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5bada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>outcome_type</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return to Owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary_color</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.503210</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>0.147988</td>\n",
       "      <td>0.306927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-black</th>\n",
       "      <td>0.492499</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.031004</td>\n",
       "      <td>0.149761</td>\n",
       "      <td>0.317845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "outcome_type   Adoption      Died  Euthanasia  Return to Owner  Transfer\n",
       "primary_color                                                           \n",
       "black          0.503210  0.010772    0.031103         0.147988  0.306927\n",
       "non-black      0.492499  0.008891    0.031004         0.149761  0.317845"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am going to try and split betwen df_dog and df_Cat\n",
    "d = df_train.groupby(['primary_color','outcome_type']).size().unstack(fill_value=0)\n",
    "d_percent = d.div(d.sum(axis=1), axis=0)\n",
    "\n",
    "d_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d11cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer code for pipelines\n",
    "\n",
    "# Use FunctionTransformer to wrap the freq_encode function\n",
    "def apply_freq_encode(df):\n",
    "    df = freq_encode(df, 'primary_color')\n",
    "    df = freq_encode(df, 'breed')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ac334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(dog_pred, cat_pred, dog_true, cat_true):\n",
    "    \"\"\"\n",
    "    Combines dog and cat predictions, ordering them by the original test set indices,\n",
    "    and writes a CSV with sequential Ids and Outcome Types.\n",
    "    \n",
    "    Example CSV output:\n",
    "    Id,Outcome Type\n",
    "    1,Died\n",
    "    2,Euthanasia\n",
    "    3,Adoption\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # Create prediction series with the same indices as the original true labels\n",
    "    dog_pred_series = pd.Series(dog_pred, index=dog_true.index)\n",
    "    cat_pred_series = pd.Series(cat_pred, index=cat_true.index)\n",
    "    \n",
    "    # Concatenate both series and sort by the original index so the output\n",
    "    # reflects the same order as the original test dataset.\n",
    "    all_predictions = pd.concat([dog_pred_series, cat_pred_series]).sort_index()\n",
    "    \n",
    "    # Generate sequential IDs starting from 1 and create the final DataFrame\n",
    "    final_df = pd.DataFrame({\n",
    "        'Id': range(1, len(all_predictions) + 1),\n",
    "        'Outcome Type': all_predictions.values\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to CSV with a header row; commas separate each field.\n",
    "    csv_path = './test_predictions_combined.csv'\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined test predictions saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(y_pred, model_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Alternate version that does not have stitching.\n",
    "    \n",
    "    Example CSV output:\n",
    "    Id,Outcome Type\n",
    "    1,Died\n",
    "    2,Euthanasia\n",
    "    3,Adoption\n",
    "    ...\n",
    "    \n",
    "    Parameters:\n",
    "        y_pred (numpy.ndarray): Predicted labels.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Create the final DataFrame with sequential Ids and Outcome Types.\n",
    "    final_df = pd.DataFrame({\n",
    "        'Id': range(1, len(y_pred) + 1),\n",
    "        'Outcome Type': y_pred  # y_pred is a numpy array; no need for .values.\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to a CSV file with a header row and comma separation.\n",
    "    csv_path = './test_' + model_name + '_predictions_combined.csv'\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined test predictions saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db76414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "balanced_acc_scorer = make_scorer(balanced_accuracy_score)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    print (classification_report(y_true, y_pred)) # print classification report\n",
    "    return balanced_accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def get_class_weights(y_train):\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "    return class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325acef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "print('Done running ml_project.ipynb.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
