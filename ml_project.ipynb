{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6786200",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5f819ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nneom\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nneom\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nneom\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae12383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d346067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR DATA CLEANING - all the stuff should be here\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train = df_train[df_train['intake_type'] != 'Wildlife']\n",
    "df_train = df_train.dropna(subset=['age_upon_intake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42369420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    cols_to_drop = ['id', 'name', 'date_of_birth', 'outcome_time', 'found_location']\n",
    "    existing_cols = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64692110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_time(df):\n",
    "    # Intake Time\n",
    "    # Convert string timestamps to UNIX timestamp\n",
    "    '''\n",
    "    dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n",
    "    df['intake_time'] = dt_series.astype('int64') // (10 ** 9)\n",
    "    '''\n",
    "    # Convert the 'intake_time' column to datetime, automatically handling both m/d/yyyy and mm/dd/yyyy formats\n",
    "    df['intake_time'] = pd.to_datetime(df['intake_time'], errors='coerce')\n",
    "    \n",
    "    # Check for any invalid dates and handle them (if needed)\n",
    "    if df['intake_time'].isnull().any():\n",
    "        print(df)\n",
    "\n",
    "    # Convert datetime to UNIX timestamp (int64) in seconds\n",
    "    df['intake_time'] = df['intake_time'].astype('int64') // (10 ** 9)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# Age Upon Intake\n",
    "def convert_age(age_str):\n",
    "    \"\"\"\n",
    "    Convert age strings to years.\n",
    "    Expected format: \"<number> <unit>\" e.g., \"2 years\", \"8 months\", \"3 weeks\", \"15 days\"\n",
    "    \"\"\"\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num = float(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    unit = parts[1].lower()\n",
    "    if \"year\" in unit:\n",
    "        return num\n",
    "    elif \"month\" in unit:\n",
    "        return num / 12\n",
    "    elif \"week\" in unit:\n",
    "        return num / 52\n",
    "    elif \"day\" in unit:\n",
    "        return num / 365\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_age_and_sex_upon_intake(df):\n",
    "    df.loc[df['sex_upon_intake'].isna(), 'sex_upon_intake'] = 'Unknown'\n",
    "    df['age_upon_intake'] = df['age_upon_intake'].apply(convert_age)\n",
    "    df.loc[df['age_upon_intake'] < 0, 'age_upon_intake'] = 0\n",
    "    return df\n",
    "\n",
    "# Breed\n",
    "def clean_breed(df):\n",
    "# Create is_mix column\n",
    "    df['is_mix'] = df['breed'].str.contains('mix', case=False, na=False).astype(int)\n",
    "    # remove mix from all breeds\n",
    "    df['breed'] = df['breed'].str.replace(' mix', '', case=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "948eeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_group_map = {\n",
    "  'blue tabby':       'gray tabby',\n",
    "  'silver tabby':     'gray tabby',\n",
    "  'silver':           'gray',\n",
    "  'blue':             'gray',\n",
    "  'orange tabby':     'orange',\n",
    "  'orange tiger':     'orange',\n",
    "  'red':              'orange',\n",
    "  'red tabby':        'orange',\n",
    "  'red tick':         'orange',\n",
    "  'yellow':           'orange',\n",
    "  'tan':              'cream',\n",
    "}\n",
    "\n",
    "def clean_color(df):\n",
    "  # lowercase\n",
    "  df['color'] = df['color'].str.lower().str.strip()\n",
    "\n",
    "  # feature engineering -> primary color \n",
    "  df['primary_color'] = df['color'].astype(str).apply(\n",
    "      lambda x: x.split('/')[0].strip() if '/' in x else x.strip()\n",
    "  )\n",
    "\n",
    "  # simplify synonymous colors if in map\n",
    "  df['primary_color'] = df['primary_color'].map(color_group_map).fillna(df['primary_color'])\n",
    "\n",
    "  df = df.drop(columns=['color'])\n",
    "  return df\n",
    "\n",
    "\n",
    "def freq_encode(df, col):\n",
    "  # count frequencies\n",
    "  freq_series = df[col].value_counts()\n",
    "\n",
    "  # map frequencies back to the original column, replacing values\n",
    "  df[col] = df[col].map(freq_series)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fe3c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_cond(df):\n",
    "    # # Known mappings\n",
    "    # df['intake_condition'] = df['intake_condition'].replace({\n",
    "    #     'Unknown': 'Unknown Condition / Other', \n",
    "    #     'Other': 'Unknown Condition / Other',\n",
    "    #     'Space': 'Unknown Condition / Other',\n",
    "    #     'Behavior': 'Normal / Behavior', \n",
    "    #     'Normal': 'Normal / Behavior',\n",
    "    #     'Neonatal': 'Nursing / Neonatal', \n",
    "    #     'Nursing': 'Nursing / Neonatal',\n",
    "    #     'Neurologic': 'Med Urgent', \n",
    "    #     'Agonal': 'Med Urgent', \n",
    "    #     'Parvo': 'Med Urgent',\n",
    "    #     'Congenital': 'Sick'\n",
    "    # })\n",
    "\n",
    "    # # Replace any unknown conditions (those not in the mapping) with 'Med Urgent'\n",
    "    # df['intake_condition'] = df['intake_condition'].apply(lambda x: x if x in df['intake_condition'].unique() else 'Med Urgent')\n",
    "\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Unknown': 'Unknown Condition / Other', 'Other': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Space': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Behavior': 'Normal / Behavior', 'Normal': 'Normal / Behavior'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neonatal': 'Nursing / Neonatal', 'Nursing': 'Nursing / Neonatal'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neurologic': 'Med Urgent', 'Agonal': 'Med Urgent', 'Parvo': 'Med Urgent'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Agonal': 'Med Urgent / Neurological'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Congenital': 'Sick'})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a452085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_animal_type(df):\n",
    "#     dummies = pd.get_dummies(df['animal_type'], drop_first=True)\n",
    "#     df = df.drop('animal_type', axis=1)\n",
    "#     df = pd.concat([df, dummies], axis=1)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "552f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = drop_cols(df)\n",
    "    print('dropped columns')\n",
    "    df = clean_intake_time(df)\n",
    "    print('cleaned intake time')\n",
    "    df = clean_intake_cond(df)\n",
    "    print('cleaned intake condition')\n",
    "    df = clean_age_and_sex_upon_intake(df)\n",
    "    print('cleaned age and sex')\n",
    "    df = clean_breed(df)\n",
    "    print('cleaned breed')\n",
    "    df = clean_color(df)\n",
    "    print('cleaned color')\n",
    "    # df = clean_animal_type(df)\n",
    "    # print('cleaned animal type')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbce3bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>intake_time</th>\n",
       "      <th>found_location</th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>color</th>\n",
       "      <th>outcome_time</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>outcome_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/3/19 16:19</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Beagle Mix</td>\n",
       "      <td>Tricolor</td>\n",
       "      <td>1/3/17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10/21/13 7:59</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Sick</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>4 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Calico</td>\n",
       "      <td>9/21/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6/29/14 10:38</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>4 years</td>\n",
       "      <td>Doberman Pinsch/Australian Cattle Dog</td>\n",
       "      <td>Tan/Gray</td>\n",
       "      <td>6/29/10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7/11/15 18:19</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>5 months</td>\n",
       "      <td>Pit Bull</td>\n",
       "      <td>Brown/White</td>\n",
       "      <td>1/11/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2/4/17 10:10</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Black/White</td>\n",
       "      <td>2/4/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27786</th>\n",
       "      <td>27787</td>\n",
       "      <td>6/18/24 14:42</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>8 months</td>\n",
       "      <td>Catahoula Mix</td>\n",
       "      <td>Brown Brindle/White</td>\n",
       "      <td>10/1/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27787</th>\n",
       "      <td>27788</td>\n",
       "      <td>8/28/24 12:05</td>\n",
       "      <td>-10</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>2 months</td>\n",
       "      <td>Domestic Shorthair</td>\n",
       "      <td>Black</td>\n",
       "      <td>6/15/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27788</th>\n",
       "      <td>27789</td>\n",
       "      <td>12/7/23 14:57</td>\n",
       "      <td>-10</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>8 years</td>\n",
       "      <td>Pit Bull/Labrador Retriever</td>\n",
       "      <td>White</td>\n",
       "      <td>11/9/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27789</th>\n",
       "      <td>27790</td>\n",
       "      <td>8/25/24 10:21</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>9 years</td>\n",
       "      <td>Domestic Shorthair</td>\n",
       "      <td>Brown/Brown Tabby</td>\n",
       "      <td>8/31/14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27790</th>\n",
       "      <td>27791</td>\n",
       "      <td>7/13/24 17:51</td>\n",
       "      <td>-10</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Feral</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Domestic Shorthair</td>\n",
       "      <td>Orange Tabby</td>\n",
       "      <td>7/13/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27791 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           name  intake_time   found_location intake_type  \\\n",
       "0          1   1/3/19 16:19          -10            Stray      Normal   \n",
       "1          2  10/21/13 7:59          -10            Stray        Sick   \n",
       "2          3  6/29/14 10:38          -10            Stray      Normal   \n",
       "3          4  7/11/15 18:19          -10            Stray      Normal   \n",
       "4          5   2/4/17 10:10          -10            Stray     Injured   \n",
       "...      ...            ...          ...              ...         ...   \n",
       "27786  27787  6/18/24 14:42          -10            Stray      Normal   \n",
       "27787  27788  8/28/24 12:05          -10  Owner Surrender      Normal   \n",
       "27788  27789  12/7/23 14:57          -10  Owner Surrender      Normal   \n",
       "27789  27790  8/25/24 10:21          -10            Stray     Injured   \n",
       "27790  27791  7/13/24 17:51          -10            Stray       Feral   \n",
       "\n",
       "      intake_condition    animal_type sex_upon_intake  \\\n",
       "0                  Dog  Neutered Male         2 years   \n",
       "1                  Cat  Intact Female         4 weeks   \n",
       "2                  Dog  Neutered Male         4 years   \n",
       "3                  Dog  Intact Female        5 months   \n",
       "4                  Cat  Intact Female         2 years   \n",
       "...                ...            ...             ...   \n",
       "27786              Dog  Intact Female        8 months   \n",
       "27787              Cat  Intact Female        2 months   \n",
       "27788              Dog  Neutered Male         8 years   \n",
       "27789              Cat  Spayed Female         9 years   \n",
       "27790              Cat    Intact Male         2 years   \n",
       "\n",
       "                             age_upon_intake                breed    color  \\\n",
       "0                                 Beagle Mix             Tricolor   1/3/17   \n",
       "1                     Domestic Shorthair Mix               Calico  9/21/13   \n",
       "2      Doberman Pinsch/Australian Cattle Dog             Tan/Gray  6/29/10   \n",
       "3                                   Pit Bull          Brown/White  1/11/15   \n",
       "4                     Domestic Shorthair Mix          Black/White   2/4/15   \n",
       "...                                      ...                  ...      ...   \n",
       "27786                          Catahoula Mix  Brown Brindle/White  10/1/23   \n",
       "27787                     Domestic Shorthair                Black  6/15/24   \n",
       "27788            Pit Bull/Labrador Retriever                White  11/9/15   \n",
       "27789                     Domestic Shorthair    Brown/Brown Tabby  8/31/14   \n",
       "27790                     Domestic Shorthair         Orange Tabby  7/13/22   \n",
       "\n",
       "       outcome_time  date_of_birth  outcome_type  \n",
       "0               NaN            NaN           NaN  \n",
       "1               NaN            NaN           NaN  \n",
       "2               NaN            NaN           NaN  \n",
       "3               NaN            NaN           NaN  \n",
       "4               NaN            NaN           NaN  \n",
       "...             ...            ...           ...  \n",
       "27786           NaN            NaN           NaN  \n",
       "27787           NaN            NaN           NaN  \n",
       "27788           NaN            NaN           NaN  \n",
       "27789           NaN            NaN           NaN  \n",
       "27790           NaN            NaN           NaN  \n",
       "\n",
       "[27791 rows x 14 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# df_test = clean_data(df_test)\n",
    "df_test = clean_intake_time(df_test)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edee2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def encode_columns(df):\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    encoder.fit(df[['category_column']])\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_type'])\n",
    "    df = df.drop('intake_type', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_condition'])\n",
    "    df = df.drop('intake_condition', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['sex_upon_intake'])\n",
    "    df = df.drop('sex_upon_intake', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4662dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_train = clean_data(df_train)\\n# df_train = encode_columns(df_train)\\nlabel_column = df_train.pop('outcome_type')\\ndf_train.insert(df_train.shape[1], 'outcome_type', label_column)    \\ndf_train.head()\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = clean_data(df_train)\n",
    "# df_train = encode_columns(df_train)\n",
    "label_column = df_train.pop('outcome_type')\n",
    "df_train.insert(df_train.shape[1], 'outcome_type', label_column)    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d11cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer code for pipelines\n",
    "\n",
    "# Use FunctionTransformer to wrap the freq_encode function\n",
    "def apply_freq_encode(df):\n",
    "    df = freq_encode(df, 'primary_color')\n",
    "    df = freq_encode(df, 'breed')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e946ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import OneHotEncoder, FunctionTransformer\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score\\nfrom xgboost import XGBClassifier\\n\\ndef train_classifier(X_train, y_train, X_test):\\n    \"\"\"\\n    Trains an XGBoost model using a pipeline that includes a frequency encoding transformation,\\n    OneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\\n\\n    Parameters:\\n        X_train (pd.DataFrame): Training features.\\n        y_train (pd.Series or np.array): Training target values.\\n        X_test (pd.DataFrame): Test features.\\n\\n    Returns:\\n        best_estimator: The best estimator from RandomizedSearchCV.\\n        test_predictions: The predicted labels for X_test from the best estimator.\\n    \"\"\"\\n    # Construct the pipeline:\\n    #   1. Apply frequency encoding (for example, on \\'primary_color\\' & \\'breed\\' if implemented in apply_freq_encode)\\n    #   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\\n    #   3. Fit an XGBClassifier.\\n    pipeline = Pipeline([\\n        (\\'freq\\', FunctionTransformer(apply_freq_encode, validate=False)),\\n        (\\'onehot\\', OneHotEncoder(handle_unknown=\\'ignore\\', sparse_output=False)),\\n        (\\'xgb\\', XGBClassifier(eval_metric=\\'logloss\\', verbosity=1))\\n    ])\\n\\n    # Set up parameter distributions for XGBoost.\\n    param_distributions = {\\n        \"xgb__max_depth\": [3, 6, 9],\\n        \"xgb__learning_rate\": [0.01, 0.1, 0.2],\\n        \"xgb__n_estimators\": [50, 100, 200],\\n        \"xgb__subsample\": [0.5, 0.7, 1.0],\\n        \"xgb__colsample_bytree\": [0.5, 0.7, 1.0]\\n    }\\n\\n    # Perform hyperparameter search using RandomizedSearchCV.\\n    randomized_search = RandomizedSearchCV(\\n        estimator=pipeline, \\n        param_distributions=param_distributions,\\n        n_iter=1,\\n        cv=5, \\n        scoring=\\'accuracy\\', \\n        verbose=3,\\n    )\\n\\n    randomized_search.fit(X_train, y_train)\\n\\n    print(\\'Best parameters:\\', randomized_search.best_params_)\\n    print(\\'Best cross-validation accuracy:\\', randomized_search.best_score_)\\n\\n    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=5, verbose=3)\\n    print(\\'Generalization accuracy (via cross_val_score):\\', cv_scores.mean())\\n\\n    # Make predictions on the test set using the best estimator.\\n    test_predictions = randomized_search.predict(X_test)\\n\\n    return randomized_search.best_estimator_, test_predictions\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_classifier(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost model using a pipeline that includes a frequency encoding transformation,\n",
    "    OneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series or np.array): Training target values.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "    \n",
    "    Returns:\n",
    "        best_estimator: The best estimator from RandomizedSearchCV.\n",
    "        test_predictions: The predicted labels for X_test from the best estimator.\n",
    "    \"\"\"\n",
    "    # Construct the pipeline:\n",
    "    #   1. Apply frequency encoding (for example, on 'primary_color' & 'breed' if implemented in apply_freq_encode)\n",
    "    #   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\n",
    "    #   3. Fit an XGBClassifier.\n",
    "    pipeline = Pipeline([\n",
    "        ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', verbosity=1))\n",
    "    ])\n",
    "    \n",
    "    # Set up parameter distributions for XGBoost.\n",
    "    param_distributions = {\n",
    "        \"xgb__max_depth\": [3, 6, 9],\n",
    "        \"xgb__learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"xgb__n_estimators\": [50, 100, 200],\n",
    "        \"xgb__subsample\": [0.5, 0.7, 1.0],\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Perform hyperparameter search using RandomizedSearchCV.\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline, \n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=1,\n",
    "        cv=5, \n",
    "        scoring='accuracy', \n",
    "        verbose=3,\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "    \n",
    "    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=5, verbose=3)\n",
    "    print('Generalization accuracy (via cross_val_score):', cv_scores.mean())\n",
    "    \n",
    "    # Make predictions on the test set using the best estimator.\n",
    "    test_predictions = randomized_search.predict(X_test)\n",
    "    \n",
    "    return randomized_search.best_estimator_, test_predictions\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4448de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import LabelEncoder\\n# For Dog:\\ntrain_dog = df_train[df_train[\\'animal_type\\'] == \\'Dog\\'].copy()\\nX_train_dog = train_dog.drop(columns=[\\'animal_type\\', \\'outcome_type\\'])\\ny_train_dog = train_dog[\\'outcome_type\\']\\n\\ntest_dog = df_test[df_test[\\'animal_type\\'] == \\'Dog\\'].copy()\\nX_test_dog = test_dog.drop(columns=[\\'animal_type\\'])\\n\\n# For Cat:\\ntrain_cat = df_train[df_train[\\'animal_type\\'] == \\'Cat\\'].copy()\\nX_train_cat = train_cat.drop(columns=[\\'animal_type\\', \\'outcome_type\\'])\\ny_train_cat = train_cat[\\'outcome_type\\']\\n\\ntest_cat = df_test[df_test[\\'animal_type\\'] == \\'Cat\\'].copy()\\nX_test_cat = test_cat.drop(columns=[\\'animal_type\\'])\\n\\n## Encode targets with LabelEncoder\\n# Dog encoding\\nle_dog = LabelEncoder()\\ny_train_dog_encoded = le_dog.fit_transform(y_train_dog)\\n\\n# Cat encoding\\nle_cat = LabelEncoder()\\ny_train_cat_encoded = le_cat.fit_transform(y_train_cat)\\n\\nprint(\"Training model for Dog data:\")\\nbest_estimator_dog, dog_predictions_encoded = train_classifier(X_train_dog, y_train_dog_encoded, X_test_dog)\\ndog_predictions = le_dog.inverse_transform(dog_predictions_encoded)\\n\\nprint(\"\\nTraining model for Cat data:\")\\nbest_estimator_cat, cat_predictions_encoded = train_classifier(X_train_cat, y_train_cat_encoded, X_test_cat)\\ncat_predictions = le_cat.inverse_transform(cat_predictions_encoded)\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# For Dog:\n",
    "train_dog = df_train[df_train['animal_type'] == 'Dog'].copy()\n",
    "X_train_dog = train_dog.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_dog = train_dog['outcome_type']\n",
    "\n",
    "test_dog = df_test[df_test['animal_type'] == 'Dog'].copy()\n",
    "X_test_dog = test_dog.drop(columns=['animal_type'])\n",
    "\n",
    "# For Cat:\n",
    "train_cat = df_train[df_train['animal_type'] == 'Cat'].copy()\n",
    "X_train_cat = train_cat.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_cat = train_cat['outcome_type']\n",
    "\n",
    "test_cat = df_test[df_test['animal_type'] == 'Cat'].copy()\n",
    "X_test_cat = test_cat.drop(columns=['animal_type'])\n",
    "\n",
    "## Encode targets with LabelEncoder\n",
    "# Dog encoding\n",
    "le_dog = LabelEncoder()\n",
    "y_train_dog_encoded = le_dog.fit_transform(y_train_dog)\n",
    "\n",
    "# Cat encoding\n",
    "le_cat = LabelEncoder()\n",
    "y_train_cat_encoded = le_cat.fit_transform(y_train_cat)\n",
    "\n",
    "print(\"Training model for Dog data:\")\n",
    "best_estimator_dog, dog_predictions_encoded = train_classifier(X_train_dog, y_train_dog_encoded, X_test_dog)\n",
    "dog_predictions = le_dog.inverse_transform(dog_predictions_encoded)\n",
    "\n",
    "print(\"\\nTraining model for Cat data:\")\n",
    "best_estimator_cat, cat_predictions_encoded = train_classifier(X_train_cat, y_train_cat_encoded, X_test_cat)\n",
    "cat_predictions = le_cat.inverse_transform(cat_predictions_encoded)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "803ac334",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICTION STITCHING ##\n",
    "def combine_predictions(dog_pred, cat_pred, dog_true, cat_true):\n",
    "    \"\"\"\n",
    "    Pass in list of dog predictions and cat predictions\n",
    "    Returns -> stitched together predictions based on original test set order\n",
    "    \"\"\"\n",
    "    dog_pred_series = pd.Series(dog_pred, index=dog_true.index)\n",
    "    cat_pred_series = pd.Series(cat_pred, index=cat_true.index)\n",
    "    # Concatenate both series and sort by the original index so the output \n",
    "    # reflects the same order as the original test dataset\n",
    "    all_predictions = pd.concat([dog_pred_series, cat_pred_series]).sort_index()\n",
    "    final_df = pd.DataFrame({'Predicted_Label': all_predictions})\n",
    "    csv_path = './test_predictions_combined.csv'\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined test predictions saved to: {csv_path}\")\n",
    "\n",
    "# combine_predictions(dog_predictions, cat_predictions, X_test_dog, X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5408179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# At the end of the notebook, or wherever you want to save the functions\\nwith open(\\'ml_project_func.py\\', \\'w\\') as f:\\n    f.write(\"\"\" \\n    # All your function code goes here\\n    \"\"\")\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the end of the notebook, or wherever you want to save the functions\n",
    "with open('ml_project.py', 'w') as f:\n",
    "    f.write(\"\"\" \n",
    "    # All your function code goes here\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22747c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ml_project successfully imported.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
