{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6786200",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f819ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae12383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR DATA CLEANING - all the stuff should be here\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train = df_train[df_train['intake_type'] != 'Wildlife']\n",
    "df_train = df_train.dropna(subset=['age_upon_intake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42369420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    cols_to_drop = ['id', 'name', 'date_of_birth', 'outcome_time', 'found_location']\n",
    "    existing_cols = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64692110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_time(df):\n",
    "    # Intake Time\n",
    "    # Convert string timestamps to UNIX timestamp\n",
    "    dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n",
    "    df['intake_time'] = dt_series.astype('int64') // (10 ** 9)\n",
    "    return df\n",
    "\n",
    "# Age Upon Intake\n",
    "def convert_age(age_str):\n",
    "    \"\"\"\n",
    "    Convert age strings to years.\n",
    "    Expected format: \"<number> <unit>\" e.g., \"2 years\", \"8 months\", \"3 weeks\", \"15 days\"\n",
    "    \"\"\"\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num = float(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    unit = parts[1].lower()\n",
    "    if \"year\" in unit:\n",
    "        return num\n",
    "    elif \"month\" in unit:\n",
    "        return num / 12\n",
    "    elif \"week\" in unit:\n",
    "        return num / 52\n",
    "    elif \"day\" in unit:\n",
    "        return num / 365\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_age_and_sex_upon_intake(df):\n",
    "    df.loc[df['sex_upon_intake'].isna(), 'sex_upon_intake'] = 'Unknown'\n",
    "    df['age_upon_intake'] = df['age_upon_intake'].apply(convert_age)\n",
    "    df.loc[df['age_upon_intake'] < 0, 'age_upon_intake'] = 0\n",
    "    return df\n",
    "\n",
    "# Breed\n",
    "def clean_breed(df):\n",
    "# Create is_mix column\n",
    "    df['is_mix'] = df['breed'].str.contains('mix', case=False, na=False).astype(int)\n",
    "    # remove mix from all breeds\n",
    "    df['breed'] = df['breed'].str.replace(' mix', '', case=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948eeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_group_map = {\n",
    "  'blue tabby':       'gray tabby',\n",
    "  'silver tabby':     'gray tabby',\n",
    "  'silver':           'gray',\n",
    "  'blue':             'gray',\n",
    "  'orange tabby':     'orange',\n",
    "  'orange tiger':     'orange',\n",
    "  'red':              'orange',\n",
    "  'red tabby':        'orange',\n",
    "  'red tick':         'orange',\n",
    "  'yellow':           'orange',\n",
    "  'tan':              'cream',\n",
    "}\n",
    "\n",
    "def clean_color(df):\n",
    "  # lowercase\n",
    "  df['color'] = df['color'].str.lower().str.strip()\n",
    "\n",
    "  # feature engineering -> primary color \n",
    "  df['primary_color'] = df['color'].astype(str).apply(\n",
    "      lambda x: x.split('/')[0].strip() if '/' in x else x.strip()\n",
    "  )\n",
    "\n",
    "  # simplify synonymous colors if in map\n",
    "  df['primary_color'] = df['primary_color'].map(color_group_map).fillna(df['primary_color'])\n",
    "\n",
    "  df = df.drop(columns=['color'])\n",
    "  return df\n",
    "\n",
    "\n",
    "def freq_encode(df, col):\n",
    "  # count frequencies\n",
    "  freq_series = df[col].value_counts()\n",
    "\n",
    "  # map frequencies back to the original column, replacing values\n",
    "  df[col] = df[col].map(freq_series)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_cond(df):\n",
    "    # Known mappings\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Unknown': 'Unknown Condition / Other', 'Other': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Space': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Behavior': 'Normal / Behavior', 'Normal': 'Normal / Behavior'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neonatal': 'Nursing / Neonatal', 'Nursing': 'Nursing / Neonatal'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neurologic': 'Med Urgent', 'Agonal': 'Med Urgent', 'Parvo': 'Med Urgent'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Agonal': 'Med Urgent / Neurological'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Congenital': 'Sick'})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = drop_cols(df)\n",
    "    print('dropped columns')\n",
    "    df = clean_intake_time(df)\n",
    "    print('cleaned intake time')\n",
    "    df = clean_intake_cond(df)\n",
    "    print('cleaned intake condition')\n",
    "    df = clean_age_and_sex_upon_intake(df)\n",
    "    print('cleaned age and sex')\n",
    "    df = clean_breed(df)\n",
    "    print('cleaned breed')\n",
    "    df = clean_color(df)\n",
    "    print('cleaned color')\n",
    "    # df = clean_animal_type(df)\n",
    "    # print('cleaned animal type')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def encode_columns(df):\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    encoder.fit(df[['category_column']])\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_type'])\n",
    "    df = df.drop('intake_type', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_condition'])\n",
    "    df = df.drop('intake_condition', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['sex_upon_intake'])\n",
    "    df = df.drop('sex_upon_intake', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4662dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = clean_data(df_train)\n",
    "# df_train = encode_columns(df_train)\n",
    "label_column = df_train.pop('outcome_type')\n",
    "df_train.insert(df_train.shape[1], 'outcome_type', label_column)    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = clean_data(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d11cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer code for pipelines\n",
    "\n",
    "# Use FunctionTransformer to wrap the freq_encode function\n",
    "def apply_freq_encode(df):\n",
    "    df = freq_encode(df, 'primary_color')\n",
    "    df = freq_encode(df, 'breed')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c79da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ac334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(dog_pred, cat_pred, dog_true, cat_true):\n",
    "    \"\"\"\n",
    "    Combines dog and cat predictions, ordering them by the original test set indices,\n",
    "    and writes a CSV with sequential Ids and Outcome Types.\n",
    "    \n",
    "    Example CSV output:\n",
    "    Id,Outcome Type\n",
    "    1,Died\n",
    "    2,Euthanasia\n",
    "    3,Adoption\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # Create prediction series with the same indices as the original true labels\n",
    "    dog_pred_series = pd.Series(dog_pred, index=dog_true.index)\n",
    "    cat_pred_series = pd.Series(cat_pred, index=cat_true.index)\n",
    "    \n",
    "    # Concatenate both series and sort by the original index so the output\n",
    "    # reflects the same order as the original test dataset.\n",
    "    all_predictions = pd.concat([dog_pred_series, cat_pred_series]).sort_index()\n",
    "    \n",
    "    # Generate sequential IDs starting from 1 and create the final DataFrame\n",
    "    final_df = pd.DataFrame({\n",
    "        'Id': range(1, len(all_predictions) + 1),\n",
    "        'Outcome Type': all_predictions.values\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to CSV with a header row; commas separate each field.\n",
    "    csv_path = './test_predictions_combined.csv'\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined test predictions saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb24c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(y_pred, model_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Alternate version that does not have stitching.\n",
    "    \n",
    "    Example CSV output:\n",
    "    Id,Outcome Type\n",
    "    1,Died\n",
    "    2,Euthanasia\n",
    "    3,Adoption\n",
    "    ...\n",
    "    \n",
    "    Parameters:\n",
    "        y_pred (numpy.ndarray): Predicted labels.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Create the final DataFrame with sequential Ids and Outcome Types.\n",
    "    final_df = pd.DataFrame({\n",
    "        'Id': range(1, len(y_pred) + 1),\n",
    "        'Outcome Type': y_pred  # y_pred is a numpy array; no need for .values.\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to a CSV file with a header row and comma separation.\n",
    "    csv_path = './test_' + model_name + '_predictions_combined.csv'\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined test predictions saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db76414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, balanced_accuracy_score\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    print (classification_report(y_true, y_pred)) # print classification report\n",
    "    return balanced_accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325acef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done running ml_project.ipynb.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
