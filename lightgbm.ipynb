{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cfd6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nbformat in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jsonschema>=2.6->nbformat) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from lightgbm) (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nbformat\n",
    "%pip install imbalanced-learn\n",
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55270c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "nb = nbformat.read(\"ml_project.ipynb\", as_version=4)\n",
    "\n",
    "# Normalize the notebook to add missing id fields and other updates\n",
    "nbformat.validator.validate(nb)\n",
    "\n",
    "# Write the normalized notebook back to a file\n",
    "nbformat.write(nb, \"ml_project_normalized.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad82977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/caseyc/Library/Python/3.9/lib/python/site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "dropped columns\n",
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n",
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/n0zzld6945vfyf6hj9_n1g4c0000gn/T/ipykernel_99114/1199118304.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "Unique primary colors:\n",
      " 1. black\n",
      " 2. non-black\n",
      "cleaned color\n",
      "cleaned breed\n",
      "Done running ml_project.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%run ml_project_normalized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2730768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.float = float  # Patch for libraries using deprecated np.float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6582ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_classifier_lightgbm(\n",
    "    X_train, y_train, X_test, rare_classes, cat_cols, custom_thresholds=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a LightGBM model using hyperparameter tuning.\n",
    "    Applies custom thresholding during prediction if specified and compares standard vs. custom accuracy.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series or np.array): Training target values.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        rare_classes (list): List of integer-encoded classes to be oversampled.\n",
    "        cat_cols (set or list): Categorical columns to one-hot encode.\n",
    "        custom_thresholds (dict, optional): Dict of class_label -> threshold.\n",
    "            e.g., {0: 0.7, 1: 0.5, 2: 0.5} for class 0 = supermajority.\n",
    "\n",
    "    Returns:\n",
    "        best_estimator: Trained pipeline.\n",
    "        test_predictions: Custom-thresholded predictions.\n",
    "        df_importances: Feature importances from LightGBM.\n",
    "    \"\"\"\n",
    "    # Compute balanced sample weights\n",
    "    class_labels = np.unique(y_train)\n",
    "    class_weights = compute_class_weight('balanced', classes=class_labels, y=y_train)\n",
    "    class_weight_dict = dict(zip(class_labels, class_weights))\n",
    "    sample_weights = np.array([class_weight_dict[y] for y in y_train])\n",
    "\n",
    "    # Ensure categorical features are strings\n",
    "    categorical_features = [col for col in X_train.columns if col in cat_cols]\n",
    "    for col in categorical_features:\n",
    "        X_train[col] = X_train[col].astype(str)\n",
    "        X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Build pipeline with LightGBM classifier\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"lgbm\", LGBMClassifier(objective='multiclass', verbosity=-1))\n",
    "    ])\n",
    "\n",
    "    # Hyperparameter search space for LGBM\n",
    "    param_distributions = {\n",
    "        \"lgbm__num_leaves\": randint(20, 150),\n",
    "        \"lgbm__learning_rate\": uniform(0.01, 0.5),\n",
    "        \"lgbm__n_estimators\": randint(50, 500),\n",
    "    \"lgbm__subsample\":        uniform(0.3, 0.7),\n",
    "    \"lgbm__colsample_bytree\": uniform(0.3, 0.7),\n",
    "        \"lgbm__min_child_samples\": randint(1, 50),\n",
    "        \"lgbm__min_split_gain\": uniform(0, 1.0),\n",
    "        \"lgbm__reg_alpha\": uniform(0, 1.0),\n",
    "        \"lgbm__reg_lambda\": uniform(0.5, 2.5)\n",
    "    }\n",
    "\n",
    "    # Stratified cross-validation setup\n",
    "    stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Randomized search for best hyperparameters\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=5,\n",
    "        cv=stratified_cv,\n",
    "        scoring='balanced_accuracy',\n",
    "        verbose=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[INFO] Starting training with {len(X_train)} samples and {len(y_train)} labels\")\n",
    "    randomized_search.fit(X_train, y_train, **{'lgbm__sample_weight': sample_weights})\n",
    "    print(f\"[INFO] Training complete. Best model fitted on {len(X_train)} samples.\\n\")\n",
    "\n",
    "    # Debug one hot encoded features by grabbing column names during training\n",
    "    best_preprocessor = randomized_search.best_estimator_.named_steps['preprocessor']\n",
    "    encoded_X_train = best_preprocessor.transform(X_train)\n",
    "    if hasattr(encoded_X_train, \"toarray\"):\n",
    "        encoded_X_train = encoded_X_train.toarray()\n",
    "    feature_names = best_preprocessor.get_feature_names_out()\n",
    "    print(\"Sample of transformed training features:\")\n",
    "    print(pd.DataFrame(encoded_X_train, columns=feature_names).head())\n",
    "\n",
    "    # Print best parameters and CV score\n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation balanced accuracy:', randomized_search.best_score_)\n",
    "\n",
    "    # Generalization accuracy via cross_val_score\n",
    "    cv_scores = cross_val_score(\n",
    "        randomized_search.best_estimator_,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        verbose=3,\n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    print('Generalization balanced accuracy:', cv_scores.mean())\n",
    "\n",
    "    # Prediction with optional custom thresholds\n",
    "    lgbm_model = randomized_search.best_estimator_.named_steps['lgbm']\n",
    "    class_names = lgbm_model.classes_\n",
    "\n",
    "\n",
    "    # Further helps with class imbalance by requiring certain labels achieve a higher/lower prediciton confidence\n",
    "    def apply_custom_thresholds(probabilities, class_names, thresholds_dict):\n",
    "        thresholds = np.array([thresholds_dict.get(cls, 0.5) for cls in class_names])\n",
    "        preds = []\n",
    "        for row in probabilities:\n",
    "            passed = row >= thresholds\n",
    "            if not passed.any():\n",
    "                pred = class_names[np.argmax(row)]\n",
    "            else:\n",
    "                pred = class_names[np.argmax(passed * row)]\n",
    "            preds.append(pred)\n",
    "        return np.array(preds)\n",
    "\n",
    "    # get probability distribution for all test records for all labels for custom thresholding\n",
    "    proba_test = randomized_search.predict_proba(X_test)\n",
    "    if custom_thresholds:\n",
    "        print(\"[INFO] Applying custom threshold logic to test set\")\n",
    "        test_predictions = apply_custom_thresholds(proba_test, class_names, custom_thresholds)\n",
    "    else:\n",
    "        test_predictions = randomized_search.predict(X_test)\n",
    "\n",
    "    # Compare accuracies on training set if custom thresholds provided\n",
    "    if custom_thresholds:\n",
    "        proba_train = randomized_search.predict_proba(X_train)\n",
    "        preds_custom_train = apply_custom_thresholds(proba_train, class_names, custom_thresholds)\n",
    "        acc_standard = accuracy_score(y_train, randomized_search.predict(X_train))\n",
    "        acc_custom = accuracy_score(y_train, preds_custom_train)\n",
    "        bal_acc_standard = balanced_accuracy_score(y_train, randomized_search.predict(X_train))\n",
    "        bal_acc_custom = balanced_accuracy_score(y_train, preds_custom_train)\n",
    "\n",
    "        print(f\"\\nAccuracy Comparison on Training Set:\")\n",
    "        print(f\"Standard Accuracy: {acc_standard:.4f}\")\n",
    "        print(f\"Custom Threshold Accuracy: {acc_custom:.4f}\")\n",
    "        print(f\"Standard Balanced Accuracy: {bal_acc_standard:.4f}\")\n",
    "        print(f\"Custom Threshold Balanced Accuracy: {bal_acc_custom:.4f}\")\n",
    "\n",
    "    # Extract feature importances\n",
    "    importances = lgbm_model.feature_importances_\n",
    "    df_importances = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    })\n",
    "\n",
    "    return randomized_search.best_estimator_, test_predictions, df_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc94e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near deadline attempt to add location into training. Little attempt before to try feature engineering on location.\n",
    "def add_in_austin(df, df_loc):\n",
    "    \"\"\"\n",
    "    Adds a binary column 'in_austin' that is 1 if 'austin' appears\n",
    "    (caseâ€‘insensitive) in the 'location' field, else 0.\n",
    "    \"\"\"\n",
    "    df['in_austin'] = (\n",
    "        df_loc\n",
    "        .str.contains('austin', case=False, na=False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b302d895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>size</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type   intake_condition animal_type sex_upon_intake  \\\n",
       "0            Stray  Normal / Behavior         Dog   Spayed Female   \n",
       "1            Stray  Normal / Behavior         Dog     Intact Male   \n",
       "2    Public Assist  Normal / Behavior         Cat   Neutered Male   \n",
       "3  Owner Surrender  Normal / Behavior         Dog   Neutered Male   \n",
       "4    Public Assist  Normal / Behavior         Dog   Neutered Male   \n",
       "\n",
       "   age_upon_intake   breed  intake_year primary_color  is_mix  size  \\\n",
       "0             96.0       2         2015     non-black       0     3   \n",
       "1             11.0       7         2016     non-black       1     2   \n",
       "2             24.0  Common         2022     non-black       0     2   \n",
       "3             24.0       2         2017     non-black       1     4   \n",
       "4             72.0       3         2019         black       1     5   \n",
       "\n",
       "      outcome_type  season time_of_day  \n",
       "0  Return to Owner  Summer   Afternoon  \n",
       "1  Return to Owner  Spring     Evening  \n",
       "2         Transfer  Spring       Night  \n",
       "3  Return to Owner  Winter   Afternoon  \n",
       "4  Return to Owner  Spring     Morning  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = df_train.copy()\n",
    "# X_train = add_in_austin(X_train, df_train_location) # df_train_location used to be populated in ml_project\n",
    "X_train = bucket_seasons(X_train)\n",
    "X_train = bucket_days(X_train)\n",
    "X_train = X_train.drop(columns=['intake_month', 'intake_hour'])\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b7ee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>intake_year</th>\n",
       "      <th>primary_color</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>size</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Sick</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2013</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>non-black</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal / Behavior</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>non-black</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Common</td>\n",
       "      <td>2017</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intake_type   intake_condition animal_type sex_upon_intake  age_upon_intake  \\\n",
       "0       Stray  Normal / Behavior         Dog   Neutered Male             24.0   \n",
       "1       Stray               Sick         Cat   Intact Female              1.0   \n",
       "2       Stray  Normal / Behavior         Dog   Neutered Male             48.0   \n",
       "3       Stray  Normal / Behavior         Dog   Intact Female              5.0   \n",
       "4       Stray            Injured         Cat   Intact Female             24.0   \n",
       "\n",
       "    breed  intake_year primary_color  is_mix  size  season time_of_day  \n",
       "0       7         2019     non-black       1     2  Winter   Afternoon  \n",
       "1  Common         2013     non-black       1     2    Fall     Morning  \n",
       "2       3         2014     non-black       1     4  Summer     Morning  \n",
       "3       4         2015     non-black       0     3  Summer     Evening  \n",
       "4  Common         2017         black       1     2  Winter     Morning  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test = df_test.copy()\n",
    "# X_test = add_in_austin(X_test, df_test_location)\n",
    "X_test = bucket_seasons(X_test)\n",
    "X_test = bucket_days(X_test)\n",
    "X_test = X_test.drop(columns=['intake_month', 'intake_hour'])\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05976deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# Encode the target variable.\n",
    "le = LabelEncoder()\n",
    "y_train = X_train['outcome_type']\n",
    "X_train = X_train.drop(columns=['outcome_type'])\n",
    "y_train = le.fit_transform(y_train)\n",
    "print('Encoding mapping:', le.classes_)\n",
    "\n",
    "# Identify rare classes that need oversampling.\n",
    "rare_classes = [\n",
    "    label for label, count in pd.Series(y_train).value_counts().items()\n",
    "    if count < 0.05 * len(y_train)\n",
    "]\n",
    "print(\"Rare classes:\")\n",
    "for cls in rare_classes:\n",
    "    print(f\"  {cls}: {le.classes_[cls]}\")\n",
    "\n",
    "# Define column groups (this example will one-hot encode all columns, so cat_cols and num_cols are not used in the transformer).\n",
    "cat_cols = {'intake_type', 'intake_condition', 'animal_type', 'sex_upon_intake', 'breed', 'intake_month', 'intake_hour', 'intake_year', 'season', 'time_of_day', 'size', 'primary_color'}\n",
    "categorical_features = [col for col in X_train.columns if col in cat_cols]\n",
    "\n",
    "'''\n",
    "# cat_cols_freq = ['primary_color']\n",
    "\n",
    "\n",
    "# Frequency encode selected high-cardinality features, old thing we tried before we realized this is data leakage\n",
    "# for col in cat_cols_freq:\n",
    "#   freq_map = X_train[col].value_counts()\n",
    "#   X_train[col] = X_train[col].map(freq_map)\n",
    "#   X_test[col]  = X_test[col].map(freq_map).fillna(0)\n",
    "'''\n",
    "# Train the classifier with the refactored pipeline.\n",
    "\n",
    "custom_thresholds = {\n",
    "    0: 0.6, # Adopted\n",
    "    1: 0.5, # Died\n",
    "    2: 0.5, # Euthanasia\n",
    "    3: 0.5, # Return to Owner\n",
    "    4: 0.5  # Transfer\n",
    "}\n",
    "\n",
    "best_model, test_predictions, df_importances = train_classifier_lightgbm(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    rare_classes=rare_classes,\n",
    "    cat_cols=categorical_features,\n",
    "    custom_thresholds=custom_thresholds\n",
    ")\n",
    "\n",
    "# Convert predictions back to original labels.\n",
    "predictions = le.inverse_transform(test_predictions)\n",
    "\n",
    "# Save predictions; assumes save_predictions is defined elsewhere.\n",
    "classification_report_with_accuracy_score(y_test, predictions)\n",
    "#save_predictions(predictions, 'lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plots feature importance values to see how our feature engineering is performing and what features we could possibly leave out\n",
    "df_plot = df_importances.sort_values(by='importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(df_plot['feature'], df_plot['importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances from light gbm')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
