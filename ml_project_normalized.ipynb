{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6786200",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f819ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nneom\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nneom\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nneom\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae12383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d346067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR DATA CLEANING - all the stuff should be here\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train = df_train[df_train['intake_type'] != 'Wildlife']\n",
    "df_train = df_train.dropna(subset=['age_upon_intake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42369420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    cols_to_drop = ['id', 'name', 'date_of_birth', 'outcome_time', 'found_location']\n",
    "    existing_cols = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64692110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_time(df):\n",
    "    # Intake Time\n",
    "    # Convert string timestamps to UNIX timestamp\n",
    "    dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n",
    "    df['intake_time'] = dt_series.astype('int64') // (10 ** 9)\n",
    "    return df\n",
    "\n",
    "# Age Upon Intake\n",
    "def convert_age(age_str):\n",
    "    \"\"\"\n",
    "    Convert age strings to years.\n",
    "    Expected format: \"<number> <unit>\" e.g., \"2 years\", \"8 months\", \"3 weeks\", \"15 days\"\n",
    "    \"\"\"\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num = float(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    unit = parts[1].lower()\n",
    "    if \"year\" in unit:\n",
    "        return num\n",
    "    elif \"month\" in unit:\n",
    "        return num / 12\n",
    "    elif \"week\" in unit:\n",
    "        return num / 52\n",
    "    elif \"day\" in unit:\n",
    "        return num / 365\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_age_and_sex_upon_intake(df):\n",
    "    df.loc[df['sex_upon_intake'].isna(), 'sex_upon_intake'] = 'Unknown'\n",
    "    df['age_upon_intake'] = df['age_upon_intake'].apply(convert_age)\n",
    "    df.loc[df['age_upon_intake'] < 0, 'age_upon_intake'] = 0\n",
    "    return df\n",
    "\n",
    "# Breed\n",
    "def clean_breed(df):\n",
    "# Create is_mix column\n",
    "    df['is_mix'] = df['breed'].str.contains('mix', case=False, na=False).astype(int)\n",
    "    # remove mix from all breeds\n",
    "    df['breed'] = df['breed'].str.replace(' mix', '', case=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "948eeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_group_map = {\n",
    "  'blue tabby':       'gray tabby',\n",
    "  'silver tabby':     'gray tabby',\n",
    "  'silver':           'gray',\n",
    "  'blue':             'gray',\n",
    "  'orange tabby':     'orange',\n",
    "  'orange tiger':     'orange',\n",
    "  'red':              'orange',\n",
    "  'red tabby':        'orange',\n",
    "  'red tick':         'orange',\n",
    "  'yellow':           'orange',\n",
    "  'tan':              'cream',\n",
    "}\n",
    "\n",
    "def clean_color(df):\n",
    "  # lowercase\n",
    "  df['color'] = df['color'].str.lower().str.strip()\n",
    "\n",
    "  # feature engineering -> primary color \n",
    "  df['primary_color'] = df['color'].astype(str).apply(\n",
    "      lambda x: x.split('/')[0].strip() if '/' in x else x.strip()\n",
    "  )\n",
    "\n",
    "  # simplify synonymous colors if in map\n",
    "  df['primary_color'] = df['primary_color'].map(color_group_map).fillna(df['primary_color'])\n",
    "\n",
    "  df = df.drop(columns=['color'])\n",
    "  return df\n",
    "\n",
    "\n",
    "def freq_encode(df, col):\n",
    "  # count frequencies\n",
    "  freq_series = df[col].value_counts()\n",
    "\n",
    "  # map frequencies back to the original column, replacing values\n",
    "  df[col] = df[col].map(freq_series)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fe3c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_cond(df):\n",
    "    # # Known mappings\n",
    "    # df['intake_condition'] = df['intake_condition'].replace({\n",
    "    #     'Unknown': 'Unknown Condition / Other', \n",
    "    #     'Other': 'Unknown Condition / Other',\n",
    "    #     'Space': 'Unknown Condition / Other',\n",
    "    #     'Behavior': 'Normal / Behavior', \n",
    "    #     'Normal': 'Normal / Behavior',\n",
    "    #     'Neonatal': 'Nursing / Neonatal', \n",
    "    #     'Nursing': 'Nursing / Neonatal',\n",
    "    #     'Neurologic': 'Med Urgent', \n",
    "    #     'Agonal': 'Med Urgent', \n",
    "    #     'Parvo': 'Med Urgent',\n",
    "    #     'Congenital': 'Sick'\n",
    "    # })\n",
    "\n",
    "    # # Replace any unknown conditions (those not in the mapping) with 'Med Urgent'\n",
    "    # df['intake_condition'] = df['intake_condition'].apply(lambda x: x if x in df['intake_condition'].unique() else 'Med Urgent')\n",
    "\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Unknown': 'Unknown Condition / Other', 'Other': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Space': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Behavior': 'Normal / Behavior', 'Normal': 'Normal / Behavior'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neonatal': 'Nursing / Neonatal', 'Nursing': 'Nursing / Neonatal'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neurologic': 'Med Urgent', 'Agonal': 'Med Urgent', 'Parvo': 'Med Urgent'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Agonal': 'Med Urgent / Neurological'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Congenital': 'Sick'})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a452085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_animal_type(df):\n",
    "#     dummies = pd.get_dummies(df['animal_type'], drop_first=True)\n",
    "#     df = df.drop('animal_type', axis=1)\n",
    "#     df = pd.concat([df, dummies], axis=1)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "552f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = drop_cols(df)\n",
    "    print('dropped columns')\n",
    "    df = clean_intake_time(df)\n",
    "    print('cleaned intake time')\n",
    "    df = clean_intake_cond(df)\n",
    "    print('cleaned intake condition')\n",
    "    df = clean_age_and_sex_upon_intake(df)\n",
    "    print('cleaned age and sex')\n",
    "    df = clean_breed(df)\n",
    "    print('cleaned breed')\n",
    "    df = clean_color(df)\n",
    "    print('cleaned color')\n",
    "    # df = clean_animal_type(df)\n",
    "    # print('cleaned animal type')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edee2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def encode_columns(df):\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    encoder.fit(df[['category_column']])\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_type'])\n",
    "    df = df.drop('intake_type', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_condition'])\n",
    "    df = df.drop('intake_condition', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['sex_upon_intake'])\n",
    "    df = df.drop('sex_upon_intake', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4662dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_train = clean_data(df_train)\\n# df_train = encode_columns(df_train)\\nlabel_column = df_train.pop('outcome_type')\\ndf_train.insert(df_train.shape[1], 'outcome_type', label_column)    \\ndf_train.head()\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_train = clean_data(df_train)\n",
    "# df_train = encode_columns(df_train)\n",
    "label_column = df_train.pop('outcome_type')\n",
    "df_train.insert(df_train.shape[1], 'outcome_type', label_column)    \n",
    "df_train.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbce3bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nneom\\AppData\\Local\\Temp\\ipykernel_1088\\850107665.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned intake time\n",
      "cleaned intake condition\n",
      "cleaned age and sex\n",
      "cleaned breed\n",
      "cleaned color\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_time</th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>sex_upon_intake</th>\n",
       "      <th>age_upon_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>is_mix</th>\n",
       "      <th>primary_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>None</td>\n",
       "      <td>Tricolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Sick</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>4 weeks</td>\n",
       "      <td>None</td>\n",
       "      <td>Calico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>4 years</td>\n",
       "      <td>None</td>\n",
       "      <td>Tan/Gray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>5 months</td>\n",
       "      <td>None</td>\n",
       "      <td>Brown/White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>2 years</td>\n",
       "      <td>None</td>\n",
       "      <td>Black/White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27786</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>8 months</td>\n",
       "      <td>None</td>\n",
       "      <td>Brown Brindle/White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27787</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>2 months</td>\n",
       "      <td>None</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27788</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>8 years</td>\n",
       "      <td>None</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27789</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>9 years</td>\n",
       "      <td>None</td>\n",
       "      <td>Brown/Brown Tabby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27790</th>\n",
       "      <td>-9223372037</td>\n",
       "      <td>Feral</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>None</td>\n",
       "      <td>Orange Tabby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27791 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_time intake_type intake_condition    animal_type  \\\n",
       "0      -9223372037      Normal              Dog  Neutered Male   \n",
       "1      -9223372037        Sick              Cat  Intact Female   \n",
       "2      -9223372037      Normal              Dog  Neutered Male   \n",
       "3      -9223372037      Normal              Dog  Intact Female   \n",
       "4      -9223372037     Injured              Cat  Intact Female   \n",
       "...            ...         ...              ...            ...   \n",
       "27786  -9223372037      Normal              Dog  Intact Female   \n",
       "27787  -9223372037      Normal              Cat  Intact Female   \n",
       "27788  -9223372037      Normal              Dog  Neutered Male   \n",
       "27789  -9223372037     Injured              Cat  Spayed Female   \n",
       "27790  -9223372037       Feral              Cat    Intact Male   \n",
       "\n",
       "      sex_upon_intake age_upon_intake                breed  outcome_type  \\\n",
       "0             2 years            None             Tricolor           NaN   \n",
       "1             4 weeks            None               Calico           NaN   \n",
       "2             4 years            None             Tan/Gray           NaN   \n",
       "3            5 months            None          Brown/White           NaN   \n",
       "4             2 years            None          Black/White           NaN   \n",
       "...               ...             ...                  ...           ...   \n",
       "27786        8 months            None  Brown Brindle/White           NaN   \n",
       "27787        2 months            None                Black           NaN   \n",
       "27788         8 years            None                White           NaN   \n",
       "27789         9 years            None    Brown/Brown Tabby           NaN   \n",
       "27790         2 years            None         Orange Tabby           NaN   \n",
       "\n",
       "       is_mix primary_color  \n",
       "0           0             1  \n",
       "1           0             9  \n",
       "2           0             6  \n",
       "3           0             1  \n",
       "4           0             2  \n",
       "...       ...           ...  \n",
       "27786       0            10  \n",
       "27787       0             6  \n",
       "27788       0            11  \n",
       "27789       0             8  \n",
       "27790       0             7  \n",
       "\n",
       "[27791 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = clean_data(df_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d11cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer code for pipelines\n",
    "\n",
    "# Use FunctionTransformer to wrap the freq_encode function\n",
    "def apply_freq_encode(df):\n",
    "    df = freq_encode(df, 'primary_color')\n",
    "    df = freq_encode(df, 'breed')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e946ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import OneHotEncoder, FunctionTransformer\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score\\nfrom xgboost import XGBClassifier\\n\\ndef train_classifier(X_train, y_train, X_test):\\n    \"\"\"\\n    Trains an XGBoost model using a pipeline that includes a frequency encoding transformation,\\n    OneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\\n\\n    Parameters:\\n        X_train (pd.DataFrame): Training features.\\n        y_train (pd.Series or np.array): Training target values.\\n        X_test (pd.DataFrame): Test features.\\n\\n    Returns:\\n        best_estimator: The best estimator from RandomizedSearchCV.\\n        test_predictions: The predicted labels for X_test from the best estimator.\\n    \"\"\"\\n    # Construct the pipeline:\\n    #   1. Apply frequency encoding (for example, on \\'primary_color\\' & \\'breed\\' if implemented in apply_freq_encode)\\n    #   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\\n    #   3. Fit an XGBClassifier.\\n    pipeline = Pipeline([\\n        (\\'freq\\', FunctionTransformer(apply_freq_encode, validate=False)),\\n        (\\'onehot\\', OneHotEncoder(handle_unknown=\\'ignore\\', sparse_output=False)),\\n        (\\'xgb\\', XGBClassifier(eval_metric=\\'logloss\\', verbosity=1))\\n    ])\\n\\n    # Set up parameter distributions for XGBoost.\\n    param_distributions = {\\n        \"xgb__max_depth\": [3, 6, 9],\\n        \"xgb__learning_rate\": [0.01, 0.1, 0.2],\\n        \"xgb__n_estimators\": [50, 100, 200],\\n        \"xgb__subsample\": [0.5, 0.7, 1.0],\\n        \"xgb__colsample_bytree\": [0.5, 0.7, 1.0]\\n    }\\n\\n    # Perform hyperparameter search using RandomizedSearchCV.\\n    randomized_search = RandomizedSearchCV(\\n        estimator=pipeline, \\n        param_distributions=param_distributions,\\n        n_iter=1,\\n        cv=5, \\n        scoring=\\'accuracy\\', \\n        verbose=3,\\n    )\\n\\n    randomized_search.fit(X_train, y_train)\\n\\n    print(\\'Best parameters:\\', randomized_search.best_params_)\\n    print(\\'Best cross-validation accuracy:\\', randomized_search.best_score_)\\n\\n    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=5, verbose=3)\\n    print(\\'Generalization accuracy (via cross_val_score):\\', cv_scores.mean())\\n\\n    # Make predictions on the test set using the best estimator.\\n    test_predictions = randomized_search.predict(X_test)\\n\\n    return randomized_search.best_estimator_, test_predictions\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_classifier(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost model using a pipeline that includes a frequency encoding transformation,\n",
    "    OneHotEncoder, and hyperparameter tuning via RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series or np.array): Training target values.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "    \n",
    "    Returns:\n",
    "        best_estimator: The best estimator from RandomizedSearchCV.\n",
    "        test_predictions: The predicted labels for X_test from the best estimator.\n",
    "    \"\"\"\n",
    "    # Construct the pipeline:\n",
    "    #   1. Apply frequency encoding (for example, on 'primary_color' & 'breed' if implemented in apply_freq_encode)\n",
    "    #   2. OneHotEncode the features (adjust handle_unknown and sparse_output as needed)\n",
    "    #   3. Fit an XGBClassifier.\n",
    "    pipeline = Pipeline([\n",
    "        ('freq', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', verbosity=1))\n",
    "    ])\n",
    "    \n",
    "    # Set up parameter distributions for XGBoost.\n",
    "    param_distributions = {\n",
    "        \"xgb__max_depth\": [3, 6, 9],\n",
    "        \"xgb__learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"xgb__n_estimators\": [50, 100, 200],\n",
    "        \"xgb__subsample\": [0.5, 0.7, 1.0],\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Perform hyperparameter search using RandomizedSearchCV.\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline, \n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=1,\n",
    "        cv=5, \n",
    "        scoring='accuracy', \n",
    "        verbose=3,\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best parameters:', randomized_search.best_params_)\n",
    "    print('Best cross-validation accuracy:', randomized_search.best_score_)\n",
    "    \n",
    "    cv_scores = cross_val_score(randomized_search.best_estimator_, X_train, y_train, cv=5, verbose=3)\n",
    "    print('Generalization accuracy (via cross_val_score):', cv_scores.mean())\n",
    "    \n",
    "    # Make predictions on the test set using the best estimator.\n",
    "    test_predictions = randomized_search.predict(X_test)\n",
    "    \n",
    "    return randomized_search.best_estimator_, test_predictions\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4448de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import LabelEncoder\\n# For Dog:\\ntrain_dog = df_train[df_train[\\'animal_type\\'] == \\'Dog\\'].copy()\\nX_train_dog = train_dog.drop(columns=[\\'animal_type\\', \\'outcome_type\\'])\\ny_train_dog = train_dog[\\'outcome_type\\']\\n\\ntest_dog = df_test[df_test[\\'animal_type\\'] == \\'Dog\\'].copy()\\nX_test_dog = test_dog.drop(columns=[\\'animal_type\\'])\\n\\n# For Cat:\\ntrain_cat = df_train[df_train[\\'animal_type\\'] == \\'Cat\\'].copy()\\nX_train_cat = train_cat.drop(columns=[\\'animal_type\\', \\'outcome_type\\'])\\ny_train_cat = train_cat[\\'outcome_type\\']\\n\\ntest_cat = df_test[df_test[\\'animal_type\\'] == \\'Cat\\'].copy()\\nX_test_cat = test_cat.drop(columns=[\\'animal_type\\'])\\n\\n## Encode targets with LabelEncoder\\n# Dog encoding\\nle_dog = LabelEncoder()\\ny_train_dog_encoded = le_dog.fit_transform(y_train_dog)\\n\\n# Cat encoding\\nle_cat = LabelEncoder()\\ny_train_cat_encoded = le_cat.fit_transform(y_train_cat)\\n\\nprint(\"Training model for Dog data:\")\\nbest_estimator_dog, dog_predictions_encoded = train_classifier(X_train_dog, y_train_dog_encoded, X_test_dog)\\ndog_predictions = le_dog.inverse_transform(dog_predictions_encoded)\\n\\nprint(\"\\nTraining model for Cat data:\")\\nbest_estimator_cat, cat_predictions_encoded = train_classifier(X_train_cat, y_train_cat_encoded, X_test_cat)\\ncat_predictions = le_cat.inverse_transform(cat_predictions_encoded)\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# For Dog:\n",
    "train_dog = df_train[df_train['animal_type'] == 'Dog'].copy()\n",
    "X_train_dog = train_dog.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_dog = train_dog['outcome_type']\n",
    "\n",
    "test_dog = df_test[df_test['animal_type'] == 'Dog'].copy()\n",
    "X_test_dog = test_dog.drop(columns=['animal_type'])\n",
    "\n",
    "# For Cat:\n",
    "train_cat = df_train[df_train['animal_type'] == 'Cat'].copy()\n",
    "X_train_cat = train_cat.drop(columns=['animal_type', 'outcome_type'])\n",
    "y_train_cat = train_cat['outcome_type']\n",
    "\n",
    "test_cat = df_test[df_test['animal_type'] == 'Cat'].copy()\n",
    "X_test_cat = test_cat.drop(columns=['animal_type'])\n",
    "\n",
    "## Encode targets with LabelEncoder\n",
    "# Dog encoding\n",
    "le_dog = LabelEncoder()\n",
    "y_train_dog_encoded = le_dog.fit_transform(y_train_dog)\n",
    "\n",
    "# Cat encoding\n",
    "le_cat = LabelEncoder()\n",
    "y_train_cat_encoded = le_cat.fit_transform(y_train_cat)\n",
    "\n",
    "print(\"Training model for Dog data:\")\n",
    "best_estimator_dog, dog_predictions_encoded = train_classifier(X_train_dog, y_train_dog_encoded, X_test_dog)\n",
    "dog_predictions = le_dog.inverse_transform(dog_predictions_encoded)\n",
    "\n",
    "print(\"\\nTraining model for Cat data:\")\n",
    "best_estimator_cat, cat_predictions_encoded = train_classifier(X_train_cat, y_train_cat_encoded, X_test_cat)\n",
    "cat_predictions = le_cat.inverse_transform(cat_predictions_encoded)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "803ac334",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICTION STITCHING ##\n",
    "def combine_predictions(dog_pred, cat_pred, dog_true, cat_true):\n",
    "    \"\"\"\n",
    "    Pass in list of dog predictions and cat predictions\n",
    "    Returns -> stitched together predictions based on original test set order\n",
    "    \"\"\"\n",
    "    dog_pred_series = pd.Series(dog_pred, index=dog_true.index)\n",
    "    cat_pred_series = pd.Series(cat_pred, index=cat_true.index)\n",
    "    # Concatenate both series and sort by the original index so the output \n",
    "    # reflects the same order as the original test dataset\n",
    "    all_predictions = pd.concat([dog_pred_series, cat_pred_series]).sort_index()\n",
    "    final_df = pd.DataFrame({'Predicted_Label': all_predictions})\n",
    "    csv_path = './test_predictions_combined.csv'\n",
    "    final_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined test predictions saved to: {csv_path}\")\n",
    "\n",
    "# combine_predictions(dog_predictions, cat_predictions, X_test_dog, X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# At the end of the notebook, or wherever you want to save the functions\\nwith open(\\'ml_project_func.py\\', \\'w\\') as f:\\n    f.write(\"\"\" \\n    # All your function code goes here\\n    \"\"\")\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the end of the notebook, or wherever you want to save the functions\n",
    "with open('ml_project.py', 'w') as f:\n",
    "    f.write(\"\"\" \n",
    "    # All your function code goes here\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22747c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ml_project successfully imported.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
