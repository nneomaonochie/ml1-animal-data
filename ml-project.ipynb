{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a68e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6786200",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ae12383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42369420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    cols_to_drop = ['id', 'name', 'date_of_birth', 'outcome_time', 'found_location']\n",
    "    existing_cols = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d346067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR DATA CLEANING - all the stuff should be here\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train = df_train[df_train['intake_type'] != 'Wildlife']\n",
    "df_train = df_train.dropna(subset=['age_upon_intake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "64692110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_time(df):\n",
    "    # Intake Time\n",
    "    # Convert string timestamps to UNIX timestamp\n",
    "    dt_series = pd.to_datetime(df['intake_time'], errors='coerce')\n",
    "    df['intake_time'] = dt_series.astype('int64') // (10 ** 9)\n",
    "    return df\n",
    "\n",
    "# Age Upon Intake\n",
    "def convert_age(age_str):\n",
    "    \"\"\"\n",
    "    Convert age strings to years.\n",
    "    Expected format: \"<number> <unit>\" e.g., \"2 years\", \"8 months\", \"3 weeks\", \"15 days\"\n",
    "    \"\"\"\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num = float(parts[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    unit = parts[1].lower()\n",
    "    if \"year\" in unit:\n",
    "        return num\n",
    "    elif \"month\" in unit:\n",
    "        return num / 12\n",
    "    elif \"week\" in unit:\n",
    "        return num / 52\n",
    "    elif \"day\" in unit:\n",
    "        return num / 365\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_age_and_sex_upon_intake(df):\n",
    "    df.loc[df['sex_upon_intake'].isna(), 'sex_upon_intake'] = 'Unknown'\n",
    "    df['age_upon_intake'] = df['age_upon_intake'].apply(convert_age)\n",
    "    df.loc[df['age_upon_intake'] < 0, 'age_upon_intake'] = 0\n",
    "    return df\n",
    "\n",
    "# Breed\n",
    "def clean_breed(df):\n",
    "# Create is_mix column\n",
    "    df['is_mix'] = df['breed'].str.contains('mix', case=False, na=False).astype(int)\n",
    "    # remove mix from all breeds\n",
    "    df['breed'] = df['breed'].str.replace(' mix', '', case=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "948eeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_group_map = {\n",
    "  'blue tabby':       'gray tabby',\n",
    "  'silver tabby':     'gray tabby',\n",
    "  'silver':           'gray',\n",
    "  'blue':             'gray',\n",
    "  'orange tabby':     'orange',\n",
    "  'orange tiger':     'orange',\n",
    "  'red':              'orange',\n",
    "  'red tabby':        'orange',\n",
    "  'red tick':         'orange',\n",
    "  'yellow':           'orange',\n",
    "  'tan':              'cream',\n",
    "}\n",
    "\n",
    "def clean_color(df):\n",
    "  # lowercase\n",
    "  df['color'] = df['color'].str.lower().str.strip()\n",
    "\n",
    "  # feature engineering -> primary color \n",
    "  df['primary_color'] = df['color'].astype(str).apply(\n",
    "      lambda x: x.split('/')[0].strip() if '/' in x else x.strip()\n",
    "  )\n",
    "\n",
    "  # simplify synonymous colors if in map\n",
    "  df['primary_color'] = df['primary_color'].map(color_group_map).fillna(df['primary_color'])\n",
    "\n",
    "  df = df.drop(columns=['color'])\n",
    "  return df\n",
    "\n",
    "\n",
    "def freq_encode(df, col):\n",
    "  # count frequencies\n",
    "  freq_series = df[col].value_counts()\n",
    "\n",
    "  # map frequencies back to the original column, replacing values\n",
    "  df[col] = df[col].map(freq_series)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3fe3c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intake_cond(df):\n",
    "    # Known mappings\n",
    "    df['intake_condition'] = df['intake_condition'].replace({\n",
    "        'Unknown': 'Unknown Condition / Other', \n",
    "        'Other': 'Unknown Condition / Other',\n",
    "        'Space': 'Unknown Condition / Other',\n",
    "        'Behavior': 'Normal / Behavior', \n",
    "        'Normal': 'Normal / Behavior',\n",
    "        'Neonatal': 'Nursing / Neonatal', \n",
    "        'Nursing': 'Nursing / Neonatal',\n",
    "        'Neurologic': 'Med Urgent', \n",
    "        'Agonal': 'Med Urgent', \n",
    "        'Parvo': 'Med Urgent',\n",
    "        'Congenital': 'Sick'\n",
    "    })\n",
    "\n",
    "    # Replace any unknown conditions (those not in the mapping) with 'Med Urgent'\n",
    "    df['intake_condition'] = df['intake_condition'].apply(lambda x: x if x in df['intake_condition'].unique() else 'Med Urgent')\n",
    "\n",
    "\n",
    "    '''\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Unknown': 'Unknown Condition / Other', 'Other': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Space': 'Unknown Condition / Other'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Behavior': 'Normal / Behavior', 'Normal': 'Normal / Behavior'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neonatal': 'Nursing / Neonatal', 'Nursing': 'Nursing / Neonatal'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Neurologic': 'Med Urgent', 'Agonal': 'Med Urgent', 'Parvo': 'Med Urgent'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Agonal': 'Med Urgent / Neurological'})\n",
    "    df['intake_condition'] = df['intake_condition'].replace({'Congenital': 'Sick'})\n",
    "    '''\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a452085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_animal_type(df):\n",
    "    dummies = pd.get_dummies(df['animal_type'], drop_first=True)\n",
    "    df = df.drop('animal_type', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "552f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = drop_cols(df)\n",
    "    df = clean_intake_time(df)\n",
    "    df = clean_intake_cond(df)\n",
    "    df = clean_age_and_sex_upon_intake(df)\n",
    "    df = clean_breed(df)\n",
    "    df = clean_color(df)\n",
    "    df = clean_animal_type(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "edee2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def encode_columns(df):\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    encoder.fit(df[['category_column']])\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_type'])\n",
    "    df = df.drop('intake_type', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['intake_condition'])\n",
    "    df = df.drop('intake_condition', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['sex_upon_intake'])\n",
    "    df = df.drop('sex_upon_intake', axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = clean_data(df_train)\n",
    "df_train = encode_columns(df_train)\n",
    "label_column = df_train.pop('outcome_type')\n",
    "df_train.insert(df_train.shape[1], 'outcome_type', label_column)    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cats = df_train[df_train['animal_type'] == 'Cat']\n",
    "# dogs = df_train[df_train['animal_type'] == 'Dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dbc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats = cats.drop('animal_type', axis=1)\n",
    "# dogs = dogs.drop('animal_type', axis=1)\n",
    "\n",
    "# cats_data = cats.iloc[:, :-1]\n",
    "# cats_labels = cats.iloc[:, -1:]\n",
    "\n",
    "# dogs_data = dogs.iloc[:, :-1]\n",
    "# dogs_labels = dogs.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b82a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Decision Trees\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d11cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer code for pipelines\n",
    "\n",
    "# Use FunctionTransformer to wrap the freq_encode function\n",
    "def apply_freq_encode(df):\n",
    "    df = freq_encode(df, 'primary_color')\n",
    "    df = freq_encode(df, 'breed')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_train.sample(n=1000)\n",
    "df_data     = sample.iloc[:, :-1]\n",
    "df_labels   = sample.iloc[:, -1:]\n",
    "\n",
    "# we are now going to clean test so we can test\n",
    "df_test = clean_data(df_test)\n",
    "df_test = encode_columns(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLAY CHAT!\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', class_weight='balanced')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('encoder', FunctionTransformer(apply_freq_encode, validate=False)),\n",
    "    ('DT', tree)\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "HP = {\n",
    "    \"DT__max_depth\": [10, 12, 15, 17, 20, 25],\n",
    "    \"DT__max_features\": [None, 5, 15, 20, 28],  \n",
    "    \"DT__min_samples_leaf\": [5, 10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "griddy = GridSearchCV(estimator=pipe, param_grid=HP, cv=10, scoring='accuracy')\n",
    "\n",
    "# Now actually fit the model\n",
    "griddy.fit(df_data, df_labels.values.ravel())\n",
    "\n",
    "# Output results\n",
    "print('The best parameters for our model are:', griddy.best_params_)\n",
    "print('The best accuracy we obtained using the best hyperparameter values is:', griddy.best_score_)\n",
    "\n",
    "# Generalization accuracy using cross_val_score (optional)\n",
    "accs = cross_val_score(griddy.best_estimator_, X=df_data, y=df_labels.values.ravel(), cv=10)\n",
    "print('The generalization accuracy of the tuned CV model is:', accs.mean())\n",
    "\n",
    "# Apply predictions using the best estimator from the grid search\n",
    "test_predictions = griddy.predict(df_test)\n",
    "\n",
    "# Save test predictions to CSV\n",
    "df_test_output = pd.DataFrame({\n",
    "  'Predicted_Label': test_predictions\n",
    "})\n",
    "\n",
    "csv_test_path = './test_predictions.csv'\n",
    "df_test_output.to_csv(csv_test_path, index=False)\n",
    "print(f'Test predictions saved to: {csv_test_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
